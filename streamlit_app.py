import streamlit as st
import requests
import json
import re
import os
import pandas as pd
import plotly.graph_objects as go
import io
import time
import logging
import fcntl
from typing import Tuple, Dict, Any, List
from openpyxl import load_workbook
from openpyxl.styles import PatternFill
from pathlib import Path

# ===============================
# åŸºç¡€é…ç½®ä¸æ—¥å¿—ï¼ˆæ–°å¢ï¼šå®šä½ä¸­æ–­åŸå› ï¼‰
# ===============================
# åˆ›å»ºæ—¥å¿—é…ç½®
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler("process_log.log", encoding="utf-8"),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items=None
)

# è‡ªå®šä¹‰CSSæ ·å¼
hide_streamlit_style = """
<style>
header {visibility: hidden;}
footer {visibility: hidden;}
.dataframe {font-size: 12px;}
[data-testid="stSidebar"] {display: none !important;}
.stApp > div:first-child {padding-top: 2rem;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# å…¨å±€å¸¸é‡ï¼ˆä¿®å¤ï¼šä½¿ç”¨ç»å¯¹è·¯å¾„é¿å…æ–‡ä»¶è·¯å¾„é—®é¢˜ï¼‰
BASE_DIR = Path(__file__).parent
BACKUP_FILE = BASE_DIR / "batch_history_log.csv"
PROGRESS_FILE = BASE_DIR / "process_progress.json"  # æ–°å¢ï¼šä¿å­˜å¤„ç†è¿›åº¦
RULE_SETS = {
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V, Väº†V, Vä¸V, Väº†æ²¡æœ‰'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®æˆ–è·Ÿåœ¨'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®ï¼Œä¸èƒ½è·Ÿåœ¨'å¤šä¹ˆ'ä¹‹åè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
    ],
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®š", "match_score": 10, "mismatch_score": -10},
        {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰\"VVã€Vä¸€Vã€Väº†Vã€Vä¸V\"ç­‰é‡å å’Œæ­£åé‡å å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°ï¼Œæˆ–è€…å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åæé—®", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š\"ä¹‹åå¯¹æ€§è´¨çš„ç¨‹åº¦è¿›è¡Œæé—®", "match_score": 10, "mismatch_score": -10},
        {"name": "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
    ]
}

# ===============================
# æ¨¡å‹é…ç½®
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True, 
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True,
        },
    },
    "gemini": {
        # æ–¹æ¡ˆ Aï¼šè¿™æ˜¯ç›®å‰æœ€é€šç”¨çš„ OpenAI å…¼å®¹è·¯å¾„
        "base_url": "https://generativelanguage.googleapis.com/v1beta/openai",
        "endpoint": "/v1/chat/completions", # æ³¨æ„è¿™é‡Œå¤šäº†ä¸€ä¸ª /v1
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, 
            "messages": messages, 
            "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        "headers": lambda key: {
            "Authorization": f"Bearer {key}", 
            "Content-Type": "application/json",
            "X-DashScope-SSE": "enable",
            "Accept": "text/event-stream"
        },
        "payload": lambda model, messages, **kw: {
            "model": model, 
            "input": {"messages": messages}, 
            "parameters": {
                "max_tokens": kw.get("max_tokens", 4096), 
                "temperature": kw.get("temperature", 0.0),
                "result_format": "message",
                "incremental_output": True 
            },
        },
    },
}

MODEL_OPTIONS = {
    "DeepSeek Chat": {
        "provider": "deepseek", 
        "model": "deepseek-chat", 
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
        "env_var": "DEEPSEEK_API_KEY"
    },
    "OpenAI GPT-4oï¼ˆæ¨èï¼‰": {
        "provider": "openai", 
        "model": "gpt-4o-mini", 
        "api_key": os.getenv("OPENAI_API_KEY"),
        "env_var": "OPENAI_API_KEY"
    },
    "Google Gemini 1.5 Pro": {
        "provider": "gemini", 
        "model": "gemini-1.5-pro", 
        "api_key": os.getenv("GEMINI_API_KEY"),
        "env_var": "GEMINI_API_KEY"
    },
    "Google Gemini 1.5 Flash": {
        "provider": "gemini", 
        "model": "gemini-1.5-flash", 
        "api_key": os.getenv("GEMINI_API_KEY"),
        "env_var": "GEMINI_API_KEY"
    },
    "Moonshotï¼ˆKimiï¼‰": {
        "provider": "moonshot", 
        "model": "moonshot-v1-32k", 
        "api_key": os.getenv("MOONSHOT_API_KEY"),
        "env_var": "MOONSHOT_API_KEY"
    },
    "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰": {
        "provider": "qwen", 
        "model": "qwen-max", 
        "api_key": os.getenv("QWEN_API_KEY"),
        "env_var": "QWEN_API_KEY"
    },
}

AVAILABLE_MODEL_OPTIONS = {
    name: info for name, info in MODEL_OPTIONS.items() if info["api_key"]
}

if not AVAILABLE_MODEL_OPTIONS:
    AVAILABLE_MODEL_OPTIONS = MODEL_OPTIONS

# ===============================
# å¢å¼ºå‹å·¥å…·å‡½æ•°ï¼ˆè§£å†³ä¸­æ–­æ ¸å¿ƒï¼‰
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    """ä»ä¸åŒæ ¼å¼çš„LLMå“åº”ä¸­å®‰å…¨æå–æ–‡æœ¬å†…å®¹ã€‚"""
    if not isinstance(resp_json, dict):
        return ""
    try:
        if "output" in resp_json and "text" in resp_json["output"]:
            return resp_json["output"]["text"]
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
        return json.dumps(resp_json, ensure_ascii=False)
    except Exception as e:
        logger.error(f"æå–å“åº”æ–‡æœ¬å¤±è´¥: {e}")
        return json.dumps(resp_json, ensure_ascii=False)

def extract_json_from_text(text: str) -> Tuple[Dict[str, Any], str]:
    """ä»æ··åˆæ–‡æœ¬ä¸­æå–å¹¶è§£æJSONå¯¹è±¡ã€‚"""
    match = re.search(r"(\{.*\})", text.strip(), re.DOTALL)
    if not match:
        return None, text

    json_text = match.group(1).strip()
    try:
        parsed_json = json.loads(json_text)
        return parsed_json, json_text
    except json.JSONDecodeError as e:
        logger.error(f"è§£æJSONå¤±è´¥: {e}, åŸå§‹æ–‡æœ¬: {json_text[:100]}")
        return None, json_text

def normalize_key(k: str, pos_rules: list) -> str:
    """æ ‡å‡†åŒ–æ¨¡å‹è¿”å›çš„è§„åˆ™åç§°"""
    if not isinstance(k, str): return None
    k_norm = re.sub(r'[\s_]+', '', k).upper()
    for r in pos_rules:
        r_norm = re.sub(r'[\s_]+', '', r["name"]).upper()
        if r_norm == k_norm:
            return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    """å°†æ¨¡å‹è¿”å›å€¼æ˜ å°„ä¸ºè§„åˆ™å¾—åˆ†"""
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    try:
        if isinstance(raw_val, bool):
            return match_score if raw_val else mismatch_score
        if isinstance(raw_val, str):
            s = raw_val.strip().lower()
            if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"):
                return match_score
            if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"):
                return mismatch_score
        if isinstance(raw_val, (int, float)):
            raw_val_int = int(raw_val)
            if raw_val_int == match_score: return match_score
            if raw_val_int == mismatch_score: return mismatch_score
    except Exception as e:
        logger.error(f"æ˜ å°„å¾—åˆ†å¤±è´¥: {e}")
    return mismatch_score

def calculate_membership(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    """è®¡ç®—éš¶å±åº¦"""
    membership = {}
    try:
        for pos, scores in scores_all.items():
            total_score = sum(scores.values())
            normalized = total_score / 100
            membership[pos] = max(-1.0, min(1.0, normalized))
    except Exception as e:
        logger.error(f"è®¡ç®—éš¶å±åº¦å¤±è´¥: {e}")
    return membership

def get_top_10_positions(membership: Dict[str, float]) -> List[Tuple[str, float]]:
    """è·å–éš¶å±åº¦æœ€é«˜çš„å‰ 10 ä¸ªè¯ç±»"""
    try:
        return sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]
    except Exception as e:
        logger.error(f"æ’åºéš¶å±åº¦å¤±è´¥: {e}")
        return []

def get_history_count(backup_file):
    """è·å–æœ€æ–°çš„å†å²è®°å½•æ•°é‡ï¼ˆå®æ—¶æ›´æ–°ç”¨ï¼‰"""
    if not os.path.exists(backup_file):
        return 0
    try:
        temp_history = pd.read_csv(backup_file, encoding='utf-8-sig')
        return len(temp_history)
    except Exception as e:
        logger.warning(f"è¯»å–å†å²è®°å½•æ•°é‡å¤±è´¥: {e}")
        return 0

# æ–°å¢ï¼šæ–‡ä»¶å†™å…¥åŠ é” + é‡è¯•ï¼ˆè§£å†³æ–‡ä»¶æ“ä½œä¸­æ–­ï¼‰
def safe_write_csv(df, file_path, mode='a', header=False, encoding='utf-8-sig', max_retries=3):
    """å®‰å…¨å†™å…¥CSVï¼ŒåŠ æ–‡ä»¶é”é¿å…å†²çªï¼Œå¤±è´¥è‡ªåŠ¨é‡è¯•"""
    retry_count = 0
    while retry_count < max_retries:
        try:
            with open(file_path, mode, encoding=encoding) as f:
                fcntl.flock(f, fcntl.LOCK_EX)  # æ’ä»–é”
                df.to_csv(f, mode=mode, header=header, index=False)
                fcntl.flock(f, fcntl.LOCK_UN)  # é‡Šæ”¾é”
            return True
        except Exception as e:
            retry_count += 1
            logger.warning(f"å†™å…¥CSVå¤±è´¥ï¼ˆé‡è¯•{retry_count}/{max_retries}ï¼‰: {e}")
            time.sleep(1)
    logger.error(f"å†™å…¥CSVæœ€ç»ˆå¤±è´¥: {file_path}")
    return False

# æ–°å¢ï¼šä¿å­˜/åŠ è½½å¤„ç†è¿›åº¦ï¼ˆè§£å†³æ–­ç‚¹ç»­ä¼ ä¸­æ–­ï¼‰
def save_process_progress(file_name, current_row, total_rows):
    """ä¿å­˜å¤„ç†è¿›åº¦"""
    try:
        progress_data = {
            "file_name": file_name,
            "current_row": current_row,
            "total_rows": total_rows,
            "last_update": time.strftime("%Y-%m-%d %H:%M:%S")
        }
        with open(PROGRESS_FILE, 'w', encoding='utf-8') as f:
            json.dump(progress_data, f, ensure_ascii=False, indent=2)
    except Exception as e:
        logger.error(f"ä¿å­˜è¿›åº¦å¤±è´¥: {e}")

def load_process_progress():
    """åŠ è½½å¤„ç†è¿›åº¦"""
    if not os.path.exists(PROGRESS_FILE):
        return None
    try:
        with open(PROGRESS_FILE, 'r', encoding='utf-8') as f:
            return json.load(f)
    except Exception as e:
        logger.error(f"åŠ è½½è¿›åº¦å¤±è´¥: {e}")
        return None

# æ–°å¢ï¼šæ¸…é™¤è¿›åº¦æ–‡ä»¶
def clear_process_progress():
    """æ¸…é™¤è¿›åº¦æ–‡ä»¶"""
    if os.path.exists(PROGRESS_FILE):
        try:
            os.remove(PROGRESS_FILE)
        except Exception as e:
            logger.error(f"æ¸…é™¤è¿›åº¦æ–‡ä»¶å¤±è´¥: {e}")

# ===============================
# å¢å¼ºå‹LLMè°ƒç”¨ï¼ˆè§£å†³APIä¸­æ–­ï¼‰
# ===============================
def call_llm_api_cached(_provider, _model, _api_key, messages, max_tokens=4096, temperature=0.0, max_retries=3):
    """å°è£…LLMè°ƒç”¨é€»è¾‘ï¼Œå¢å¼ºé”™è¯¯åˆ†ç±»ä¸é‡è¯•æœºåˆ¶"""
    if not _api_key: 
        logger.error("API Key ä¸ºç©º")
        return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"
    if _provider not in MODEL_CONFIGS: 
        logger.error(f"æœªçŸ¥æä¾›å•† {_provider}")
        return False, {"error": f"æœªçŸ¥æä¾›å•† {_provider}"}, f"æœªçŸ¥æä¾›å•† {_provider}"

    cfg = MODEL_CONFIGS[_provider]
    # æ³¨æ„ï¼šè¿™é‡Œçš„ url æ‹¼æ¥é€»è¾‘å·²ç»è€ƒè™‘äº† base_url ä¿®æ”¹åçš„å…¼å®¹æ€§
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](_api_key)
    payload = cfg["payload"](_model, messages, max_tokens=max_tokens, temperature=temperature)

    streaming_placeholder = st.empty()
    full_content = ""
    error_msg = "æœªçŸ¥é”™è¯¯"

    # å¢å¼ºé‡è¯•é€»è¾‘
    for attempt in range(max_retries):
        try:
            # å¢åŠ  timeout é˜²æ­¢ç½‘ç»œæŒ‚æ­»
            with requests.post(url, headers=headers, json=payload, stream=True, timeout=120) as response:
                # æ£€æŸ¥ HTTP çŠ¶æ€ç 
                if response.status_code != 200:
                    if response.status_code == 404:
                        error_msg = f"API è·¯å¾„é”™è¯¯ (404): è¯·æ£€æŸ¥ {_provider} çš„ base_url æˆ–æ¨¡å‹åç§°æ˜¯å¦æ­£ç¡®ã€‚"
                    elif response.status_code == 401:
                        error_msg = f"é‰´æƒå¤±è´¥ (401): è¯·æ£€æŸ¥æ‚¨çš„ API Key æ˜¯å¦æœ‰æ•ˆã€‚"
                    elif response.status_code == 429:
                        error_msg = "è¯·æ±‚è¿‡å¿« (429): å·²è§¦å‘é¢‘ç‡é™åˆ¶ï¼Œæ­£åœ¨ç­‰å¾…é‡è¯•..."
                    else:
                        error_msg = f"API å“åº”å¼‚å¸¸: çŠ¶æ€ç  {response.status_code}, å†…å®¹: {response.text}"
                    
                    # è§¦å‘çŠ¶æ€ç å¼‚å¸¸ï¼Œè¿›å…¥ except ä»£ç å—
                    response.raise_for_status()

                # æ­£å¸¸æµå¼è¯»å–
                for line in response.iter_lines():
                    if not line: continue
                    line_text = line.decode('utf-8').strip()
                    
                    # é€‚é…ä¸åŒå¹³å°çš„ SSE æ ¼å¼
                    json_str = line_text[5:].strip() if line_text.startswith("data:") else line_text
                    if json_str == "[DONE]": break
                    
                    try:
                        chunk = json.loads(json_str)
                        delta_text = ""
                        # å…¼å®¹ OpenAI/DeepSeek æ ¼å¼
                        if "choices" in chunk and len(chunk["choices"]) > 0:
                            delta = chunk["choices"][0].get("delta", {})
                            delta_text = delta.get("content", "")
                        # å…¼å®¹ Qwen ç­‰æ ¼å¼
                        elif "output" in chunk:
                            output = chunk["output"]
                            if "choices" in output and len(output["choices"]) > 0:
                                msg = output["choices"][0].get("message", {})
                                delta_text = msg.get("content", "")
                            elif "text" in output:
                                delta_text = output["text"]
                        
                        if delta_text:
                            full_content += delta_text
                    except json.JSONDecodeError:
                        continue
            
            # å¦‚æœæˆåŠŸè·å–å†…å®¹ï¼Œåˆ™è¿”å›
            if full_content:
                streaming_placeholder.empty()
                mock_response = {
                    "choices": [{"message": {"content": full_content}}],
                    "output": {"text": full_content}
                }
                return True, mock_response, ""
            else:
                error_msg = "æ¨¡å‹å“åº”æˆåŠŸä½†å†…å®¹ä¸ºç©º"

        except requests.exceptions.HTTPError:
            # raise_for_status è§¦å‘çš„é”™è¯¯åœ¨è¿™é‡Œè®°å½•æ—¥å¿—
            logger.warning(f"HTTP å¼‚å¸¸ (ç¬¬ {attempt+1} æ¬¡å°è¯•): {error_msg}")
            if "404" in error_msg or "401" in error_msg:
                # è·¯å¾„æˆ–é…ç½®é”™è¯¯ä¸é‡è¯•ï¼Œç›´æ¥æŠ¥é”™
                break
            time.sleep(2 ** attempt)
        except requests.exceptions.RequestException as e:
            # ç½‘ç»œè¿æ¥ã€è¶…æ—¶ç­‰å¼‚å¸¸
            error_msg = f"ç½‘ç»œè¿æ¥å¼‚å¸¸: {str(e)}"
            logger.warning(f"ç½‘ç»œå¼‚å¸¸ (ç¬¬ {attempt+1} æ¬¡å°è¯•): {error_msg}")
            time.sleep(2 ** attempt)
        except Exception as e:
            error_msg = f"æœªçŸ¥å†…éƒ¨é”™è¯¯: {str(e)}"
            logger.error(error_msg)
            break
    
    streaming_placeholder.empty()
    return False, {"error": error_msg}, error_msg

# ===============================
# è¯ç±»åˆ¤å®šä¸»å‡½æ•°
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str, str]:
    """è¯ç±»åˆ¤å®šæ ¸å¿ƒå‡½æ•°"""
    if not word:
        return {}, "", "æœªçŸ¥", ""

    full_rules_by_pos = {
        pos: "\n".join([f"- {r['name']}: {r['desc']}ï¼ˆç¬¦åˆ: {r['match_score']} åˆ†ï¼Œä¸ç¬¦åˆ: {r['mismatch_score']} åˆ†ï¼‰" for r in rules])
        for pos, rules in RULE_SETS.items()
    }

    system_msg = f"""ä½ æ˜¯ä¸€åä¸­æ–‡è¯æ³•ä¸è¯­æ³•æ–¹é¢çš„ä¸“å®¶ã€‚ç°åœ¨è¦åˆ†æè¯è¯­ã€Œ{word}ã€åœ¨ä¸‹åˆ—è¯ç±»ä¸­çš„è¡¨ç°ï¼š
- éœ€è¦åˆ¤æ–­çš„è¯ç±»ï¼šåè¯ã€åŠ¨è¯ã€ååŠ¨è¯
- è¯„åˆ†è§„åˆ™å·²ç»ç”±ç³»ç»Ÿå®šä¹‰ï¼Œä½ **ä¸è¦**è‡ªå·±è®¾è®¡åˆ†å€¼ï¼Œä¹Ÿ**ä¸è¦**åœ¨ JSON ä¸­ç»™å‡ºå…·ä½“æ•°å­—åˆ†æ•°ã€‚ç¨‹åºå°†æ ¹æ®ä½ çš„åˆ¤æ–­ï¼ˆtrue/falseï¼‰è‡ªåŠ¨èµ‹å€¼ã€‚
- ä½ åªéœ€è¦åˆ¤æ–­æ¯ä¸€æ¡è§„åˆ™æ˜¯â€œç¬¦åˆâ€è¿˜æ˜¯â€œä¸ç¬¦åˆâ€ã€‚

ã€å„è¯ç±»çš„è§„åˆ™è¯´æ˜ï¼ˆä»…ä¾›ä½ åˆ¤æ–­ä½¿ç”¨ï¼‰ã€‘
ã€åè¯ã€‘
{full_rules_by_pos["åè¯"]}

ã€åŠ¨è¯ã€‘
{full_rules_by_pos["åŠ¨è¯"]}

ã€ååŠ¨è¯ã€‘
{full_rules_by_pos["ååŠ¨è¯"]}

ã€è¾“å‡ºè¦æ±‚ã€‘
1. åœ¨ explanation å­—æ®µä¸­ï¼Œå¿…é¡»**é€æ¡è§„åˆ™**è¯´æ˜åˆ¤æ–­ä¾æ®ï¼Œå¹¶ä¸¾ä¾‹ï¼ˆå¯ä»¥è‡ªå·±é€ å¥ï¼‰ï¼š
   - æ ¼å¼ç¤ºä¾‹ï¼š
     - ã€Œåè¯-N1_å¯å—æ•°é‡è¯ä¿®é¥°ï¼šç¬¦åˆã€‚ç†ç”±ï¼šâ€¦â€¦ã€‚ä¾‹å¥ï¼šâ€¦â€¦ã€‚ã€
     - ã€ŒåŠ¨è¯-V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼šä¸ç¬¦åˆã€‚ç†ç”±ï¼šâ€¦â€¦ã€‚ä¾‹å¥ï¼šâ€¦â€¦ã€‚ã€
   - explanation é‡Œè¦è¦†ç›– **ä¸‰ä¸ªè¯ç±»çš„æ‰€æœ‰è§„åˆ™**ï¼Œä¸èƒ½åªå†™å‡ æ¡ã€‚

2. åœ¨ JSON ä¸­çš„ scores å­—æ®µé‡Œï¼š
   - æ¯ä¸€ç±»ä¸‹çš„æ¯ä¸€æ¡è§„åˆ™ï¼Œåªèƒ½ç»™å‡º **å¸ƒå°”å€¼ true / false**ï¼Œè¡¨ç¤ºæ˜¯å¦ç¬¦åˆè¯¥è§„åˆ™
   - ä¸¥ç¦åœ¨ scores é‡Œä½¿ç”¨æ•°å€¼åˆ†æ•°ï¼ˆä¾‹å¦‚ 0, 5, 10 ç­‰ï¼‰
   - å¦‚æœä½ ä¸ç¡®å®šï¼Œä¹Ÿå¿…é¡»åšå‡ºåˆ¤æ–­ï¼ˆtrue æˆ– falseï¼‰ï¼Œä¸è¦ç”¨ nullã€0 æˆ–å…¶å®ƒå€¼
   - JSON ç»“æ„å¿…é¡»æ˜¯ï¼š{{"explanation": "...", "predicted_pos": "...", "scores": {{"åè¯": {{...}}, "åŠ¨è¯": {{...}}, "ååŠ¨è¯": {{...}}}}}}

3. predicted_posï¼š
   - è¯·é€‰æ‹©ã€Œåè¯ã€ã€ŒåŠ¨è¯ã€ã€ŒååŠ¨è¯ã€ä¹‹ä¸€ï¼Œä½œä¸ºè¯¥è¯è¯­æœ€å…¸å‹çš„è¯ç±»ã€‚

4. **æœ€åè¾“å‡ºæ—¶ï¼Œå…ˆå†™è¯¦ç»†çš„æ–‡å­—æ¨ç†ï¼Œæœ€åå•ç‹¬ä¸”å®Œæ•´åœ°ç»™å‡ºä¸€æ®µåˆæ³•çš„ JSONï¼ˆä¸è¦å†åŠ æ³¨é‡Šï¼‰ã€‚**
"""

    user_prompt = f"""
è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚åˆ†æè¯è¯­ã€Œ{word}ã€ã€‚
ç‰¹åˆ«æ³¨æ„ï¼š
- åœ¨ JSON çš„ scores éƒ¨åˆ†ï¼Œåªèƒ½ç”¨ true/false è¡¨ç¤ºâ€œæ˜¯å¦ç¬¦åˆè§„åˆ™â€ï¼Œä¸èƒ½ä½¿ç”¨ä»»ä½•æ•°å­—ã€‚
- explanation ä¸­å¿…é¡»å¯¹æ¯ä¸€æ¡è§„åˆ™å†™æ˜â€œç¬¦åˆ/ä¸ç¬¦åˆ + ç†ç”± + ä¾‹å¥â€ã€‚

è¯·å…ˆç»™å‡ºè¯¦ç»†æ¨ç†è¿‡ç¨‹ï¼Œç„¶ååœ¨æœ€åå•ç‹¬è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ã€‚
"""

    with st.spinner(f"æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹ ({model}) è¿›è¡Œåˆ†æï¼Œè¯·ç¨å€™..."):
        ok, resp_json, err_msg = call_llm_api_cached(
            _provider=provider,
            _model=model,
            _api_key=api_key,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt}
            ]
        )

    if not ok:
        st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {err_msg}")
        logger.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥ - è¯è¯­:{word}, é”™è¯¯:{err_msg}")
        return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {err_msg}"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, cleaned_json_text = extract_json_from_text(raw_text)

    if parsed_json and isinstance(parsed_json, dict):
        explanation = parsed_json.get("explanation", "æ¨¡å‹æœªæä¾›è¯¦ç»†æ¨ç†è¿‡ç¨‹ã€‚")
        predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
        raw_scores = parsed_json.get("scores", {})
        if predicted_pos not in RULE_SETS:
             st.warning(f"æ¨¡å‹é¢„æµ‹çš„è¯ç±» '{predicted_pos}' ä¸åœ¨åˆ†æèŒƒå›´å†… ('åè¯', 'åŠ¨è¯', 'ååŠ¨è¯')ã€‚")
    else:
        st.error("âŒ æœªèƒ½ä»æ¨¡å‹å“åº”ä¸­è§£æå‡ºæœ‰æ•ˆçš„JSONã€‚è¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚")
        explanation = "æ— æ³•è§£ææ¨¡å‹è¾“å‡ºã€‚åŸå§‹å“åº”ï¼š\n" + raw_text
        predicted_pos = "æœªçŸ¥"
        raw_scores = {}
        cleaned_json_text = raw_text

    scores_out = {pos: {} for pos in RULE_SETS.keys()}
    try:
        for pos, rules in RULE_SETS.items():
            raw_pos_scores = raw_scores.get(pos, {})
            if isinstance(raw_pos_scores, dict):
                for k, v in raw_pos_scores.items():
                    normalized_key = normalize_key(k, rules)
                    if normalized_key:
                        rule_def = next(r for r in rules if r["name"] == normalized_key)
                        scores_out[pos][normalized_key] = map_to_allowed_score(rule_def, v)

        # è¡¥å…¨ç¼ºå¤±çš„è§„åˆ™å¾—åˆ†
        for pos, rules in RULE_SETS.items():
            for rule in rules:
                rule_name = rule["name"]
                if rule_name not in scores_out[pos]:
                    scores_out[pos][rule_name] = 0
    except Exception as e:
        logger.error(f"å¤„ç†å¾—åˆ†å¤±è´¥: {e}")
        scores_out = {}

    return scores_out, raw_text, predicted_pos, explanation

# ===============================
# é›·è¾¾å›¾ç»˜åˆ¶å‡½æ•°
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    """ç»˜åˆ¶è¯ç±»éš¶å±åº¦é›·è¾¾å›¾"""
    if not scores_norm:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return
    
    categories = list(scores_norm.keys())
    if not categories:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆè¯ç±»ã€‚")
        return
        
    values = list(scores_norm.values())
    categories += [categories[0]]
    values += [values[0]]
    
    min_val = min(values)
    max_val = max(values)
    axis_min = min(min_val, -0.1) 
    axis_max = max(max_val, 1.0)
    
    fig = go.Figure(data=[
        go.Scatterpolar(
            r=values, 
            theta=categories, 
            fill="toself", 
            name="éš¶å±åº¦",
            hovertemplate = '<b>%{theta}</b><br>éš¶å±åº¦: %{r:.4f}<extra></extra>'
        )
    ])
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True, 
                range=[axis_min, axis_max],
                tickvals=[0, 0.25, 0.5, 0.75, 1.0] if axis_min >= 0 else [-1.0, -0.5, 0, 0.5, 1.0]
            )
        ),
        showlegend=False,
        title=dict(text=title, x=0.5, font=dict(size=16))
    )
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# å¢å¼ºå‹æ‰¹é‡å¤„ç†ï¼ˆæ ¸å¿ƒä¿®å¤ä¸­æ–­ï¼‰
# ===============================
def process_and_style_excel(df, selected_model_info, target_col_name, metric_placeholder, backup_file):
    """æ‰¹é‡å¤„ç†Excelå¹¶å®æ—¶æ›´æ–°æ•°æ®é‡ï¼Œå¢å¼ºé²æ£’æ€§"""
    output = io.BytesIO()
    if 'processed_history' not in st.session_state:
        st.session_state.processed_history = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    backup_info_placeholder = st.container()
    total = len(df)
    file_name = f"excel_{int(time.time())}"  # å”¯ä¸€æ ‡è¯†å½“å‰æ–‡ä»¶
    
    # åŠ è½½ä¸Šæ¬¡è¿›åº¦
    last_progress = load_process_progress()
    start_row = 0
    if last_progress and last_progress.get("file_name") == file_name:
        start_row = last_progress.get("current_row", 0)
        st.info(f"ğŸ“Œ æ£€æµ‹åˆ°ä¸Šæ¬¡æœªå®Œæˆçš„ä»»åŠ¡ï¼Œä»ç¬¬ {start_row+1} è¡Œç»§ç»­å¤„ç†")
    
    try:
        for index in range(start_row, total):
            row = df.iloc[index]
            word = str(row[target_col_name]).strip()
            
            # ä¿å­˜å½“å‰è¿›åº¦
            save_process_progress(file_name, index, total)
            
            # å•æ¡æ•°æ®å¼‚å¸¸æ•è·ï¼ˆæ ¸å¿ƒï¼šé¿å…å•æ¡å¤±è´¥ä¸­æ–­æ•´ä½“ï¼‰
            try:
                max_retries = 3
                success = False
                scores_all, raw_text, predicted_pos, explanation = {}, "", "è¯·æ±‚å¤±è´¥", ""
                
                for attempt in range(max_retries):
                    try:
                        status_text.text(f"æ­£åœ¨å¤„ç† ({index + 1}/{total}): {word} ... (å°è¯• {attempt + 1})")
                        scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
                            word=word,
                            provider=selected_model_info["provider"],
                            model=selected_model_info["model"],
                            api_key=selected_model_info["api_key"]
                        )
                        if scores_all:
                            success = True
                            break
                        time.sleep(2)
                    except Exception as e:
                        logger.error(f"å¤„ç†è¯è¯­{word}å¤±è´¥ï¼ˆå°è¯•{attempt+1}ï¼‰: {e}")
                        time.sleep(2)
                
                # æ„é€ æ•°æ®è¡Œ
                membership = calculate_membership(scores_all) if success else {}
                new_row = {
                    "åºæ•°": index + 1,
                    "è¯è¯­": word,
                    "åŠ¨è¯": membership.get("åŠ¨è¯", 0.0),
                    "åè¯": membership.get("åè¯", 0.0),
                    "ååŠ¨è¯": membership.get("ååŠ¨è¯", 0.0),
                    "å·®å€¼/è·ç¦»": round(abs(membership.get("åŠ¨è¯", 0.0) - membership.get("åè¯", 0.0)), 4),
                    "é¢„æµ‹è¯ç±»": predicted_pos,
                    "åŸå§‹å“åº”": raw_text if success else f"é”™è¯¯: {explanation}",
                    "æ—¶é—´æˆ³": time.strftime("%Y-%m-%d %H:%M:%S")
                }
                
                # ä¿å­˜åˆ°SessionState
                st.session_state.processed_history.append(new_row)
                
                # å®‰å…¨å†™å…¥CSVå¹¶å®æ—¶æ›´æ–°æ•°æ®é‡
                try:
                    temp_df = pd.DataFrame([new_row])
                    header_needed = not os.path.exists(backup_file)
                    write_success = safe_write_csv(temp_df, backup_file, mode='a', header=header_needed)
                    if write_success:
                        # å®æ—¶æ›´æ–°å·²å­˜æ•°æ®é‡
                        latest_count = get_history_count(backup_file)
                        metric_placeholder.metric("å·²å­˜æ•°æ®é‡", f"{latest_count} æ¡")
                    else:
                        st.error(f"âš ï¸ ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•å¤±è´¥ï¼ˆæ–‡ä»¶å†™å…¥é”™è¯¯ï¼‰")
                except Exception as csv_err:
                    st.error(f"ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•å¤±è´¥: {csv_err}")
                    logger.error(f"ä¿å­˜CSVå¤±è´¥ - è¡Œå·:{index+1}, é”™è¯¯:{csv_err}")

                with backup_info_placeholder:
                    st.info(f"ğŸ’¾ å·²è‡ªåŠ¨ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•ã€‚å¦‚é‡ä¸­æ–­ï¼Œä¸‹æ¬¡å°†ä»ç¬¬ {index+2} è¡Œç»§ç»­")

                progress_bar.progress((index + 1) / total)
                time.sleep(0.5)  # é™æµï¼šé¿å…è¯·æ±‚è¿‡å¿«è¢«å°ç¦
                
            except Exception as row_err:
                logger.error(f"å¤„ç†ç¬¬{index+1}è¡Œå¤±è´¥ï¼ˆè·³è¿‡ï¼‰: {row_err}")
                st.warning(f"âš ï¸ è·³è¿‡ç¬¬ {index+1} è¡Œï¼ˆå¤„ç†å¤±è´¥ï¼‰: {row_err}")
                progress_bar.progress((index + 1) / total)
                continue

    except Exception as e:
        st.error(f"âš ï¸ æ‰¹é‡å¤„ç†æ„å¤–ä¸­æ–­: {e}")
        logger.error(f"æ‰¹é‡å¤„ç†ä¸­æ–­: {e}")
        return None
    finally:
        # å¤„ç†å®Œæˆ/ä¸­æ–­åæ¸…é™¤è¿›åº¦æ–‡ä»¶
        clear_process_progress()
    
    # å¯¼å‡ºExcel
    final_data = st.session_state.processed_history
    if not final_data:
        return None

    result_df = pd.DataFrame(final_data)
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            cols = ["è¯è¯­", "åŠ¨è¯", "åè¯", "ååŠ¨è¯", "å·®å€¼/è·ç¦»", "é¢„æµ‹è¯ç±»", "åŸå§‹å“åº”"]
            result_df[cols].to_excel(writer, index=False, sheet_name='åˆ†æç»“æœ')
            
            workbook = writer.book
            worksheet = writer.sheets['åˆ†æç»“æœ']
            yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
            
            for i, data_row in enumerate(final_data):
                row_num = i + 2
                pred = data_row["é¢„æµ‹è¯ç±»"]
                target_idx = {"åŠ¨è¯": 2, "åè¯": 3, "ååŠ¨è¯": 4}.get(pred)
                if target_idx:
                    worksheet.cell(row=row_num, column=target_idx).fill = yellow_fill
                    
        return output.getvalue()
    except Exception as e:
        st.error(f"Excel ç”Ÿæˆå¤±è´¥: {e}")
        logger.error(f"ç”ŸæˆExcelå¤±è´¥: {e}")
        return None

# ===============================
# ä¸»é¡µé¢é€»è¾‘
# ===============================
def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»")
    
    # é¡¶éƒ¨æ§åˆ¶åŒº
    control_container = st.container()
    with control_container:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.subheader("âš™ï¸ æ¨¡å‹è®¾ç½®")
            if not AVAILABLE_MODEL_OPTIONS:
                st.error("âŒ æ‰¾ä¸åˆ°å¯ç”¨çš„ API Keyï¼è¯·è®¾ç½®ä»¥ä¸‹ä»»æ„ä¸€ä¸ªç¯å¢ƒå˜é‡æ¥å¯ç”¨æ¨¡å‹:")
                for name, info in MODEL_OPTIONS.items():
                      st.code(f"export {info['env_var']}='ä½ çš„API Key'", language="bash")
                selected_model_display_name = list(MODEL_OPTIONS.keys())[0]
                selected_model_info = MODEL_OPTIONS[selected_model_display_name]
                st.selectbox("é€‰æ‹©å¤§æ¨¡å‹ (ä¸å¯ç”¨)", list(MODEL_OPTIONS.keys()), disabled=True)
            else:
                selected_model_display_name = st.selectbox(
                    "é€‰æ‹©å¤§æ¨¡å‹", 
                    list(AVAILABLE_MODEL_OPTIONS.keys()), 
                    key="model_select"
                )
                selected_model_info = AVAILABLE_MODEL_OPTIONS[selected_model_display_name]
                
        with col2:
            st.subheader("ğŸ”— è¿æ¥æµ‹è¯•")
            st.write("")
            if not selected_model_info["api_key"]:
                st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥ (ä¸å¯ç”¨)", type="secondary", disabled=True)
            else:
                if st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary"):
                    with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                        ok, _, err_msg = call_llm_api_cached(
                            _provider=selected_model_info["provider"],
                            _model=selected_model_info["model"],
                            _api_key=selected_model_info["api_key"],
                            messages=[{"role": "user", "content": "è¯·å›å¤'pong'"}],
                            max_tokens=10
                        )
                    if ok:
                        st.success("âœ… æˆåŠŸï¼")
                    else:
                        st.error(f"âŒ å¤±è´¥: {err_msg}")

    st.markdown("---")

    # åˆ†é¡µ
    tab1, tab2 = st.tabs(["ğŸ” å•ä¸ªè¯è¯­è¯¦ç»†åˆ†æ", "ğŸ“‚ Excel æ‰¹é‡å¤„ç†"])

    # å•ä¸ªè¯è¯­åˆ†æ
    with tab1:
        st.subheader("ğŸ”¤ è¯è¯­è¾“å…¥")
        word = st.text_input("è¯·è¾“å…¥è¦åˆ†æçš„æ±‰è¯­è¯è¯­", placeholder="ä¾‹å¦‚ï¼šè‹¹æœã€è·‘ã€ç¾ä¸½...", key="word_input")
        analyze_button = st.button(
            "ğŸš€ å¼€å§‹åˆ†æ", 
            type="primary",
            disabled=not (selected_model_info["api_key"] and word)
        )

        with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜", expanded=False):
            st.info("""
            1. **é…ç½® API Key**: è¯·åœ¨è¿è¡Œç¨‹åºå‰è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ã€‚
            2. **è¯è¯­è¾“å…¥**ï¼šåœ¨ä¸Šæ–¹çš„â€œè¯è¯­è¾“å…¥â€æ¡†ä¸­è¾“å…¥ä¸€ä¸ªæ±‰è¯­è¯ã€‚
            3. **å¼€å§‹åˆ†æ**ï¼šç‚¹å‡»â€œå¼€å§‹åˆ†æâ€æŒ‰é’®ã€‚
            4. **ç»“æœè§£æ**ï¼šç³»ç»Ÿå°†æ˜¾ç¤ºéš¶å±åº¦ã€é›·è¾¾å›¾å’Œè¯¦ç»†è§„åˆ™å¾—åˆ†ã€‚
            """)

        if analyze_button and word and selected_model_info["api_key"]:
            status_placeholder = st.empty()
            status_placeholder.info(f"æ­£åœ¨ä¸ºè¯è¯­ã€Œ{word}ã€å¯åŠ¨åˆ†æï¼Œä½¿ç”¨æ¨¡å‹ï¼š{selected_model_display_name}...")

            scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
                word=word,
                provider=selected_model_info["provider"],
                model=selected_model_info["model"],
                api_key=selected_model_info["api_key"]
            )
            
            status_placeholder.empty()
            
            if scores_all:
                membership = calculate_membership(scores_all)
                final_membership = membership.get(predicted_pos, 0)
                st.success(f'**åˆ†æå®Œæˆ**ï¼šè¯è¯­ã€Œ{word}ã€æœ€å¯èƒ½çš„è¯ç±»æ˜¯ **ã€{predicted_pos}ã€‘**ï¼Œéš¶å±åº¦ä¸º **{final_membership:.4f}**')
                
                col_results_1, col_results_2 = st.columns(2)
                
                with col_results_1:
                    st.subheader("ğŸ† è¯ç±»éš¶å±åº¦æ’å")
                    top10 = get_top_10_positions(membership)
                    top10_df = pd.DataFrame(top10, columns=["è¯ç±»", "éš¶å±åº¦"])
                    top10_df["éš¶å±åº¦"] = top10_df["éš¶å±åº¦"].apply(lambda x: f"{x:.4f}")
                    st.table(top10_df)
                    
                    st.subheader("ğŸ“Š è¯ç±»éš¶å±åº¦é›·è¾¾å›¾")
                    plot_radar_chart_streamlit(dict(top10), f"ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦åˆ†å¸ƒ")

                with col_results_2:
                    st.subheader("ğŸ“‹ å„è¯ç±»è¯¦ç»†å¾—åˆ†")
                    pos_total_scores = {pos: sum(scores_all[pos].values()) for pos in scores_all.keys()}
                    sorted_pos_names = sorted(pos_total_scores.keys(), key=lambda pos: pos_total_scores[pos], reverse=True)
                    
                    for pos in sorted_pos_names:
                        total_score = pos_total_scores[pos]
                        max_rule = max(scores_all[pos].items(), key=lambda x: x[1], default=("æ— ", 0))
                        with st.expander(f"**{pos}** (æ€»åˆ†: {total_score}, æœ€é«˜åˆ†è§„åˆ™: {max_rule[0]} - {max_rule[1]}åˆ†)"):
                            rule_data = []
                            for rule_name, rule_score in scores_all[pos].items():
                                rule_desc = ""
                                if pos in RULE_SETS:
                                    for rule in RULE_SETS[pos]:
                                        if rule["name"] == rule_name:
                                            rule_desc = rule["desc"]
                                            break
                                rule_data.append({
                                    "è§„åˆ™ä»£ç ": rule_name,
                                    "è§„åˆ™æè¿°": rule_desc,
                                    "å¾—åˆ†": rule_score
                                })
                            rule_data_sorted = sorted(rule_data, key=lambda x: x["å¾—åˆ†"], reverse=True)
                            rule_df = pd.DataFrame(rule_data_sorted)
                            styled_df = rule_df.style.applymap(
                                lambda x: "color: #ff4b4b; font-weight: bold" if isinstance(x, int) and x < 0 else "",
                                subset=["å¾—åˆ†"]
                            )
                            st.dataframe(
                                styled_df,
                                use_container_width=True,
                                height=min(len(rule_df) * 30 + 50, 400)
                            )
                    
                    st.subheader("ğŸ“¥ æ¨¡å‹åŸå§‹å“åº”")
                    with st.expander("ç‚¹å‡»å±•å¼€æŸ¥çœ‹åŸå§‹å“åº”", expanded=False):
                        st.code(raw_text, language="text")

    # æ‰¹é‡å¤„ç†
    with tab2:
        st.header("ğŸ“‚ æ‰¹é‡ä»»åŠ¡å®æ—¶ç›‘æ§")

        # æ§åˆ¶é¢æ¿
        st.subheader("ğŸ› ï¸ æ§åˆ¶é¢æ¿")
        ctrl_col1, ctrl_col2, ctrl_col3 = st.columns([2, 1, 1])
        
        with ctrl_col1:
            # å¯å®æ—¶æ›´æ–°çš„metricå ä½ç¬¦
            metric_placeholder = st.empty()
            # åˆå§‹åŒ–æ˜¾ç¤ºæœ€æ–°æ•°é‡
            history_count = get_history_count(BACKUP_FILE)
            metric_placeholder.metric("å·²å­˜æ•°æ®é‡", f"{history_count} æ¡")
            
            has_history = os.path.exists(BACKUP_FILE)
            if has_history:
                st.caption(f"å­˜å‚¨ä½ç½®: `{BACKUP_FILE}`")
        
        with ctrl_col2:
            if os.path.exists(BACKUP_FILE):
                with open(BACKUP_FILE, "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å†å²æ–‡ä»¶(CSV)",
                        data=f,
                        file_name=f"batch_results_{time.strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
            else:
                st.button("ğŸ“¥ ä¸‹è½½å†å²æ–‡ä»¶", disabled=True, use_container_width=True)

        with ctrl_col3:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæœ¬åœ°è®°å½•", use_container_width=True, type="secondary"):
                if os.path.exists(BACKUP_FILE):
                    try:
                        os.remove(BACKUP_FILE)
                        clear_process_progress()  # åŒæ—¶æ¸…é™¤è¿›åº¦
                        st.success("âœ… å·²æ¸…ç©ºæœ¬åœ°è®°å½•å’Œè¿›åº¦")
                        metric_placeholder.metric("å·²å­˜æ•°æ®é‡", "0 æ¡")
                        st.rerun()
                    except Exception as e:
                        st.error(f"æ¸…ç©ºè®°å½•å¤±è´¥: {e}")
                else:
                    st.info("ğŸ“„ æš‚æ— æœ¬åœ°è®°å½•å¯æ¸…ç©º")

        st.divider()

        # è¿è¡ŒçŠ¶æ€
        st.subheader("ğŸ“ˆ è¿è¡ŒçŠ¶æ€")
        progress_bar = st.progress(0)
        status_info = st.empty()
        
        # å®æ—¶ç»“æœé¢„è§ˆ
        st.subheader("ğŸ“‹ å®æ—¶ç»“æœé¢„è§ˆ")
        table_placeholder = st.empty()
        if os.path.exists(BACKUP_FILE):
            try:
                table_placeholder.dataframe(
                    pd.read_csv(BACKUP_FILE, encoding='utf-8-sig'), 
                    use_container_width=True, 
                    height=300
                )
            except Exception as e:
                table_placeholder.error(f"æ˜¾ç¤ºå†å²è®°å½•å¤±è´¥: {e}")
        else:
            table_placeholder.info("æš‚æ— æ•°æ®ã€‚ä¸Šä¼ æ–‡ä»¶å¹¶ç‚¹å‡»å¼€å§‹åï¼Œç»“æœå°†åœ¨æ­¤é€è¡Œå®æ—¶æ˜¾ç¤ºã€‚")

        st.divider()

        # ä¸Šä¼ ä»»åŠ¡
        st.subheader("ğŸ“¤ ä¸Šä¼ æ–°ä»»åŠ¡")
        uploaded_file = st.file_uploader("é€‰æ‹© Excel æ–‡ä»¶", type=["xlsx", "xls"])
        
        if uploaded_file:
            try:
                df_input = pd.read_excel(uploaded_file)
                target_col = next((col for col in df_input.columns if "è¯" in str(col) or "word" in str(col).lower()), None)
                
                if target_col:
                    st.write(f"âœ… è¯†åˆ«åˆ°ç›®æ ‡åˆ—: `{target_col}` | å¾…åˆ†ææ€»æ•°: {len(df_input)}")
                    
                    if st.button("ğŸš€ å¼€å§‹å¤„ç† (æ–­ç‚¹ç»­ä¼ )", type="primary", use_container_width=True):
                        if not selected_model_info["api_key"]:
                            st.error("âŒ è¯·å…ˆåœ¨ä¸Šæ–¹é…ç½®æœ‰æ•ˆçš„ API Key")
                        else:
                            # è·å–å·²å¤„ç†çš„è¯è¯­
                            existing_words = set()
                            if os.path.exists(BACKUP_FILE):
                                try:
                                    existing_df = pd.read_csv(BACKUP_FILE, encoding='utf-8-sig')
                                    if "è¯è¯­" in existing_df.columns:
                                        existing_words = set(existing_df["è¯è¯­"].astype(str).tolist())
                                    st.info(f"â„¹ï¸ å·²è·³è¿‡ {len(existing_words)} æ¡å·²å¤„ç†è®°å½•")
                                except Exception as e:
                                    st.warning(f"è¯»å–å·²å¤„ç†è®°å½•å¤±è´¥ï¼Œå°†é‡æ–°å¤„ç†æ‰€æœ‰æ•°æ®: {e}")

                            total_rows = len(df_input)
                            
                            # æ‰¹é‡å¤„ç†ä¸»å¾ªç¯ï¼ˆå…¨é‡å¼‚å¸¸æ•è·ï¼‰
                            try:
                                for index, row in df_input.iterrows():
                                    word = str(row[target_col]).strip()
                                    if not word:
                                        status_info.write(f"â© **è·³è¿‡ç©ºå€¼**: ç¬¬ {index+1}/{total_rows} è¡Œ")
                                        progress_bar.progress((index + 1) / total_rows)
                                        continue
                                    
                                    pct = int((index + 1) / total_rows * 100)
                                    progress_bar.progress((index + 1) / total_rows)
                                    
                                    if word in existing_words:
                                        status_info.write(f"â© **è·³è¿‡å·²å¤„ç†**: {word} ({index+1}/{total_rows}) | è¿›åº¦: {pct}%")
                                        continue
                                    
                                    status_info.write(f"ğŸ” **æ­£åœ¨åˆ†æ**: `{word}` | è¿›åº¦: {index+1}/{total_rows} ({pct}%)")
                                    
                                    # è°ƒç”¨APIå¤„ç†ï¼ˆå¢å¼ºé‡è¯•ï¼‰
                                    max_retries = 3
                                    success = False
                                    scores, raw_text, pred_pos, explanation = {}, "", "å¤„ç†å¤±è´¥", "æ— å“åº”"
                                    for attempt in range(max_retries):
                                        try:
                                            scores, raw_text, pred_pos, explanation = ask_model_for_pos_and_scores(
                                                word=word,
                                                provider=selected_model_info["provider"],
                                                model=selected_model_info["model"],
                                                api_key=selected_model_info["api_key"]
                                            )
                                            success = bool(scores)
                                            if success:
                                                break
                                            time.sleep(2)
                                        except Exception as e:
                                            explanation = f"è°ƒç”¨å¼‚å¸¸: {str(e)}"
                                            logger.error(f"å¤„ç†è¯è¯­{word}å¤±è´¥ï¼ˆå°è¯•{attempt+1}ï¼‰: {e}")
                                            time.sleep(2)
                                    
                                    # æ„é€ æ•°æ®è¡Œ
                                    membership = calculate_membership(scores) if success else {}
                                    new_row = {
                                        "åºæ•°": index + 1,
                                        "è¯è¯­": word,
                                        "åŠ¨è¯": membership.get("åŠ¨è¯", 0.0),
                                        "åè¯": membership.get("åè¯", 0.0),
                                        "ååŠ¨è¯": membership.get("ååŠ¨è¯", 0.0),
                                        "å·®å€¼/è·ç¦»": round(abs(membership.get("åŠ¨è¯", 0.0) - membership.get("åè¯", 0.0)), 4),
                                        "é¢„æµ‹è¯ç±»": pred_pos,
                                        "åŸå§‹å“åº”": raw_text if success else f"é”™è¯¯: {explanation}",
                                        "æ—¶é—´æˆ³": time.strftime("%Y-%m-%d %H:%M:%S")
                                    }
                                    
                                    # å®‰å…¨ä¿å­˜æ•°æ®
                                    try:
                                        temp_df = pd.DataFrame([new_row])
                                        header_needed = not os.path.exists(BACKUP_FILE)
                                        write_success = safe_write_csv(temp_df, BACKUP_FILE, mode='a', header=header_needed)
                                        if write_success:
                                            existing_words.add(word)
                                            # å®æ—¶æ›´æ–°å·²å­˜æ•°æ®é‡
                                            latest_count = get_history_count(BACKUP_FILE)
                                            metric_placeholder.metric("å·²å­˜æ•°æ®é‡", f"{latest_count} æ¡")
                                        else:
                                            st.error(f"âš ï¸ ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•å¤±è´¥ï¼ˆæ–‡ä»¶å†™å…¥é”™è¯¯ï¼‰")
                                    except Exception as csv_err:
                                        st.error(f"âš ï¸ ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•å¤±è´¥: {csv_err}")
                                        logger.error(f"ä¿å­˜CSVå¤±è´¥ - è¡Œå·:{index+1}, é”™è¯¯:{csv_err}")
                                    
                                    # åˆ·æ–°è¡¨æ ¼
                                    try:
                                        updated_df = pd.read_csv(BACKUP_FILE, encoding='utf-8-sig')
                                        table_placeholder.dataframe(updated_df, use_container_width=True, height=300)
                                    except Exception as read_err:
                                        st.warning(f"åˆ·æ–°è¡¨æ ¼å¤±è´¥: {read_err}")
                                    
                                    time.sleep(0.5)  # é™æµ
                                
                                progress_bar.progress(100)
                                status_info.success(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼æ€»å¤„ç†é‡: {total_rows} æ¡ï¼Œå·²ä¿å­˜åˆ° {BACKUP_FILE}")
                                clear_process_progress()  # æ¸…é™¤è¿›åº¦
                                st.rerun()
                            except Exception as batch_err:
                                logger.error(f"æ‰¹é‡å¤„ç†ä¸»å¾ªç¯ä¸­æ–­: {batch_err}")
                                status_info.error(f"âš ï¸ æ‰¹é‡å¤„ç†ä¸­æ–­: {batch_err}ï¼Œä¸‹æ¬¡å¯ä»æ–­ç‚¹ç»§ç»­")
                else:
                    st.error("âŒ æœªè¯†åˆ«åˆ°åŒ…å«'è¯'æˆ–'word'çš„åˆ—ï¼Œè¯·æ£€æŸ¥Excelæ–‡ä»¶ç»“æ„")
            except Exception as e:
                st.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")
                logger.error(f"è¯»å–Excelå¤±è´¥: {e}")

# ===============================
# è¿è¡Œä¸»å‡½æ•°
# ===============================
if __name__ == "__main__":
    main()

# ===============================
# é¡µé¢åº•éƒ¨è¯´æ˜
# ===============================
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:#666;'>"
    "Â© 2025 æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»ï¼ˆé˜²ä¸­æ–­ç‰ˆï¼‰ "
    "</div>",
    unsafe_allow_html=True
)
