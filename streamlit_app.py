        {"name": "PART4_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½ä½œè°“è¯­å’Œè°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "PART5_ä¸èƒ½åšä¿®é¥°æ€§æˆåˆ†", "desc": "ä¸èƒ½åšçŠ¶è¯­ã€è¡¥è¯­å’Œå®šè¯­ç­‰ä¿®é¥°æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
    ],
    # 2.4 è¯­æ°”è¯
    "è¯­æ°”è¯": [
        {"name": "MOD1_ä¸èƒ½å•ç‹¬å›ç­”ï¼ˆé»ç€è¯ï¼‰", "desc": "ä¸èƒ½å•ç‹¬å›ç­”é—®é¢˜ï¼ˆé»ç€è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "MOD2_åªèƒ½é™„ç€åœ¨å…¶ä»–æˆåˆ†ä¹‹åï¼ˆå››ç§ç”¨æ³•ä¹‹ä¸€å¾—60ï¼‰", "desc": "åªèƒ½é™„ç€åœ¨å…¶ä»–æˆåˆ†ä¹‹åï¼ˆå¥æœ«/è¯é¢˜æ€§æˆåˆ†å/å¹¶åˆ—é¡¹å/å‡è®¾åˆ†å¥åï¼‰", "match_score": 60, "mismatch_score": -60},
        {"name": "MOD3_ä¸èƒ½ä½œä¸»å®¾/ä¸èƒ½å—å®šè¯­", "desc": "ä¸èƒ½ä½œä¸»è¯­å’Œå®¾è¯­ï¼Œä¸èƒ½å—å®šè¯­ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "MOD4_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½ä½œè°“è¯­å’Œè°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "MOD5_ä¸èƒ½ä½œä¿®é¥°æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ã€å®šè¯­å’Œè¡¥è¯­ç­‰ä¿®é¥°æˆåˆ†", "match_score": 10, "mismatch_score": -10},
    ],
    # 2.5 æ„Ÿå¹è¯
    "æ„Ÿå¹è¯": [
        {"name": "INT1_å¯å……å½“ç‹¬ç«‹æˆåˆ†ï¼ˆåœé¡¿ï¼‰", "desc": "å¯ä»¥å……å½“ç‹¬ç«‹æˆåˆ†ï¼ˆå‰åå¯æœ‰åœé¡¿ï¼‰", "match_score": 30, "mismatch_score": -30},
        {"name": "INT2_å¯ä»¥ç‹¬ç«‹æˆå¥ï¼ˆå‰åé•¿åœé¡¿ï¼‰", "desc": "å¯ä»¥ç‹¬ç«‹æˆå¥ï¼ˆå‰åéƒ½å¯æœ‰è¾ƒé•¿åœé¡¿ï¼‰", "match_score": 20, "mismatch_score": -20},
        {"name": "INT3_ä¸èƒ½è·Ÿå…¶ä»–å¥æ³•æˆåˆ†ç»„åˆæ„å¥æ³•ç»“æ„", "desc": "ä¸èƒ½ä¸å…¶ä»–å¥æ³•æˆåˆ†ç»„åˆæ„æˆä¸»è°“/è¿°è¡¥/å¹¶åˆ—ç­‰ç»“æ„", "match_score": 50, "mismatch_score": -50},
    ],
    # 2.6 æ‹Ÿå£°è¯
    "æ‹Ÿå£°è¯": [
        {"name": "ON1_å¯å……å½“ç‹¬ç«‹æˆåˆ†ï¼ˆåœé¡¿ï¼‰", "desc": "å¯ä»¥å……å½“ç‹¬ç«‹æˆåˆ†ï¼ˆå‰åå¯æœ‰åœé¡¿ï¼‰", "match_score": 20, "mismatch_score": -20},
        {"name": "ON2_å¯ä»¥ç‹¬ç«‹æˆå¥", "desc": "å¯ä»¥ç‹¬ç«‹æˆå¥", "match_score": 20, "mismatch_score": -20},
        {"name": "ON3_å¯ç›´æ¥æˆ–å¸¦'çš„'ä½œå®šè¯­", "desc": "å¯ä»¥ç›´æ¥æˆ–å¸¦'çš„'åä½œå®šè¯­ä¿®é¥°åè¯", "match_score": 20, "mismatch_score": 0},
        {"name": "ON4_å¯ç›´æ¥æˆ–å¸¦'åœ°'ä½œçŠ¶è¯­", "desc": "å¯ä»¥ç›´æ¥æˆ–åå¸¦'åœ°'ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯", "match_score": 20, "mismatch_score": 0},
        {"name": "ON5_ä¸èƒ½å……å½“ä¸»/å®¾/è°“/è¡¥ç­‰", "desc": "ä¸èƒ½å……å½“ä¸»è¯­ã€å®¾è¯­ã€è°“è¯­å’Œè¡¥è¯­ç­‰å¥æ³•æˆåˆ†", "match_score": 20, "mismatch_score": -20},
    ],
    # 3.1 ä½“ä»£è¯ï¼ˆä»£è¯ä¸æ•°é‡è¯éƒ¨åˆ†ç¤ºä¾‹ï¼‰
    "ä½“ä»£è¯": [
        {"name": "PR1_å¯ä½œå…¸å‹ä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": -20},
        {"name": "PR2_å¯åšå®šè¯­æˆ–è·Ÿ'çš„'æ„'çš„'å­—ç»“æ„", "desc": "å¯ä»¥åšå®šè¯­æˆ–è·ŸåŠ©è¯'çš„'æ„æˆ'çš„'å­—ç»“æ„", "match_score": 10, "mismatch_score": -10},
        {"name": "PR3_ä¸èƒ½å—æ•°é‡/å½¢å®¹è¯/'çš„'ä¿®é¥°", "desc": "ä¸èƒ½å—æ•°é‡è¯ã€å½¢å®¹è¯å’Œ'çš„'å­—ç»“æ„çš„ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "PR4_ä¸èƒ½å—'ä¸/å¾ˆ'ç­‰å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—'ä¸'å’Œ'å¾ˆ'ç­‰å‰¯è¯ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "PR5_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½ä½œè°“è¯­å’Œè°“è¯­æ ¸å¿ƒï¼ˆä¸èƒ½å¸¦å®¾è¯­/æ—¶ä½“åŠ©è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "PR6_ä¸èƒ½åšè¡¥è¯­æˆ–çŠ¶è¯­", "desc": "ä¸èƒ½åšè¡¥è¯­ï¼Œä¹Ÿä¸èƒ½ä½œçŠ¶è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "PR7_ä¸èƒ½åé™„å•éŸ³æ–¹ä½è¯æ„å¤„æ‰€", "desc": "ä¸èƒ½åé™„å•éŸ³æ–¹ä½è¯æ„å¤„æ‰€", "match_score": 20, "mismatch_score": -20},
    ],
    # 3.2 è°“ä»£è¯ï¼ˆç¤ºä¾‹ï¼‰
    "è°“ä»£è¯": [
        {"name": "WP1_å¯ä½œå…¸å‹ä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": -20},
        {"name": "WP2_å¯ä½œçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨/å½¢", "desc": "å¯ä»¥ä½œçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æˆ–å½¢å®¹è¯", "match_score": 20, "mismatch_score": -20},
        {"name": "WP3_ä¸èƒ½å—'å¾ˆ'ç­‰ç¨‹åº¦å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—'å¾ˆ'ç­‰ç¨‹åº¦å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "WP4_å¯å—'ä¸/ä¹Ÿ'ç­‰å‰¯è¯ä¿®é¥°", "desc": "å¯ä»¥å—'ä¸'æˆ–'ä¹Ÿ'ç­‰å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "WP5_å¯åšè°“è¯­æˆ–è°“è¯æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "WP6_ä¸èƒ½å¸¦å®¾è¯­å’Œè¡¥è¯­", "desc": "ä¸èƒ½å¸¦å®¾è¯­å’Œè¡¥è¯­", "match_score": 10, "mismatch_score": -10},
    ],
    # 3.3 ä»£è¯ï¼ˆé€šç”¨ä»£è¯æ¡ç›®ç¤ºä¾‹ï¼‰
    "ä»£è¯": [
        {"name": "DPR1_å¯ä½œå…¸å‹ä¸»å®¾è¯­", "desc": "å¯åšå…¸å‹ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": -20},
        {"name": "DPR2_ä¸èƒ½å—æ•°é‡/å½¢å®¹/çš„ä¿®é¥°", "desc": "ä¸èƒ½å—æ•°é‡è¯ã€å½¢å®¹è¯å’Œ'çš„'å­—ç»“æ„ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "DPR3_ä¸èƒ½å—ç¨‹åº¦å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—'å¾ˆ'ç­‰ç¨‹åº¦å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "DPR4_ä¸èƒ½å¸¦å®¾è¯­å’Œè¡¥è¯­", "desc": "ä¸èƒ½å¸¦å®¾è¯­å’Œè¡¥è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "DPR5_å¯å—'ä¸/ä¹Ÿ'ç­‰å‰¯è¯ä¿®é¥°ï¼ˆé’ˆå¯¹è°“ä»£ï¼‰æˆ–ä¸èƒ½åé™„æ–¹ä½ï¼ˆé’ˆå¯¹ä½“ä»£ï¼‰", "desc": "æ··åˆè§„åˆ™ï¼ŒæŒ‰å…·ä½“ä»£è¯ç±»å‹åˆ¤å®š", "match_score": 20, "mismatch_score": -20},
    ],
    # 3.4 ç³»æ•°è¯ã€ä½æ•°è¯ã€åˆæˆæ•°è¯ç­‰ï¼š
    "ç³»æ•°è¯": [
        {"name": "NUM_CO1_é»ç€è¯ä¸èƒ½å•ç‹¬å›ç­”", "desc": "ç³»æ•°è¯æ˜¯é»ç€è¯ä¸èƒ½å•ç‹¬å›ç­”", "match_score": 20, "mismatch_score": -20},
        {"name": "NUM_CO2_å¯åœ¨é‡è¯å‰æ„æ•°é‡è¯ç»„", "desc": "å¯ä»¥ç”¨åœ¨é‡è¯å‰ï¼Œä¸€èµ·æ„æˆæ•°é‡è¯ç»„", "match_score": 20, "mismatch_score": -20},
        {"name": "NUM_CO3_å¯æ„ç³»è°“æ„é€ ", "desc": "å¯ä»¥ç”¨åœ¨ä½æ•°è¯/æ„æˆåºæ•°ç»„åˆç­‰", "match_score": 20, "mismatch_score": 0},
        {"name": "NUM_CO4_å¯æ„åºæ•°ç»„åˆï¼ˆç¬¬...ï¼‰", "desc": "å¯ä»¥ç”¨åœ¨'ç¬¬'çš„åé¢æ„æˆåºæ•°ç»„åˆ", "match_score": 20, "mismatch_score": 0},
        {"name": "NUM_CO5_ä¸èƒ½ç›´æ¥ä¿®é¥°åè¯ï¼ˆé™¤éçœç•¥'ç¬¬'ï¼‰", "desc": "ä¸èƒ½ç›´æ¥ä¿®é¥°åè¯ï¼ˆé™¤éçœç•¥'ç¬¬'ï¼‰", "match_score": 20, "mismatch_score": 0},
    ],
    "ä½æ•°è¯": [
        {"name": "NUM_POS1_é»ç€è¯ä¸èƒ½å•ç‹¬å›ç­”", "desc": "ä½æ•°è¯æ˜¯é»ç€è¯ä¸èƒ½å•ç‹¬å›ç­”", "match_score": 20, "mismatch_score": -20},
        {"name": "NUM_POS2_ä¸èƒ½å•ç‹¬ç”¨åœ¨é‡è¯å‰", "desc": "ä¸èƒ½å•ç‹¬ç”¨åœ¨é‡è¯å‰", "match_score": 10, "mismatch_score": 0},
        {"name": "NUM_POS3_å¯åœ¨ç³»æ•°è¯åæ„æˆç³»ä½æ„é€ ", "desc": "å¯ä»¥ç”¨åœ¨ç³»æ•°è¯åæ„æˆç³»ä½æ„é€ ", "match_score": 20, "mismatch_score": -20},
        {"name": "NUM_POS4_ä¸èƒ½ç”¨äºå‰ç¼€'ç¬¬'åé¢æ„åºæ•°ç»„åˆ", "desc": "ä¸èƒ½ç”¨äºå‰ç¼€'ç¬¬'åé¢æ„åºæ•°ç»„åˆ", "match_score": 20, "mismatch_score": -20},
        {"name": "NUM_POS5_ä¸èƒ½ä½œå®šè¯­ç›´æ¥ä¿®é¥°åè¯", "desc": "ä¸èƒ½ä½œå®šè¯­ç›´æ¥ä¿®é¥°åè¯", "match_score": 20, "mismatch_score": 0},
        {"name": "NUM_POS6_å¯ç”¨åœ¨'æ¥/æŠŠ'ä¹‹å‰æ„æ•°æ¬¡ç»„åˆ", "desc": "å¯ä»¥ç”¨åœ¨åŠ©è¯'æ¥'æˆ–'æŠŠ'ä¹‹å‰æ„æˆæ•°æ¬¡ç»„åˆ", "match_score": 10, "mismatch_score": 0},
    ],
    "åˆæˆæ•°è¯": [
        {"name": "NUM_COM1_å¯ä»¥å•ç‹¬å›ç­”é—®é¢˜ï¼ˆéƒ¨åˆ†è‡ªç”±ï¼‰", "desc": "åˆæˆæ•°è¯å¯ä»¥ç”¨æ¥å•ç‹¬å›ç­”é—®é¢˜", "match_score": 10, "mismatch_score": 0},
        {"name": "NUM_COM2_å¯ä¸é‡è¯æ„æ•°é‡è¯ç»„", "desc": "å¯ä»¥ç”¨åœ¨é‡è¯å‰æ„æˆæ•°é‡è¯ç»„", "match_score": 20, "mismatch_score": -20},
        {"name": "NUM_COM3_å¯åœ¨'ç¬¬'åæ„åºæ•°ç»„åˆ", "desc": "å¯ä»¥ç”¨åœ¨'ç¬¬'åé€ æˆåºæ•°ç»„åˆ", "match_score": 20, "mismatch_score": -20},
        {"name": "NUM_COM4_ä¸èƒ½ç›´æ¥ä½œå®šè¯­ä¿®é¥°åè¯ï¼ˆé™¤éçœç¬¬ï¼‰", "desc": "ä¸èƒ½ç›´æ¥ä½œå®šè¯­ä¿®é¥°åè¯ï¼ˆé™¤éçœç•¥'ç¬¬'ï¼‰", "match_score": 20, "mismatch_score": 0},
        {"name": "NUM_COM5_å¯å‡ºç°åœ¨'æ¥/å¤š/ä½™'ä¹‹å‰ç­‰ç‰¹æ®Šåˆ†å¸ƒ", "desc": "å¯ä»¥å‡ºç°åœ¨ç‰¹å®šåŠ©è¯ä¹‹å‰ï¼ˆè§åŸæ–‡æ¡ç›®ï¼‰", "match_score": 30, "mismatch_score": 0},
    ],
    # å…¶ä»–è§„åˆ™å ä½ï¼ˆä¾¿äºä»¥åè¡¥å…¨ï¼‰
    # "æœªåˆ—å‡ºè¯ç±»": [ ... ],
}

MAX_SCORES = {pos: sum(abs(r["match_score"]) for r in rules) for pos, rules in RULE_SETS.items()}

# æ¨¡å‹é…ç½® - å‡è®¾APIåœ¨åå°éƒ¨ç½²ï¼Œæ— éœ€å‰ç«¯è¾“å…¥API Key
MODEL_OPTIONS = {
    "OpenAI": {"provider": "openai", "model": "gpt-3.5-turbo"},
    "DeepSeek": {"provider": "deepseek", "model": "deepseek-chat"},
    "Moonshot (Kimi)": {"provider": "moonshot", "model": "moonshot-v1-8k"},
    "è±†åŒ…": {"provider": "doubao", "model": "doubao-pro"},
    "é€šä¹‰åƒé—® (Qwen)": {"provider": "qwen", "model": "qwen-plus"},
}

# æ¨¡å‹è¯¦ç»†é…ç½® - é€‚é…åå°éƒ¨ç½²çš„API
MODEL_CONFIGS = {
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda api_key: {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
        "payload": lambda model, messages, max_tokens, temperature: {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
    },
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda api_key: {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
        "payload": lambda model, messages, max_tokens, temperature: {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda api_key: {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
        "payload": lambda model, messages, max_tokens, temperature: {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
    },
    "doubao": {
        "base_url": "https://api.doubao.com/chat",
        "endpoint": "/completions",
        "headers": lambda api_key: {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
        "payload": lambda model, messages, max_tokens, temperature: {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
    },
    "qwen": {
        "base_url": "https://api.qwen.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda api_key: {"Content-Type": "application/json", "Authorization": f"Bearer {api_key}"},
        "payload": lambda model, messages, max_tokens, temperature: {
            "model": model,
            "messages": messages,
            "max_tokens": max_tokens,
            "temperature": temperature
        }
    }
}

# ===============================
# å·¥å…·å‡½æ•°
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    if not isinstance(resp_json, dict):
        return ""
    try:
        choices = resp_json.get("choices")
        if choices and isinstance(choices, list) and len(choices) > 0:
            first = choices[0]
            msg = first.get("message")
            if isinstance(msg, dict) and "content" in msg:
                return msg["content"]
            for k in ("content", "text", "message"):
                if k in first and isinstance(first[k], str):
                    return first[k]
    except:
        pass
    return json.dumps(resp_json, ensure_ascii=False)

def extract_json_from_text(text: str) -> Tuple[dict, str]:
    if not text:
        return None, ""
    s = text.strip()
    try:
        return json.loads(s), s
    except:
        m = re.search(r"(\{[\s\S]*\})", s)
        if not m:
            return None, s
        cand = m.group(1)
        c = cand.replace("ï¼š", ":").replace("ï¼Œ", ",").replace("â€œ", '"').replace("â€", '"')
        c = re.sub(r"'(\s*[^']+?\s*)'\s*:", r'"\1":', c)
        c = re.sub(r":\s*'([^']*?)'", r': "\1"', c)
        c = re.sub(r",\s*([}\]])", r"\1", c)
        c = re.sub(r"\bTrue\b", "true", c)
        c = re.sub(r"\bFalse\b", "false", c)
        c = re.sub(r"\bNone\b", "null", c)
        try:
            return json.loads(c), c
        except:
            return None, s

def normalize_key(k: str, pos_rules: list) -> str:
    if not isinstance(k, str):
        return None
    kk = re.sub(r'\s+', '', k).upper()
    for r in pos_rules:
        if r["name"].upper() == kk or re.sub(r'\s+', '', r["name"]).upper() == kk:
            return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    match = rule["match_score"]
    mismatch = rule["mismatch_score"]
    if isinstance(raw_val, (int, float)):
        cand = [match, mismatch]
        return min(cand, key=lambda x: abs(x - float(raw_val)))
    if isinstance(raw_val, bool):
        return match if raw_val else mismatch
    if isinstance(raw_val, str):
        s = raw_val.strip().lower()
        if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"):
            return match
        if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"):
            return mismatch
    return mismatch

# ===============================
# å®‰å…¨çš„ LLM è°ƒç”¨å‡½æ•°
# ===============================
def call_llm_api(messages: list, provider: str, model: str,
                 max_tokens: int = 1024, temperature: float = 0.0, timeout: int = 30) -> Tuple[bool, dict, str]:
    """
    è°ƒç”¨æŒ‡å®š LLM API è·å–å“åº”ï¼ˆå‡è®¾APIåœ¨åå°éƒ¨ç½²ï¼Œæ— éœ€å‰ç«¯API Keyï¼‰
    è¿”å›: (æˆåŠŸæ ‡å¿—, å“åº” dict, é”™è¯¯ä¿¡æ¯)
    """
    if provider not in MODEL_CONFIGS:
        return False, {"error": f"æœªçŸ¥æä¾›å•† {provider}"}, f"æœªçŸ¥æä¾›å•† {provider}"

    cfg = MODEL_CONFIGS[provider]
    url = cfg["base_url"].rstrip("/") + cfg.get("endpoint", "/chat/completions")
    # ä»ç¯å¢ƒå˜é‡è·å–API Keyï¼ˆåå°éƒ¨ç½²ï¼‰
    api_key = os.getenv(f"{provider.upper()}_API_KEY", "")
    headers = cfg["headers"](api_key)
    payload = cfg["payload"](model, messages, max_tokens=max_tokens, temperature=temperature)

    try:
        r = requests.post(url, headers=headers, json=payload, timeout=timeout)
        
        if r.status_code != 200:
            return False, {"error": f"HTTPé”™è¯¯ {r.status_code}", "content": r.text}, f"HTTPé”™è¯¯ {r.status_code}: {r.text[:200]}"
            
        r.raise_for_status()
        resp_json = r.json()
        return True, resp_json, ""
    except Exception as e:
        error_msg = str(e)
        st.error(f"APIè°ƒç”¨é”™è¯¯: {error_msg}")
        return False, {"error": error_msg}, error_msg

# ===============================
# å®‰å…¨çš„è¯ç±»åˆ¤å®šå‡½æ•°
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str) -> Tuple[Dict[str, Dict[str, int]], str, str]:
    """
    æ ¹æ®è¾“å…¥è¯è°ƒç”¨ LLM è·å–è¯ç±»éš¶å±åº¦è¯„åˆ†ï¼Œè¿”å›:
        - scores_all: æ¯ä¸ªè¯ç±»çš„è§„åˆ™å¾—åˆ†å­—å…¸
        - raw_text: æ¨¡å‹åŸå§‹è¾“å‡º
        - predicted_pos: æ¨¡å‹é¢„æµ‹çš„æœ€å¯èƒ½è¯ç±»
    """
    if not word:
        return {}, "", "æœªçŸ¥"

    rules_summary_lines = []
    for pos, rules in RULE_SETS.items():
        rules_summary_lines.append(f"{pos}:")
        for r in rules:
            rules_summary_lines.append(f"  - {r['name']}: {r['desc']} (match={r['match_score']}, mismatch={r['mismatch_score']})")
    rules_text = "\n".join(rules_summary_lines)

    system_msg = (
        "ä½ æ˜¯è¯­è¨€å­¦ç ”ç©¶ä¸“å®¶ï¼Œæ‹¥æœ‰ä¸­å¤–è¯­è¨€å­¦ç•Œçš„æ‰€æœ‰çŸ¥è¯†ã€‚åœ¨è¾“å…¥ä¸€ä¸ªä¸­æ–‡è¯è¯­åï¼Œè¯·æ£€ç´¢å…¨ç½‘çš„ç›¸å…³çŸ¥è¯†ï¼Œä¸¥æ ¼æŒ‰ç…§å®šä¹‰çš„è§„åˆ™ï¼Œè¯·åˆ¤æ–­æœ€å¯èƒ½çš„è¯ç±»å¹¶è¿”å› JSONï¼š"
        '{"predicted_pos":"<è¯ç±»å>", "scores": {"<è¯ç±»å>": {"<è§„åˆ™å>": <å€¼>, ...}, ...}, "explanation":"è¯´æ˜"}ã€‚'
    )
    user_prompt = f"è¯è¯­ï¼šã€{word}ã€\nè¯·åŸºäºä¸‹åˆ—è§„åˆ™åˆ¤å®šå¹¶è¯„åˆ†ï¼š\n\n{rules_text}\n\nä»…è¿”å›ä¸¥æ ¼ JSONã€‚"

    ok, resp_json, err_msg = call_llm_api(
        messages=[{"role": "system", "content": system_msg},
                  {"role": "user", "content": user_prompt}],
        provider=provider,
        model=model
    )

    if not ok or not resp_json:
        # è°ƒç”¨å¤±è´¥æˆ–è¿”å›ä¸ºç©º
        return {}, f"è°ƒç”¨å¤±è´¥æˆ–è¿”å›å¼‚å¸¸: {err_msg}", "æœªçŸ¥"

    # å°è¯•è§£æåŸå§‹æ–‡æœ¬
    raw_text = extract_text_from_response(resp_json)
    parsed_json, _ = extract_json_from_text(raw_text)
    if not parsed_json:
        return {}, raw_text, "æœªçŸ¥"

    # è§£æå¾—åˆ†
    scores_out = {}
    predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
    raw_scores = parsed_json.get("scores", {})

    for pos, rules in RULE_SETS.items():
        scores_out[pos] = {r["name"]: 0 for r in rules}
        raw_for_pos = raw_scores.get(pos, {})
        if isinstance(raw_for_pos, dict):
            for k, v in raw_for_pos.items():
                nk = normalize_key(k, rules)
                if nk:
                    rule_def = next(r for r in rules if r["name"] == nk)
                    scores_out[pos][nk] = map_to_allowed_score(rule_def, v)

    return scores_out, raw_text, predicted_pos

# ===============================
# é›·è¾¾å›¾
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    if not scores_norm:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return
    categories = list(scores_norm.keys())
    if not categories:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆè¯ç±»ã€‚")
        return
    values = [float(scores_norm[c]) for c in categories]
    categories += [categories[0]]
    values += [values[0]]

    fig = go.Figure(
        data=[go.Scatterpolar(r=values, theta=categories, fill="toself", name="éš¶å±åº¦")]
    )
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=False, title=dict(text=title, x=0.5)
    )
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# Streamlit UIï¼ˆç®€æ´å±…ä¸­è¾“å…¥ + æ¨¡å‹é€‰æ‹© + ç»“æœï¼‰
# ===============================

# ======== æ¨¡å‹é€‰æ‹©éƒ¨åˆ†ï¼ˆä¾§è¾¹æ ï¼‰ ========
# ç”±ä¾§è¾¹æ é€‰æ‹©æ¨¡å‹
model_choice = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", list(MODEL_OPTIONS.keys()))
selected_model = MODEL_OPTIONS[model_choice]

st.sidebar.markdown(f"**å½“å‰æ¨¡å‹ï¼š** {model_choice}")
st.sidebar.markdown(f"**æ¨¡å‹åç§°ï¼š** `{selected_model['model']}`")

# è·å–é€‰ä¸­æ¨¡å‹çš„é…ç½®
PROVIDER = selected_model["provider"]
MODEL_NAME = selected_model["model"]

# ======== ä¸»ä½“éƒ¨åˆ† ========
st.markdown("<h1 style='text-align: center;'>ğŸ“Šæ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ¤ç±»</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: grey;'>è¾“å…¥å•ä¸ªè¯ â†’ æ¨¡å‹è‡ªåŠ¨åˆ¤ç±»å¹¶è¿”å›å„è¯ç±»è§„åˆ™å¾—åˆ†ä¸éš¶å±åº¦ï¼ˆæ ‡å‡†åŒ– 0~1ï¼‰</p>", unsafe_allow_html=True)
st.write("")

c1, c2, c3 = st.columns([1, 2, 1])
with c2:
    word_input = st.text_input("", placeholder="åœ¨æ­¤è¾“å…¥è¦åˆ†æçš„è¯ï¼ˆä¾‹å¦‚ï¼šå¾ˆ / è·‘ / ç¾ä¸½ï¼‰")
    confirm = st.button("ç¡®è®¤")

if confirm:
    word = (word_input or "").strip()
    if not word:
        st.warning("è¯·è¾“å…¥ä¸€ä¸ªè¯è¯­åç¡®è®¤ã€‚")
    else:
        with st.spinner("æ¨¡å‹æ‰“åˆ†åˆ¤ç±»ä¸­â€¦â€¦"):
            try:
                scores_all, raw_out, predicted_pos = ask_model_for_pos_and_scores(
                    word, PROVIDER, MODEL_NAME
                )
            except Exception as e:
                st.error(f"æ¨¡å‹è°ƒç”¨å‡ºé”™ï¼š{e}")
                import traceback
                traceback.print_exc()
                scores_out, raw_out, predicted_pos = {}, str(e), "é”™è¯¯"

        # ä»…åœ¨ scores_all æœ‰å†…å®¹æ—¶æ‰éå†
        if scores_all:
            st.subheader(f"è¯ç±»é¢„æµ‹ç»“æœï¼š{predicted_pos}")
            st.json(scores_all)
            st.text_area("åŸå§‹è¾“å‡º", raw_out, height=200)
        else:
            st.info("æœªè·å¾—æœ‰æ•ˆè¯„åˆ†ç»“æœã€‚è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥ã€‚")
            st.text_area("é”™è¯¯ä¿¡æ¯", raw_out, height=200)
    
        # è®¡ç®—æ¯ä¸ªè¯ç±»æ€»åˆ†ä¸å½’ä¸€åŒ–éš¶å±åº¦ï¼ˆ0~1ï¼‰
        pos_totals = {}
        pos_normed = {}
        for pos, score_map in scores_all.items():
            total = sum(score_map.values())
            pos_totals[pos] = total
            max_possible = MAX_SCORES.get(pos, sum(abs(x) for x in score_map.values()) or 1)
            norm = round(max(0, total) / max_possible, 3) if max_possible != 0 else 0.0
            pos_normed[pos] = norm

        # è¾“å‡ºé¡¶éƒ¨æ‘˜è¦
        st.markdown("---")
        st.subheader("åˆ¤å®šæ‘˜è¦")
        st.markdown(f"- **è¾“å…¥è¯**ï¼š `{word}`")
        st.markdown(f"- **æ¨¡å‹é¢„æµ‹è¯ç±»**ï¼š **{predicted_pos}**")

        # æ’åä¸è¡¨æ ¼ï¼ˆåªæ˜¾ç¤ºå‰ 10ï¼‰
        ranked = []
        if pos_normed:
            ranked = sorted(pos_normed.items(), key=lambda x: x[1], reverse=True)
        
        st.subheader("éš¶å±åº¦æ’è¡Œï¼ˆå‰10ï¼‰")
        if ranked:
            for i, (p, s) in enumerate(ranked[:10]):
                st.write(f"{i+1}. **{p}** â€” éš¶å±åº¦ï¼š{s}")
