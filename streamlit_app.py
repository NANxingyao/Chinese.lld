import streamlit as st
import requests
import json
import re
import os
import pandas as pd
import plotly.graph_objects as go
import io
import time  # ç”¨äºé™é€Ÿå’Œé‡è¯•
from typing import Tuple, Dict, Any, List
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ===============================
# é¡µé¢é…ç½®
# ===============================
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items=None
)

# è‡ªå®šä¹‰CSSæ ·å¼
hide_streamlit_style = """
<style>
header {visibility: hidden;}
footer {visibility: hidden;}
.dataframe {font-size: 12px;}
[data-testid="stSidebar"] { display: none !important; }
.stApp > div:first-child { padding-top: 2rem; }
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# ===============================
# æ¨¡å‹é…ç½®
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), "stream": True, 
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), "stream": True,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), "stream": True,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        "headers": lambda key: {
            "Authorization": f"Bearer {key}", "Content-Type": "application/json",
            "X-DashScope-SSE": "enable", "Accept": "text/event-stream"
        },
        "payload": lambda model, messages, **kw: {
            "model": model, "input": {"messages": messages}, 
            "parameters": {"max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0),
                           "result_format": "message", "incremental_output": True},
        },
    },
}

MODEL_OPTIONS = {
    "DeepSeek Chat": {"provider": "deepseek", "model": "deepseek-chat", "api_key": os.getenv("DEEPSEEK_API_KEY"), "env_var": "DEEPSEEK_API_KEY"},
    "OpenAI GPT-4oï¼ˆæ¨èï¼‰": {"provider": "openai", "model": "gpt-4o-mini", "api_key": os.getenv("OPENAI_API_KEY"), "env_var": "OPENAI_API_KEY"},
    "Moonshotï¼ˆKimiï¼‰": {"provider": "moonshot", "model": "moonshot-v1-32k", "api_key": os.getenv("MOONSHOT_API_KEY"), "env_var": "MOONSHOT_API_KEY"},
    "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰": {"provider": "qwen", "model": "qwen-max", "api_key": os.getenv("QWEN_API_KEY"), "env_var": "QWEN_API_KEY"},
}

AVAILABLE_MODEL_OPTIONS = {name: info for name, info in MODEL_OPTIONS.items() if info["api_key"]}
if not AVAILABLE_MODEL_OPTIONS: AVAILABLE_MODEL_OPTIONS = MODEL_OPTIONS

# ===============================
# è§„åˆ™å®šä¹‰
# ===============================
RULE_SETS = {
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸èƒ½å¸¦å®¾è¯­ï¼Œä¸èƒ½å—çŠ¶è¯­å’Œè¡¥è¯­ï¼Œä¸èƒ½åé™„æ—¶ä½“åŠ©è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼Œæˆ–è¿›å…¥'...äº†æ²¡æœ‰'æ ¼å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œæˆ–é€šè¿‡'å’Œ/ä¸º/å¯¹/å‘/æ‹¿/äº'ç­‰ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V, Väº†V, Vä¸V, Väº†æ²¡æœ‰'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®æˆ–è·Ÿåœ¨'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®ï¼Œä¸èƒ½è·Ÿåœ¨'å¤šä¹ˆ'ä¹‹åè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
    ],
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®šï¼Œå¹¶ä¸”\"æ²¡æœ‰â€¦â€¦\"çš„è‚¯å®šå½¢å¼å¯ä»¥æ˜¯\"â€¦â€¦äº†\"å’Œ\"æœ‰â€¦â€¦\"", "match_score": 10, "mismatch_score": -10},
        {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"ï¼Œæˆ–è€…å¯ä»¥è¿›å…¥\"â€¦â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰\"VVã€Vä¸€Vã€Väº†Vã€Vä¸V\"ç­‰é‡å å’Œæ­£åé‡å å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­ï¼Œä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°ï¼Œæˆ–è€…å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åæé—®ï¼Œè·Ÿåœ¨\"è¿™ä¹ˆã€è¿™æ ·\"ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š\"ä¹‹åï¼Œå¯¹æ€§è´¨çš„ç¨‹åº¦è¿›è¡Œæé—®ï¼Œä¹Ÿä¸èƒ½è·Ÿåœ¨\"å¤šä¹ˆ\"ä¹‹åï¼Œè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
        {"name": "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
    ]
}

# ===============================
# å·¥å…·å‡½æ•° (å·²å¢å¼º)
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    if not isinstance(resp_json, dict): return ""
    try:
        if "output" in resp_json and "text" in resp_json["output"]: return resp_json["output"]["text"]
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]: return choice["message"]["content"]
        return json.dumps(resp_json, ensure_ascii=False)
    except Exception: return json.dumps(resp_json, ensure_ascii=False)

def extract_json_from_text(text: str) -> Tuple[Dict[str, Any], str]:
    """
    ã€å¢å¼ºç‰ˆã€‘ä¼˜å…ˆå¯»æ‰¾Markdownä»£ç å—ï¼Œæ‰¾ä¸åˆ°å†æ‰¾å¤§æ‹¬å·ã€‚
    è§£å†³æ¨¡å‹è¾“å‡ºåºŸè¯å¯¼è‡´æå–å¤±è´¥çš„é—®é¢˜ã€‚
    """
    if not text: return None, ""
    
    json_str = ""
    # 1. å°è¯•æå– ```json ... ```
    code_match = re.search(r"```json\s*(.*?)\s*```", text, re.DOTALL)
    if code_match:
        json_str = code_match.group(1).strip()
    
    # 2. å¦‚æœå¤±è´¥ï¼Œå°è¯•æå–æœ€å¤–å±‚ {...}
    if not json_str:
        match = re.search(r"(\{.*\})", text.strip(), re.DOTALL)
        if match: json_str = match.group(1).strip()

    if not json_str: return None, text

    try: 
        return json.loads(json_str), json_str
    except json.JSONDecodeError: 
        return None, text

def normalize_key(k: str, pos_rules: list) -> str:
    if not isinstance(k, str): return None
    k_norm = re.sub(r'[\s_]+', '', k).upper()
    for r in pos_rules:
        r_norm = re.sub(r'[\s_]+', '', r["name"]).upper()
        if r_norm == k_norm: return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    if isinstance(raw_val, bool): return match_score if raw_val is True else mismatch_score
    if isinstance(raw_val, str):
        s = raw_val.strip().lower()
        if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"): return match_score
        if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"): return mismatch_score
    if isinstance(raw_val, (int, float)):
        raw_val_int = int(raw_val)
        if raw_val_int == match_score: return match_score
        if raw_val_int == mismatch_score: return mismatch_score
    return mismatch_score

def calculate_membership(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    membership = {}
    for pos, scores in scores_all.items():
        total_score = sum(scores.values())
        normalized = total_score / 100
        membership[pos] = max(-1.0, min(1.0, normalized))
    return membership

def get_top_10_positions(membership: Dict[str, float]) -> List[Tuple[str, float]]:
    return sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]

# ===============================
# APIè°ƒç”¨
# ===============================
def call_llm_api_cached(_provider, _model, _api_key, messages, max_tokens=4096, temperature=0.0):
    if not _api_key: return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"
    if _provider not in MODEL_CONFIGS: return False, {"error": f"æœªçŸ¥æä¾›å•† {_provider}"}, f"æœªçŸ¥æä¾›å•† {_provider}"

    cfg = MODEL_CONFIGS[_provider]
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](_api_key)
    payload = cfg["payload"](_model, messages, max_tokens=max_tokens, temperature=temperature)
    streaming_placeholder = st.empty()
    full_content = ""

    try:
        with requests.post(url, headers=headers, json=payload, stream=True, timeout=60) as response:
            response.raise_for_status()
            for line in response.iter_lines():
                if not line: continue
                line_text = line.decode('utf-8').strip()
                if line_text.startswith("data:"): json_str = line_text[5:].strip()
                else: json_str = line_text
                if json_str == "[DONE]": break
                try:
                    chunk = json.loads(json_str)
                    delta_text = ""
                    if "choices" in chunk and len(chunk["choices"]) > 0:
                        delta = chunk["choices"][0].get("delta", {})
                        delta_text = delta.get("content", "")
                    elif "output" in chunk:
                        output = chunk["output"]
                        if "choices" in output and len(output["choices"]) > 0:
                             msg = output["choices"][0].get("message", {})
                             delta_text = msg.get("content", "")
                        elif "text" in output:
                             delta_text = output["text"]
                    if delta_text: full_content += delta_text
                except json.JSONDecodeError: continue
        streaming_placeholder.empty()
        mock_response = {"choices": [{"message": {"content": full_content}}], "output": {"text": full_content}}
        if not full_content: return False, {"error": "æ— å†…å®¹"}, "æ— å†…å®¹"
        return True, mock_response, ""
    except Exception as e:
        return False, {"error": str(e)}, str(e)

# ===============================
# æ ¸å¿ƒåˆ†æ
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict, str, str, str]:
    if not word: return {}, "", "æœªçŸ¥", ""

    full_rules_by_pos = {
        pos: "\n".join([f"- {r['name']}: {r['desc']}ï¼ˆç¬¦åˆ: {r['match_score']} åˆ†ï¼Œä¸ç¬¦åˆ: {r['mismatch_score']} åˆ†ï¼‰" for r in rules])
        for pos, rules in RULE_SETS.items()
    }

    system_msg = f"""ä½ æ˜¯ä¸€åä¸­æ–‡è¯æ³•ä¸“å®¶ã€‚åˆ†æã€Œ{word}ã€åœ¨åè¯ã€åŠ¨è¯ã€ååŠ¨è¯çš„è¡¨ç°ã€‚
è§„åˆ™ï¼š{full_rules_by_pos["åè¯"]}\n{full_rules_by_pos["åŠ¨è¯"]}\n{full_rules_by_pos["ååŠ¨è¯"]}
è¦æ±‚ï¼š
1. explanation: é€æ¡è§„åˆ™è¯´æ˜ç†ç”±ã€‚
2. scores: æ¯æ¡è§„åˆ™ true/falseã€‚
3. predicted_pos: é€‰ä¸€ä¸ªã€‚
4. è¿”å› JSONã€‚"""

    user_prompt = f"åˆ†æè¯è¯­ã€Œ{word}ã€ï¼Œè¯·ç›´æ¥è¿”å›åŒ…å« explanation, predicted_pos, scores çš„ JSONã€‚"

    with st.spinner(f"æ­£åœ¨åˆ†æ..."):
        ok, resp_json, err_msg = call_llm_api_cached(provider, model, api_key, [{"role": "system", "content": system_msg}, {"role": "user", "content": user_prompt}])

    if not ok: return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", f"å¤±è´¥: {err_msg}"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, _ = extract_json_from_text(raw_text)

    # å…œåº•é€»è¾‘ï¼šå¦‚æœJSONè§£æå¤±è´¥ï¼Œè‡³å°‘ä¿ç•™åŸå§‹æ–‡æœ¬ä½œä¸ºæ¨ç†è¿‡ç¨‹
    if parsed_json and isinstance(parsed_json, dict):
        explanation = parsed_json.get("explanation", "æ— ")
        predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
        raw_scores = parsed_json.get("scores", {})
    else:
        # å¦‚æœè§£æå¤±è´¥ï¼ŒæŠŠåŸå§‹å›å¤å½“ä½œæ¨ç†è¿‡ç¨‹
        explanation = "è§£æå¤±è´¥ï¼ŒåŸå§‹å›å¤ï¼š" + raw_text
        predicted_pos = "æœªçŸ¥"
        raw_scores = {}

    scores_out = {pos: {} for pos in RULE_SETS.keys()}
    for pos, rules in RULE_SETS.items():
        raw_pos_scores = raw_scores.get(pos, {})
        if isinstance(raw_pos_scores, dict):
            for k, v in raw_pos_scores.items():
                normalized_key = normalize_key(k, rules)
                if normalized_key:
                    rule_def = next(r for r in rules if r["name"] == normalized_key)
                    scores_out[pos][normalized_key] = map_to_allowed_score(rule_def, v)
    
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            if rule["name"] not in scores_out[pos]: scores_out[pos][rule["name"]] = 0

    return scores_out, raw_text, predicted_pos, explanation

def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    if not scores_norm: return
    categories = list(scores_norm.keys())
    values = list(scores_norm.values())
    categories += [categories[0]]
    values += [values[0]]
    fig = go.Figure(data=[go.Scatterpolar(r=values, theta=categories, fill="toself", name="éš¶å±åº¦")])
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[-1, 1])), showlegend=False, title=dict(text=title, x=0.5))
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# ã€å¢å¼ºç‰ˆã€‘Excel æ‰¹é‡å¤„ç†ï¼ˆå®æ—¶ä¿å­˜ + å…œåº•æ˜¾ç¤ºï¼‰
# ===============================
def process_and_style_excel(df, selected_model_info, target_col_name):
    """
    ä¿®æ”¹ç‚¹ï¼š
    1. å®æ—¶è¿½åŠ å†™å…¥ 'history_database.csv'ï¼Œé˜²ä¸¢å¤±ã€‚
    2. è¯»å– 'history_database.csv' å®ç°æ–­ç‚¹ç»­ä¼ ã€‚
    3. å¦‚æœ JSON è§£æå¤±è´¥ï¼Œå¼ºåˆ¶å¡«å…¥ raw_text ä½œä¸ºæ¨ç†è¿‡ç¨‹ã€‚
    """
    output = io.BytesIO()
    processed_rows = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    total = len(df)
    
    # 1. å®šä¹‰æœ¬åœ°æ•°æ®åº“
    db_file = "history_database.csv"
    
    # 2. è¯»å–å·²æœ‰å†å²ï¼ˆç”¨äºè·³è¿‡ï¼‰
    existing_data = {}
    if os.path.exists(db_file):
        try:
            # è¯»å–æ—¶å¼ºåˆ¶å°†'è¯è¯­'åˆ—è½¬ä¸ºstrï¼Œé˜²æ­¢åŒ¹é…é”™è¯¯
            history_df = pd.read_csv(db_file)
            history_df['è¯è¯­'] = history_df['è¯è¯­'].astype(str).str.strip()
            for _, row in history_df.iterrows():
                existing_data[row['è¯è¯­']] = row.to_dict()
            st.info(f"ğŸ“š å·²åŠ è½½ {len(existing_data)} æ¡æœ¬åœ°å†å²è®°å½•ï¼Œå°†è‡ªåŠ¨è·³è¿‡è¿™äº›è¯ã€‚")
        except:
            pass

    try:
        for index, row in df.iterrows():
            word = str(row[target_col_name]).strip()
            
            # 3. æ£€æŸ¥å†å²ç¼“å­˜
            if word in existing_data:
                status_text.text(f"â™»ï¸ ä½¿ç”¨ç¼“å­˜ ({index + 1}/{total}): {word}")
                processed_rows.append(existing_data[word])
                time.sleep(0.01)
            else:
                # è·‘æ–°è¯
                max_retries = 3
                success = False
                scores_all = {}
                raw_text = ""
                predicted_pos = "è¯·æ±‚å¤±è´¥"
                explanation = "é‡è¯•å¤±è´¥"
                
                for attempt in range(max_retries):
                    try:
                        status_text.text(f"ğŸš€ åˆ†ææ–°è¯ ({index + 1}/{total}): {word} ...")
                        scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
                            word=word,
                            provider=selected_model_info["provider"],
                            model=selected_model_info["model"],
                            api_key=selected_model_info["api_key"]
                        )
                        # åªè¦ raw_text æœ‰å†…å®¹å°±ç®—é€šä¿¡æˆåŠŸï¼Œå“ªæ€•è§£æå¤±è´¥
                        if raw_text:
                            success = True
                            break 
                        else:
                            time.sleep(2)
                    except Exception as e:
                        time.sleep(2)
                
                # è®¡ç®—åˆ†æ•°
                if success and scores_all:
                    membership = calculate_membership(scores_all)
                    score_v = membership.get("åŠ¨è¯", 0.0)
                    score_n = membership.get("åè¯", 0.0)
                    score_nv = membership.get("ååŠ¨è¯", 0.0)
                else:
                    score_v, score_n, score_nv = 0.0, 0.0, 0.0
                
                diff_val = round(abs(score_v - score_n), 4)
                
                # å…³é”®ï¼šå¦‚æœ explanation ä¸ºç©ºï¼ˆè§£æå¤±è´¥ï¼‰ï¼Œåˆ™ä½¿ç”¨ raw_text
                final_explanation = explanation if (explanation and len(explanation) > 5) else raw_text
                
                new_row = {
                    "è¯è¯­": word,
                    "åŠ¨è¯": score_v,
                    "åè¯": score_n,
                    "ååŠ¨è¯": score_nv,
                    "å·®å€¼/è·ç¦»": diff_val,
                    "åŸå§‹å“åº”": final_explanation if success else "é”™è¯¯",
                    "_predicted_pos": predicted_pos
                }
                
                processed_rows.append(new_row)
                
                # 4. å®æ—¶å†™å…¥æ•°æ®åº“ (è¿½åŠ æ¨¡å¼)
                try:
                    temp_df = pd.DataFrame([new_row])
                    write_header = not os.path.exists(db_file)
                    # utf-8-sig é˜²æ­¢ä¸­æ–‡ä¹±ç 
                    temp_df.to_csv(db_file, mode='a', header=write_header, index=False, encoding='utf-8-sig')
                except:
                    pass
                
                time.sleep(1) # é™é€Ÿ

            progress_bar.progress((index + 1) / total)

    except Exception as e:
        st.error(f"æ„å¤–ä¸­æ–­: {e}")

    # ç”Ÿæˆ Excel
    if not processed_rows: return None
    result_df = pd.DataFrame(processed_rows)
    
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        cols = ["è¯è¯­", "åŠ¨è¯", "åè¯", "ååŠ¨è¯", "å·®å€¼/è·ç¦»", "åŸå§‹å“åº”"]
        # ç¡®ä¿åˆ—éƒ½å­˜åœ¨
        valid_cols = [c for c in cols if c in result_df.columns]
        result_df[valid_cols].to_excel(writer, index=False, sheet_name='åˆ†æç»“æœ')
        
        # æ ‡é»„
        try:
            ws = writer.sheets['åˆ†æç»“æœ']
            fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
            for i, r in enumerate(processed_rows):
                if "_predicted_pos" not in r: continue
                pred = r["_predicted_pos"]
                target = None
                if pred == "åŠ¨è¯": target = 2
                elif pred == "åè¯": target = 3
                elif pred == "ååŠ¨è¯": target = 4
                if target: ws.cell(row=i+2, column=target).fill = fill
        except:
            pass

    status_text.success(f"âœ… å®Œæˆï¼")
    return output.getvalue()

# ===============================
# ä¸»ç¨‹åº
# ===============================
def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»")
    
    control_container = st.container()
    with control_container:
        col1, col2 = st.columns([3, 1])
        with col1:
            if not AVAILABLE_MODEL_OPTIONS:
                st.error("âŒ æ—  API Key")
                selected_model_info = {"api_key": None}
            else:
                s_name = st.selectbox("é€‰æ‹©æ¨¡å‹", list(AVAILABLE_MODEL_OPTIONS.keys()))
                selected_model_info = AVAILABLE_MODEL_OPTIONS[s_name]
        with col2:
            st.write("")
            if st.button("æµ‹è¯•è¿æ¥"):
                ok, _, msg = call_llm_api_cached(selected_model_info["provider"], selected_model_info["model"], selected_model_info["api_key"], [{"role":"user","content":"hi"}], max_tokens=5)
                if ok: st.success("æˆåŠŸ")
                else: st.error(msg)
    
    st.markdown("---")
    
    tab1, tab2 = st.tabs(["ğŸ” å•ä¸ªè¯è¯­è¯¦ç»†åˆ†æ", "ğŸ“‚ Excel æ‰¹é‡å¤„ç†"])
    
    # Tab 1: å•ä¸ªåˆ†æ
    with tab1:
        word = st.text_input("è¯è¯­è¾“å…¥", key="word_input")
        if st.button("å¼€å§‹åˆ†æ", disabled=not (word and selected_model_info["api_key"])):
            scores, raw, pred, expl = ask_model_for_pos_and_scores(word, selected_model_info["provider"], selected_model_info["model"], selected_model_info["api_key"])
            if scores:
                mem = calculate_membership(scores)
                st.success(f"ç»“æœ: {pred} ({mem.get(pred,0):.2f})")
                c1, c2 = st.columns(2)
                with c1:
                    st.table(pd.DataFrame(get_top_10_positions(mem), columns=["è¯ç±»","éš¶å±åº¦"]))
                    plot_radar_chart_streamlit(mem, f"{word} é›·è¾¾å›¾")
                with c2:
                    st.subheader("å¾—åˆ†è¯¦æƒ…")
                    # æ˜¾ç¤ºæ¨ç†è¿‡ç¨‹
                    st.info(expl)
                    with st.expander("åŸå§‹å“åº”"): st.text(raw)

    # Tab 2: æ‰¹é‡å¤„ç†
    with tab2:
        st.header("Excel æ‰¹é‡å¤„ç†")
        up_file = st.file_uploader("ä¸Šä¼  Excel", type=["xlsx"])
        
        if up_file and selected_model_info["api_key"]:
            df = pd.read_excel(up_file)
            target = next((c for c in df.columns if "è¯" in str(c) or "word" in str(c).lower()), None)
            if target:
                st.dataframe(df.head(3))
                if st.button("ğŸš€ å¼€å§‹æ‰¹é‡"):
                    res = process_and_style_excel(df, selected_model_info, target)
                    if res:
                        st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ (Excel)", res, "result.xlsx")
            else:
                st.error("æœªæ‰¾åˆ°'è¯'åˆ—")

        st.markdown("---")
        
        # --- å†å²è®°å½•ç®¡ç†åŒºåŸŸ ---
        st.subheader("ğŸ“š å†å²è®°å½•æ•°æ®åº“ç®¡ç†")
        db_file = "history_database.csv"
        
        if os.path.exists(db_file):
            try:
                # è¯»å–æ—¶å…¨éƒ¨è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œç¡®ä¿æ ¼å¼ä¸€è‡´
                history_df = pd.read_csv(db_file)
                st.info(f"æœ¬åœ°æ•°æ®åº“ä¸­å…±æœ‰ {len(history_df)} æ¡å·²åˆ†æè®°å½•ã€‚")
                
                with st.expander("æŸ¥çœ‹å†å²æ•°æ®é¢„è§ˆ"):
                    st.dataframe(history_df)
                
                col_h1, col_h2 = st.columns([1, 1])
                with col_h1:
                    # æä¾›CSVä¸‹è½½ï¼ˆæœ€åŸå§‹çš„æ•°æ®å¤‡ä»½ï¼‰
                    st.download_button(
                        label="ğŸ’¾ ä¸‹è½½å®Œæ•´å†å²è®°å½• (CSV)",
                        data=history_df.to_csv(index=False).encode('utf-8-sig'),
                        file_name="history_database.csv",
                        mime="text/csv"
                    )
                with col_h2:
                    if st.button("ğŸ—‘ï¸ æ¸…ç©ºå†å²è®°å½• (æ…ç‚¹)"):
                        os.remove(db_file)
                        st.success("å†å²è®°å½•å·²æ¸…ç©ºï¼æ­£åœ¨åˆ·æ–°...")
                        time.sleep(1)
                        st.rerun()
            except Exception as e:
                st.error(f"è¯»å–å†å²è®°å½•å‡ºé”™: {e}")
        else:
            st.warning("æš‚æ— å†å²è®°å½•ã€‚")

if __name__ == "__main__":
    main()
