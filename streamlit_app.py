import streamlit as st
import requests
import json
import re
import os
import pandas as pd
import plotly.graph_objects as go
from typing import Tuple, Dict, Any, List
# å¢åŠ å®½æ¾çš„JSONè§£æåº“ï¼ˆéœ€å…ˆå®‰è£…ï¼špip install demjsonï¼‰
try:
    import demjson
    DEMJSON_AVAILABLE = True
except ImportError:
    DEMJSON_AVAILABLE = False
    st.warning("æœªå®‰è£…demjsonåº“ï¼ŒJSONè§£æå®¹é”™èƒ½åŠ›ä¼šé™ä½ã€‚å»ºè®®æ‰§è¡Œï¼špip install demjson")

# ===============================
# é¡µé¢é…ç½®
# ===============================
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»",
    page_icon="ğŸ“°",
    layout="wide",  # ä½¿ç”¨å®½å¸ƒå±€
    initial_sidebar_state="collapsed",  # é»˜è®¤æŠ˜å ä¾§è¾¹æ 
    menu_items=None
)

# è‡ªå®šä¹‰CSSæ ·å¼
hide_streamlit_style = """
<style>
/* éšè—é¡¶éƒ¨èœå•æ å’Œé¡µè„š */
header {visibility: hidden;}
footer {visibility: hidden;}

/* è°ƒæ•´è¡¨æ ¼æ ·å¼ */
.dataframe {font-size: 12px;}

/* éšè—é»˜è®¤çš„ä¾§è¾¹æ  */
[data-testid="stSidebar"] {
    display: none !important;
}

/* ä¸ºé¡¶éƒ¨æ§åˆ¶åŒºæ·»åŠ è¾¹æ¡†å’ŒèƒŒæ™¯è‰²ï¼Œä½¿å…¶çœ‹èµ·æ¥åƒä¸€ä¸ªå›ºå®šçš„é¢æ¿ */
.stApp > div:first-child {
    padding-top: 2rem;
}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# ===============================
# æ¨¡å‹é…ç½® (ä»…ä»ç¯å¢ƒå˜é‡è·å–API Key)
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "input": {"messages": messages}, "parameters": {"max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0),},
        },
    },
}

# æ¨¡å‹é€‰é¡¹ï¼ˆä»…ä»ç¯å¢ƒå˜é‡è·å–API Keyï¼Œä¸æä¾›æ‰‹åŠ¨è¾“å…¥ï¼‰
MODEL_OPTIONS = {
    "DeepSeek Chat": {
        "provider": "deepseek", 
        "model": "deepseek-chat", 
        "api_key": os.getenv("DEEPSEEK_API_KEY", "sk-759d66c83f374a2aaac0db5814ccb016"),
        "env_var": "DEEPSEEK_API_KEY"
    },
    "OpenAI GPT-4oï¼ˆå°šä¸æ”¯æŒï¼‰": {
        "provider": "openai", 
        "model": "gpt-4o-mini", 
        "api_key": os.getenv("OPENAI_API_KEY", "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"),
        "env_var": "OPENAI_API_KEY"
    },
    "Moonshotï¼ˆKimiï¼‰": {
        "provider": "moonshot", 
        "model": "moonshot-v1-32k", 
        "api_key": os.getenv("MOONSHOT_API_KEY", "sk-l5FvRWegjM5DEk4AU71YPQ1QgvFPTHZIJOmq6qdssPY4sNtE"),
        "env_var": "MOONSHOT_API_KEY"
    },
    "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰": {
        "provider": "qwen", 
        "model": "qwen-max", 
        "api_key": os.getenv("QWEN_API_KEY", "sk-b3f7a1153e6f4a44804a296038aa86c5"),
        "env_var": "QWEN_API_KEY"
    },
}

# ===============================
# è¯ç±»è§„åˆ™ä¸æœ€å¤§å¾—åˆ†
# ===============================
RULE_SETS = {
    # 1.1 åè¯
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸èƒ½å¸¦å®¾è¯­ï¼Œä¸èƒ½å—çŠ¶è¯­å’Œè¡¥è¯­ï¼Œä¸èƒ½åé™„æ—¶ä½“åŠ©è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    # 1.5 åŠ¨è¯
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼Œæˆ–è¿›å…¥'...äº†æ²¡æœ‰'æ ¼å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œæˆ–é€šè¿‡'å’Œ/ä¸º/å¯¹/å‘/æ‹¿/äº'ç­‰ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­ï¼ˆæŒ‰æ¡ç›®ç»™äºˆå¾—åˆ†ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V, Väº†V, Vä¸V, Väº†æ²¡æœ‰'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸€èˆ¬å¯å—çŠ¶è¯­æˆ–è¡¥è¯­ä¿®é¥°ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®æˆ–è·Ÿåœ¨'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®ï¼Œä¸èƒ½è·Ÿåœ¨'å¤šä¹ˆ'ä¹‹åè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
    ],
    # 4.6 ååŠ¨è¯
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®šï¼Œå¹¶ä¸”\"æ²¡æœ‰â€¦â€¦\"çš„è‚¯å®šå½¢å¼å¯ä»¥æ˜¯\"â€¦â€¦äº†\"å’Œ\"æœ‰â€¦â€¦\"(å‰ä¸€ç§æƒ…å†µä¸­çš„\"æ²¡æœ‰\"æ˜¯å‰¯è¯ï¼Œåä¸€ç§æƒ…å†µä¸­çš„\"æ²¡æœ‰\"æ˜¯åŠ¨è¯)", "match_score": 10, "mismatch_score": -10},
        {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"ï¼Œæˆ–è€…å¯ä»¥è¿›å…¥\"â€¦â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰\"VVã€Vä¸€Vã€Väº†Vã€Vä¸V\"ç­‰é‡å å’Œæ­£åé‡å å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­ï¼Œå¹¶ä¸”ï¼Œå¯ä»¥ä½œå½¢å¼åŠ¨è¯\"ä½œã€è¿›è¡Œã€åŠ ä»¥ã€ç»™äºˆã€å—åˆ°\"ç­‰çš„å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°ï¼Œæˆ–è€…å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åï¼Œå¯¹åŠ¨ä½œçš„æ–¹å¼è¿›è¡Œæé—®ï¼Œå¹¶ä¸”å¯ä»¥è·Ÿåœ¨\"è¿™ä¹ˆã€è¿™æ ·ã€é‚£ä¹ˆã€é‚£æ ·\"ä¹‹åï¼Œç”¨ä»¥ä½œå‡ºç›¸åº”çš„å›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š\"ä¹‹åï¼Œå¯¹æ€§è´¨çš„ç¨‹åº¦è¿›è¡Œæé—®ï¼Œä¹Ÿä¸èƒ½è·Ÿåœ¨\"å¤šä¹ˆ\"ä¹‹åï¼Œè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
        {"name": "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„(ç„¶åä½œâ€œåœ¨ã€åˆ°ã€ä»â€ç­‰ä»‹è¯çš„å®¾è¯­ï¼Œè¿™ç§ä»‹è¯ç»“æ„åˆå¯ä»¥ä½œçŠ¶è¯­æˆ–è¡¥è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†)", "match_score": 10, "mismatch_score": 0},
    ]
}

# é¢„è®¡ç®—æ¯ä¸ªè¯ç±»çš„æœ€å¤§å¯èƒ½å¾—åˆ†
MAX_SCORES = {pos: sum(abs(r["match_score"]) for r in rules) for pos, rules in RULE_SETS.items()}

# ===============================
# å·¥å…·å‡½æ•°
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    if not isinstance(resp_json, dict): return ""
    try:
        # --- å¤„ç†é€šä¹‰åƒé—® (Qwen) çš„å“åº”æ ¼å¼ ---
        if "output" in resp_json and "text" in resp_json["output"]:
            return resp_json["output"]["text"]
            
        # --- å¤„ç† OpenAI ç³»åˆ—çš„å“åº”æ ¼å¼ ---
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
            for k in ("content", "text"):
                if k in choice: return choice[k]
    except Exception: 
        pass
    # å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œè¿”å›æ•´ä¸ªå“åº”çš„å­—ç¬¦ä¸²å½¢å¼ï¼Œç”¨äºè°ƒè¯•
    return json.dumps(resp_json, ensure_ascii=False)

def safe_json_parse(json_str: str) -> Tuple[dict, str]:
    """
    å®‰å…¨çš„JSONè§£æå‡½æ•°ï¼Œæ”¯æŒå¤šç§å®¹é”™æ–¹å¼
    è¿”å›ï¼š(è§£æåçš„å­—å…¸, æœ€ç»ˆå°è¯•çš„JSONå­—ç¬¦ä¸²)
    """
    # ç¬¬ä¸€æ­¥ï¼šåŸºç¡€æ¸…ç†
    json_str = json_str.strip()
    # ç§»é™¤æ³¨é‡Š
    json_str = re.sub(r'//.*?$', '', json_str, flags=re.MULTILINE)
    json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
    # æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹
    json_str = json_str.replace("ï¼š", ":").replace("ï¼Œ", ",").replace("â€œ", '"').replace("â€", '"').replace("â€™", "'")
    # å¤„ç†å•å¼•å·
    json_str = re.sub(r"'(\s*[^']+?\s*)'\s*:", r'"\1":', json_str)
    json_str = re.sub(r":\s*'([^']*?)'", r': "\1"', json_str)
    # ç§»é™¤æœ«å°¾é€—å·
    json_str = re.sub(r",\s*([}\]])", r"\1", json_str)
    # å¤„ç†å¸ƒå°”å€¼
    json_str = re.sub(r"\bTrue\b", "true", json_str)
    json_str = re.sub(r"\bFalse\b", "false", json_str)
    json_str = re.sub(r"\bNone\b", "null", json_str)
    
    # ç¬¬äºŒæ­¥ï¼šå°è¯•æ ‡å‡†è§£æ
    try:
        return json.loads(json_str), json_str
    except Exception as e1:
        # ç¬¬ä¸‰æ­¥ï¼šå°è¯•demjsonå®½æ¾è§£æï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if DEMJSON_AVAILABLE:
            try:
                parsed = demjson.decode(json_str)
                if isinstance(parsed, dict):
                    return parsed, json_str
            except Exception as e2:
                st.warning(f"demjsonè§£æå¤±è´¥: {e2}")
        
        # ç¬¬å››æ­¥ï¼šå°è¯•æå–æœ€å¤–å±‚çš„{}å†…å®¹
        match = re.search(r'\{[\s\S]*\}', json_str)
        if match:
            try:
                inner_str = match.group(0)
                return json.loads(inner_str), inner_str
            except:
                pass
        
        # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
        return None, json_str

def extract_json_from_text(text: str) -> Tuple[dict, str]:
    """
    å¢å¼ºç‰ˆJSONæå–å‡½æ•°
    ä¼˜å…ˆæå–```json```ä»£ç å—ï¼Œå†å°è¯•å…¶ä»–æ–¹å¼
    """
    if not text:
        return None, ""
    
    # ç¬¬ä¸€æ­¥ï¼šä¼˜å…ˆæå–```json```ä»£ç å—
    json_block_pattern = re.compile(r'```(?:json)?\s*\n?([\s\S]*?)\n?```', re.IGNORECASE)
    json_block_matches = json_block_pattern.findall(text)
    if json_block_matches:
        for json_str in json_block_matches:
            parsed, final_str = safe_json_parse(json_str)
            if parsed is not None:
                return parsed, final_str
    
    # ç¬¬äºŒæ­¥ï¼šæå–æ‰€æœ‰{}åŒ…è£¹çš„å†…å®¹
    all_json_matches = re.findall(r'\{[\s\S]*\}', text)
    if all_json_matches:
        for json_str in all_json_matches:
            parsed, final_str = safe_json_parse(json_str)
            if parsed is not None:
                return parsed, final_str
    
    # ç¬¬ä¸‰æ­¥ï¼šå°è¯•ç›´æ¥è§£ææ•´ä¸ªæ–‡æœ¬
    parsed, final_str = safe_json_parse(text)
    if parsed is not None:
        return parsed, final_str
    
    # æ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥
    st.warning("æ— æ³•ä»æ–‡æœ¬ä¸­æå–æœ‰æ•ˆçš„JSONç»“æ„")
    return None, text
    
def normalize_key(k: str, pos_rules: list) -> str:
    if not isinstance(k, str): return None
    k_upper = re.sub(r'\s+', '', k).upper()
    for r in pos_rules:
        if re.sub(r'\s+', '', r["name"]).upper() == k_upper:
            return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    # å¼ºåˆ¶ä¿ç•™åŸå§‹å¾—åˆ†ä¸­çš„è´Ÿåˆ†ï¼ˆå¦‚æœæ˜¯æœ‰æ•ˆè§„åˆ™åˆ†ï¼‰
    if isinstance(raw_val, (int, float)):
        # å…è®¸åŒ¹é…å¾—åˆ†æˆ–ä¸åŒ¹é…å¾—åˆ†ï¼ˆåŒ…æ‹¬è´Ÿåˆ†ï¼‰
        if raw_val == match_score or raw_val == mismatch_score:
            return int(raw_val)
    if isinstance(raw_val, bool):
        return match_score if raw_val else mismatch_score
    if isinstance(raw_val, str):
        s = raw_val.strip().lower()
        if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"):
            return match_score
        if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"):
            return mismatch_score
    # æ— æ•ˆå€¼æ—¶è¿”å›ä¸åŒ¹é…å¾—åˆ†ï¼ˆä¿ç•™è´Ÿåˆ†ï¼‰
    return mismatch_score

def calculate_membership(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    membership = {}
    for pos, scores in scores_all.items():
        total_score = sum(scores.values())
        # æ”¹ä¸ºï¼šæ€»å¾—åˆ†é™¤ä»¥100å¾—åˆ°éš¶å±åº¦ï¼ˆå‡ ååˆ†å¯¹åº”é›¶ç‚¹å‡ ï¼‰
        # åŒæ—¶é™åˆ¶åœ¨ [0, 1] åŒºé—´å†…
        # è´Ÿåˆ†å¯é™ä½éš¶å±åº¦ï¼Œä¿ç•™åŸå§‹è®¡ç®—é€»è¾‘ä½†ä¸å¼ºåˆ¶æˆªæ–­ä¸º0ï¼ˆå¯é€‰è°ƒæ•´ï¼‰
        normalized = total_score / 100
        # è‹¥éœ€å…è®¸éš¶å±åº¦ä¸ºè´Ÿï¼ˆæ›´å‡†ç¡®åæ˜ è´Ÿåˆ†å½±å“ï¼‰ï¼Œå¯æ”¹ä¸ºï¼š
        # membership[pos] = normalized
        # è‹¥éœ€é™åˆ¶åœ¨[-1, 1]åŒºé—´ï¼š
        membership[pos] = max(-1.0, min(1.0, normalized))
    return membership

def get_top_10_positions(membership: Dict[str, float]) -> List[Tuple[str, float]]:
    return sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]

def prepare_detailed_scores_df(scores_all: Dict[str, Dict[str, int]]) -> pd.DataFrame:
    rows = []
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            rows.append({
                "è¯ç±»": pos,
                "è§„åˆ™ä»£ç ": rule["name"],
                "è§„åˆ™æè¿°": rule["desc"],
                "å¾—åˆ†": scores_all[pos].get(rule["name"], 0)
            })
    return pd.DataFrame(rows)

# ===============================
# å®‰å…¨çš„ LLM è°ƒç”¨å‡½æ•° (å¢åŠ è¶…æ—¶)
# ===============================
def call_llm_api_cached(_provider, _model, _api_key, messages, max_tokens=4096, temperature=0.0):
    if not _api_key: return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"
    if _provider not in MODEL_CONFIGS: return False, {"error": f"æœªçŸ¥æä¾›å•† {_provider}"}, f"æœªçŸ¥æä¾›å•† {_provider}"

    cfg = MODEL_CONFIGS[_provider]
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](_api_key)
    payload = cfg["payload"](_model, messages, max_tokens=max_tokens, temperature=temperature)

    try:
        # å¢åŠ è¶…æ—¶è®¾ç½®åˆ°120ç§’
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        return True, response.json(), ""
    except requests.exceptions.Timeout:
        error_msg = "è¯·æ±‚è¶…æ—¶ã€‚æ¨¡å‹å¯èƒ½æ­£å¿™æˆ–ç½‘ç»œè¿æ¥è¾ƒæ…¢ã€‚å»ºè®®å°è¯•å…¶ä»–æ¨¡å‹æˆ–ç¨åå†è¯•ã€‚"
        return False, {"error": error_msg}, error_msg
    except requests.exceptions.RequestException as e:
        # å¯¹äº4xxå’Œ5xxé”™è¯¯ï¼Œæå–æ›´å¤šä¿¡æ¯
        error_msg = f"APIè¯·æ±‚å¤±è´¥: {str(e)}"
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_details = e.response.json()
                if 'error' in error_details:
                    error_msg += f" è¯¦æƒ…: {error_details['error']['message']}"
            except:
                error_msg += f" å“åº”å†…å®¹: {e.response.text[:200]}..." # åªæ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
        return False, {"error": error_msg}, error_msg
    except Exception as e:
        error_msg = f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        return False, {"error": error_msg}, error_msg

# ===============================
# è¯ç±»åˆ¤å®šä¸»å‡½æ•° (ä¼˜åŒ–Prompt)
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str, str]:
    if not word:
        return {}, "", "æœªçŸ¥", ""

    # è§„åˆ™æ–‡å­—è¯´æ˜ï¼ˆç»™æ¨¡å‹çœ‹ï¼Œè®©å®ƒè€è€å®å®æŒ‰è§„åˆ™æ¥åˆ¤æ–­ï¼‰
    full_rules_by_pos = {
        pos: "\n".join([
            f"- {r['name']}: {r['desc']}ï¼ˆç¬¦åˆ: {r['match_score']} åˆ†ï¼Œä¸ç¬¦åˆ: {r['mismatch_score']} åˆ†ï¼‰"
            for r in rules
        ])
        for pos, rules in RULE_SETS.items()
    }

    # ===== å¢å¼ºç‰ˆç³»ç»Ÿæç¤ºï¼šå¼ºåˆ¶è§„èŒƒè¾“å‡º =====
    system_msg = f"""ä½ æ˜¯ä¸€åä¸­æ–‡è¯æ³•ä¸è¯­æ³•æ–¹é¢çš„ä¸“å®¶ã€‚ç°åœ¨è¦åˆ†æè¯è¯­ã€Œ{word}ã€åœ¨ä¸‹åˆ—è¯ç±»ä¸­çš„è¡¨ç°ï¼š

- éœ€è¦åˆ¤æ–­çš„è¯ç±»ï¼šåè¯ã€åŠ¨è¯ã€ååŠ¨è¯
- è¯„åˆ†è§„åˆ™å·²ç»ç”±ç³»ç»Ÿå®šä¹‰ï¼Œä½ **ä¸è¦**è‡ªå·±è®¾è®¡åˆ†å€¼ï¼Œä¹Ÿ**ä¸è¦**åœ¨ JSON ä¸­ç»™å‡ºå…·ä½“æ•°å­—åˆ†æ•°
- ä½ åªéœ€è¦åˆ¤æ–­æ¯ä¸€æ¡è§„åˆ™æ˜¯â€œç¬¦åˆâ€è¿˜æ˜¯â€œä¸ç¬¦åˆâ€ï¼Œç¨‹åºä¼šè‡ªåŠ¨æ ¹æ® match_score / mismatch_score æ¢ç®—æˆæ­£åˆ†æˆ–è´Ÿåˆ†

ã€å„è¯ç±»çš„è§„åˆ™è¯´æ˜ï¼ˆä»…ä¾›ä½ åˆ¤æ–­ä½¿ç”¨ï¼‰ã€‘

ã€åè¯ã€‘
{full_rules_by_pos["åè¯"]}

ã€åŠ¨è¯ã€‘
{full_rules_by_pos["åŠ¨è¯"]}

ã€ååŠ¨è¯ã€‘
{full_rules_by_pos["ååŠ¨è¯"]}

ã€è¾“å‡ºè¦æ±‚ - å¿…é¡»ä¸¥æ ¼éµå®ˆã€‘
1. é¦–å…ˆè¾“å‡ºè¯¦ç»†çš„æ¨ç†è¿‡ç¨‹ï¼š
   - é€æ¡è§„åˆ™è¯´æ˜åˆ¤æ–­ä¾æ®ï¼Œå¹¶ä¸¾ä¾‹ï¼ˆå¯ä»¥è‡ªå·±é€ å¥ï¼‰
   - æ ¼å¼ç¤ºä¾‹ï¼š
     - ã€Œåè¯-N1_å¯å—æ•°é‡è¯ä¿®é¥°ï¼šç¬¦åˆã€‚ç†ç”±ï¼šâ€¦â€¦ã€‚ä¾‹å¥ï¼šâ€¦â€¦ã€‚ã€
     - ã€ŒåŠ¨è¯-V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼šä¸ç¬¦åˆã€‚ç†ç”±ï¼šâ€¦â€¦ã€‚ä¾‹å¥ï¼šâ€¦â€¦ã€‚ã€
   - å¿…é¡»è¦†ç›–ä¸‰ä¸ªè¯ç±»çš„æ‰€æœ‰è§„åˆ™ï¼Œä¸èƒ½é—æ¼

2. æ¨ç†è¿‡ç¨‹ç»“æŸåï¼Œå•ç‹¬è¾“å‡ºä¸€ä¸ª```json```ä»£ç å—ï¼ŒåŒ…å«ä»¥ä¸‹ç»“æ„ï¼š
{{
  "explanation": "å®Œæ•´çš„æ¨ç†è¿‡ç¨‹æ–‡æœ¬",
  "predicted_pos": "åè¯/åŠ¨è¯/ååŠ¨è¯ï¼ˆé€‰æ‹©å…¶ä¸€ï¼‰",
  "scores": {{
    "åè¯": {{
      "N1_å¯å—æ•°é‡è¯ä¿®é¥°": true/false,
      "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°": true/false,
      // å…¶ä»–åè¯è§„åˆ™...
    }},
    "åŠ¨è¯": {{
      "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°": true/false,
      // å…¶ä»–åŠ¨è¯è§„åˆ™...
    }},
    "ååŠ¨è¯": {{
      "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1": true/false,
      // å…¶ä»–ååŠ¨è¯è§„åˆ™...
    }}
  }}
}}

3. ç‰¹åˆ«æ³¨æ„ï¼š
   - JSONä¸­scoreså­—æ®µä¸‹çš„æ‰€æœ‰å€¼åªèƒ½æ˜¯trueæˆ–falseï¼Œä¸¥ç¦ä½¿ç”¨æ•°å­—ã€ä¸­æ–‡æˆ–å…¶ä»–å€¼
   - JSONå¿…é¡»æ˜¯åˆæ³•çš„ï¼Œä¸èƒ½æœ‰è¯­æ³•é”™è¯¯
   - JSONå¿…é¡»ç”¨```json```ä»£ç å—åŒ…è£¹ï¼Œä¸”å•ç‹¬æˆè¡Œ
   - ä¸è¦åœ¨JSONä¸­æ·»åŠ ä»»ä½•æ³¨é‡Š
"""

    # ç”¨æˆ·æç¤ºï¼šå†å¼ºè°ƒä¸€æ¬¡
    user_prompt = f"""
è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚åˆ†æè¯è¯­ã€Œ{word}ã€ã€‚

ç‰¹åˆ«æ³¨æ„ï¼š
- åœ¨ JSON çš„ scores éƒ¨åˆ†ï¼Œåªèƒ½ç”¨ true/false è¡¨ç¤ºâ€œæ˜¯å¦ç¬¦åˆè§„åˆ™â€ï¼Œä¸èƒ½ä½¿ç”¨ä»»ä½•æ•°å­—ã€ä¸­æ–‡æˆ–å…¶ä»–å€¼ã€‚
- explanation ä¸­å¿…é¡»å¯¹æ¯ä¸€æ¡è§„åˆ™å†™æ˜â€œç¬¦åˆ/ä¸ç¬¦åˆ + ç†ç”± + ä¾‹å¥â€ã€‚
- æœ€ç»ˆçš„JSONå¿…é¡»ç”¨```json```ä»£ç å—åŒ…è£¹ï¼Œç¡®ä¿å¯ä»¥è¢«ç¨‹åºæ­£ç¡®æå–ã€‚

è¯·å…ˆç»™å‡ºè¯¦ç»†æ¨ç†è¿‡ç¨‹ï¼Œç„¶ååœ¨æœ€åå•ç‹¬è¾“å‡ºJSONä»£ç å—ã€‚
"""

    with st.spinner("æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æï¼Œè¯·ç¨å€™..."):
        ok, resp_json, err_msg = call_llm_api_cached(
            _provider=provider,
            _model=model,
            _api_key=api_key,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt}
            ]
        )

    if not ok:
        st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {err_msg}")
        return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", f"è°ƒç”¨å¤±è´¥: {err_msg}"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, cleaned_json_text = extract_json_from_text(raw_text)

    # è§£æ JSON
    if parsed_json and isinstance(parsed_json, dict):
        explanation = parsed_json.get("explanation", "æ¨¡å‹æœªæä¾›è¯¦ç»†æ¨ç†è¿‡ç¨‹ã€‚")
        predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
        raw_scores = parsed_json.get("scores", {})
        st.success("âœ… æˆåŠŸè§£ææ¨¡å‹è¾“å‡ºçš„JSONç»“æ„")
    else:
        st.warning("âš ï¸ æœªèƒ½ä»æ¨¡å‹å“åº”ä¸­è§£æå‡ºæœ‰æ•ˆçš„JSONï¼Œå°†ä½¿ç”¨é»˜è®¤å¾—åˆ†")
        # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºæ¸…ç†åçš„JSONæ–‡æœ¬
        with st.expander("ğŸ“ è§£æå¤±è´¥çš„JSONæ–‡æœ¬ï¼ˆè°ƒè¯•ç”¨ï¼‰", expanded=False):
            st.code(cleaned_json_text, language="json")
        explanation = "æ— æ³•è§£ææ¨¡å‹è¾“å‡ºã€‚åŸå§‹å“åº”ï¼š\n" + raw_text
        predicted_pos = "æœªçŸ¥"
        raw_scores = {}

    # --- å…³é”®ï¼šåˆå§‹åŒ–æ‰€æœ‰è¯ç±»çš„å¾—åˆ†å­—å…¸ ---
    scores_out = {pos: {} for pos in RULE_SETS.keys()}

    # åªæŠŠâ€œç¬¦åˆ/ä¸ç¬¦åˆâ€è½¬æˆå…·ä½“åˆ†å€¼ï¼ˆæ­£åˆ† / è´Ÿåˆ†ï¼‰
    for pos, rules in RULE_SETS.items():
        raw_pos_scores = raw_scores.get(pos, {})
        if isinstance(raw_pos_scores, dict):
            for k, v in raw_pos_scores.items():
                normalized_key = normalize_key(k, rules)
                if normalized_key:
                    # æ‰¾åˆ°å½“å‰è§„åˆ™çš„å®šä¹‰
                    rule_def = next(r for r in rules if r["name"] == normalized_key)
                    # ä½¿ç”¨ map_to_allowed_scoreï¼štrue/false/â€œæ˜¯/å¦â€ç­‰ â†’ match_score / mismatch_score
                    scores_out[pos][normalized_key] = map_to_allowed_score(rule_def, v)

    # ä¿è¯æ¯æ¡è§„åˆ™éƒ½æœ‰å¾—åˆ†ï¼Œæ²¡æœ‰å°±é»˜è®¤ 0 åˆ†ï¼ˆè¯´æ˜æ¨¡å‹å®Œå…¨æ²¡æåˆ°ï¼‰
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            rule_name = rule["name"]
            if rule_name not in scores_out[pos]:
                scores_out[pos][rule_name] = 0

    return scores_out, raw_text, predicted_pos, explanation

# ===============================
# é›·è¾¾å›¾
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    if not scores_norm:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return
    categories = list(scores_norm.keys())
    if not categories:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆè¯ç±»ã€‚")
        return
    values = list(scores_norm.values())
    
    # é—­åˆé›·è¾¾å›¾
    categories += [categories[0]]
    values += [values[0]]

    fig = go.Figure(data=[go.Scatterpolar(r=values, theta=categories, fill="toself", name="éš¶å±åº¦")])
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=False,
        title=dict(text=title, x=0.5, font=dict(size=16))
    )
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# ä¸»é¡µé¢é€»è¾‘
# ===============================
def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»")
    
    # --- é¡¶éƒ¨å›ºå®šæ§åˆ¶åŒº ---
    control_container = st.container()
    with control_container:
        col1, col2, col3 = st.columns([2, 1, 3])
        
        with col1:
            st.subheader("âš™ï¸ æ¨¡å‹è®¾ç½®")
            selected_model_display_name = st.selectbox("é€‰æ‹©å¤§æ¨¡å‹", list(MODEL_OPTIONS.keys()), key="model_select")
            selected_model_info = MODEL_OPTIONS[selected_model_display_name]
            
            # æ£€æŸ¥API Keyæ˜¯å¦å­˜åœ¨
            if not selected_model_info["api_key"]:
                st.error(f"âŒ æœªæ‰¾åˆ° {selected_model_display_name} çš„API Key")
                st.info(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ **{selected_model_info['env_var']}** åé‡è¯•")
                st.code(f"# Linux/Mac\n export {selected_model_info['env_var']}='ä½ çš„API Key'\n\n# Windows\n set {selected_model_info['env_var']}='ä½ çš„API Key'", language="bash")
        
        with col2:
            st.subheader("ğŸ”— è¿æ¥æµ‹è¯•")
            if not selected_model_info["api_key"]:
                st.disabled(True)
                st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary", disabled=True)
            else:
                if st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary"):
                    with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„pingè¯·æ±‚æ¥æµ‹è¯•è¿æ¥
                        ok, _, err_msg = call_llm_api_cached(
                            _provider=selected_model_info["provider"],
                            _model=selected_model_info["model"],
                            _api_key=selected_model_info["api_key"],
                            messages=[{"role": "user", "content": "è¯·å›å¤'pong'"}],
                            max_tokens=10
                        )
                    if ok:
                        st.success("âœ… æ¨¡å‹é“¾æ¥æµ‹è¯•æˆåŠŸï¼")
                    else:
                        st.error(f"âŒ æ¨¡å‹é“¾æ¥æµ‹è¯•å¤±è´¥: {err_msg}")

        with col3:
            st.subheader("ğŸ”¤ è¯è¯­è¾“å…¥")
            word = st.text_input("è¯·è¾“å…¥è¦åˆ†æçš„æ±‰è¯­è¯è¯­", placeholder="ä¾‹å¦‚ï¼šè‹¹æœã€è·‘ã€ç¾ä¸½...", key="word_input")
            
            # å¼€å§‹åˆ†ææŒ‰é’®ï¼ˆAPI Keyä¸ºç©ºæ—¶ç¦ç”¨ï¼‰
            analyze_button = st.button(
                "ğŸš€ å¼€å§‹åˆ†æ", 
                type="primary",
                disabled=not (selected_model_info["api_key"] and word)
            )

    st.markdown("---")

    
    # --- ä½¿ç”¨è¯´æ˜ ---
    info_container = st.container()
    with info_container:
        with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜", expanded=False):
            st.info("""
            1. åœ¨ä¸Šæ–¹çš„â€œè¯è¯­è¾“å…¥â€æ¡†ä¸­è¾“å…¥ä¸€ä¸ªæ±‰è¯­è¯ã€‚
            2. ï¼ˆå¯é€‰ï¼‰åœ¨æ¨¡å‹é€‰æ‹©åŒºåŸŸç‚¹å‡»å‘ä¸‹ç®­å¤´å±•å¼€ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ã€‚
            3. ï¼ˆå¯é€‰ï¼‰ç‚¹å‡»â€œæµ‹è¯•æ¨¡å‹é“¾æ¥â€æŒ‰é’®ï¼Œç¡®è®¤æ‰€é€‰æ¨¡å‹å¯ä»¥æ­£å¸¸è®¿é—®ã€‚
            4. ç‚¹å‡»â€œå¼€å§‹åˆ†æâ€æŒ‰é’®ï¼Œç³»ç»Ÿå°†ä½¿ç”¨é€‰å®šçš„å¤§æ¨¡å‹åˆ†æè¯¥è¯è¯­çš„è¯ç±»éš¶å±åº¦ã€‚
            5. åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨ä¸‹æ–¹ï¼ŒåŒ…æ‹¬éš¶å±åº¦æ’åã€è¯¦ç»†å¾—åˆ†ã€æ¨ç†è¿‡ç¨‹å’ŒåŸå§‹å“åº”ã€‚
            """)

     # --- ç»“æœæ˜¾ç¤ºåŒº ---
    if analyze_button and word and selected_model_info["api_key"]:
        status_placeholder = st.empty()
        status_placeholder.info(f"æ­£åœ¨ä¸ºè¯è¯­ã€Œ{word}ã€å¯åŠ¨åˆ†æ...")

        scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
            word=word,
            provider=selected_model_info["provider"],
            model=selected_model_info["model"],
            api_key=selected_model_info["api_key"]
        )
        
        status_placeholder.empty()
        
        membership = calculate_membership(scores_all)
        st.success(f'**åˆ†æå®Œæˆ**ï¼šè¯è¯­ã€Œ{word}ã€æœ€å¯èƒ½çš„è¯ç±»æ˜¯ ã€{predicted_pos}ã€‘ï¼Œéš¶å±åº¦ä¸º {membership.get(predicted_pos, 0):.4f}')
        
        col_results_1, col_results_2 = st.columns(2)
        
        with col_results_1:
            st.subheader("ğŸ† è¯ç±»éš¶å±åº¦æ’å")
            top10 = get_top_10_positions(membership)
            top10_df = pd.DataFrame(top10, columns=["è¯ç±»", "éš¶å±åº¦"])
            top10_df["éš¶å±åº¦"] = top10_df["éš¶å±åº¦"].apply(lambda x: f"{x:.4f}")
            st.table(top10_df)
            
            st.subheader("ğŸ“Š è¯ç±»éš¶å±åº¦é›·è¾¾å›¾")
            plot_radar_chart_streamlit(dict(top10), f"ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦åˆ†å¸ƒ")

        with col_results_2:
            st.subheader("ğŸ“‹ å„è¯ç±»è¯¦ç»†å¾—åˆ†")
            
            # 1. è®¡ç®—æ‰€æœ‰è¯ç±»çš„æ€»åˆ†å¹¶æ’åºï¼Œå–å‰10å
            pos_total_scores = {pos: sum(scores_all[pos].values()) for pos in RULE_SETS.keys()}
            # æŒ‰æ€»åˆ†é™åºæ’åºï¼Œå–å‰10
            top10_pos = sorted(pos_total_scores.items(), key=lambda x: x[1], reverse=True)[:10]
            
            # 2. åªæ˜¾ç¤ºæ’åå‰10çš„è¯ç±»
            for pos, total_score in top10_pos:
                # æ‰¾åˆ°è¯¥è¯ç±»ä¸‹å¾—åˆ†æœ€é«˜çš„è§„åˆ™
                max_rule = max(scores_all[pos].items(), key=lambda x: x[1], default=("æ— ", 0))
                
                # åˆ›å»ºexpanderï¼Œæ˜¾ç¤ºè¯ç±»åç§°ã€æ€»åˆ†å’Œæœ€é«˜åˆ†è§„åˆ™
                with st.expander(f"**{pos}** (æ€»åˆ†: {total_score}, æœ€é«˜åˆ†è§„åˆ™: {max_rule[0]} - {max_rule[1]}åˆ†)"):
                    # æ˜¾ç¤ºè¯¥è¯ç±»ä¸‹çš„æ‰€æœ‰è§„åˆ™å¾—åˆ†ï¼ˆæŒ‰è§„åˆ™å¾—åˆ†é™åºæ’åˆ—ï¼‰
                    rule_data = []
                    for rule in RULE_SETS[pos]:
                        rule_score = scores_all[pos][rule["name"]]
                        rule_data.append({
                            "è§„åˆ™ä»£ç ": rule["name"],
                            "è§„åˆ™æè¿°": rule["desc"],
                            "å¾—åˆ†": rule_score
                        })
                    
                    # æŒ‰å¾—åˆ†é™åºæ’åºè§„åˆ™ï¼Œè®©é«˜åˆ†è§„åˆ™æ’åœ¨å‰é¢
                    rule_data_sorted = sorted(rule_data, key=lambda x: x["å¾—åˆ†"], reverse=True)
                    rule_df = pd.DataFrame(rule_data_sorted)
                    
                    # è´Ÿåˆ†æ ‡çº¢
                    styled_df = rule_df.style.applymap(
                        lambda x: "color: #ff4b4b; font-weight: bold" if isinstance(x, int) and x < 0 else "",
                        subset=["å¾—åˆ†"]
                    )
                    
                    st.dataframe(
                        styled_df,
                        use_container_width=True,
                        height=min(len(rule_df) * 30 + 50, 800)
                    )
            
            st.subheader("ğŸ“¥ æ¨¡å‹åŸå§‹å“åº”")
            with st.expander("ç‚¹å‡»å±•å¼€æŸ¥çœ‹åŸå§‹å“åº”", expanded=False):
                st.code(raw_text, language="text")
            
            st.subheader("ğŸ” æ¨¡å‹æ¨ç†è¿‡ç¨‹")
            with st.expander("ç‚¹å‡»å±•å¼€æŸ¥çœ‹æ¨ç†è¿‡ç¨‹", expanded=False):
                st.markdown(explanation)

if __name__ == "__main__":
    main()

# ===============================
# é¡µé¢åº•éƒ¨è¯´æ˜
# ===============================
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:#666;'>"
    "Â© 2025 æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±» "
    "</div>",
    unsafe_allow_html=True
)

