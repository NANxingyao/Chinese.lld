import streamlit as st
import requests
import json
import re
import os
import time
import pandas as pd
import plotly.graph_objects as go
from typing import Tuple, Dict, Any, List, Optional
from concurrent.futures import ThreadPoolExecutor, as_completed
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# ===============================
# å…¨å±€é…ç½®ï¼šå¹¶å‘/è¿æ¥æ± /é‡è¯•
# ===============================
# çº¿ç¨‹æ± å¤§å°ï¼ˆæ ¹æ®APIå¹¶å‘é™åˆ¶è°ƒæ•´ï¼‰
MAX_WORKERS = 5
# è¿æ¥æ± é…ç½®
SESSION = requests.Session()
RETRY_STRATEGY = Retry(
    total=2,  # é‡è¯•æ¬¡æ•°
    backoff_factor=0.1,  # é‡è¯•é—´éš”
    status_forcelist=[429, 500, 502, 503, 504],  # é‡è¯•çš„çŠ¶æ€ç 
    allowed_methods=["POST"]
)
ADAPTER = HTTPAdapter(max_retries=RETRY_STRATEGY, pool_connections=10, pool_maxsize=10)
SESSION.mount("https://", ADAPTER)
SESSION.mount("http://", ADAPTER)

# ===============================
# é¡µé¢é…ç½®
# ===============================
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»ï¼ˆå¹¶å‘æé€Ÿç‰ˆï¼‰",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items=None
)

# è‡ªå®šä¹‰CSS
hide_streamlit_style = """
<style>
header {visibility: hidden;}
footer {visibility: hidden;}
.dataframe {font-size: 12px;}
[data-testid="stSidebar"] {display: none !important;}
.stApp > div:first-child {padding-top: 2rem;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# ===============================
# æ¨¡å‹é…ç½®ï¼ˆä»…ç¯å¢ƒå˜é‡ï¼‰
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "input": {"messages": messages}, 
            "parameters": {"max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0),},
        },
    },
}

MODEL_OPTIONS = {
    "DeepSeek Chat": {
        "provider": "deepseek", 
        "model": "deepseek-chat", 
        "api_key": os.getenv("DEEPSEEK_API_KEY", "sk-759d66c83f374a2aaac0db5814ccb016"),
        "env_var": "DEEPSEEK_API_KEY"
    },
    "OpenAI GPT-4oï¼ˆæµ‹è¯•ï¼‰": {
        "provider": "openai", 
        "model": "gpt-4o-mini", 
        "api_key": os.getenv("OPENAI_API_KEY", "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"),
        "env_var": "OPENAI_API_KEY"
    },
    "Moonshotï¼ˆKimiï¼‰": {
        "provider": "moonshot", 
        "model": "moonshot-v1-32k", 
        "api_key": os.getenv("MOONSHOT_API_KEY", "sk-l5FvRWegjM5DEk4AU71YPQ1QgvFPTHZIJOmq6qdssPY4sNtE"),
        "env_var": "MOONSHOT_API_KEY"
    },
    "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰": {
        "provider": "qwen", 
        "model": "qwen-max", 
        "api_key": os.getenv("QWEN_API_KEY", "sk-b3f7a1153e6f4a44804a296038aa86c5"),
        "env_var": "QWEN_API_KEY"
    },
}

# ===============================
# è¯ç±»è§„åˆ™ï¼ˆç›´å‡ºåˆ†æ•°ï¼‰
# ===============================
RULE_SETS = {
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œæˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®", "match_score": 10, "mismatch_score": -10},
    ],
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®š", "match_score": 10, "mismatch_score": -10},
        {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰\"VVã€Vä¸€V\"ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­ï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åæé—®", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š\"ä¹‹åå¯¹æ€§è´¨çš„ç¨‹åº¦è¿›è¡Œæé—®", "match_score": 10, "mismatch_score": -10},
        {"name": "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
    ]
}

MAX_SCORES = {pos: sum(abs(r["match_score"]) for r in rules) for pos, rules in RULE_SETS.items()}

# ===============================
# æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆå¹¶å‘ä¼˜åŒ–ï¼‰
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    """æå–æ¨¡å‹å“åº”æ–‡æœ¬ï¼ˆé€‚é…å¤šæ¨¡å‹æ ¼å¼ï¼‰"""
    if not isinstance(resp_json, dict): return ""
    try:
        # é€šä¹‰åƒé—®
        if "output" in resp_json and "text" in resp_json["output"]:
            return resp_json["output"]["text"]
        # OpenAIç³»åˆ—
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
            for k in ("content", "text"):
                if k in choice: return choice[k]
    except Exception: 
        pass
    return json.dumps(resp_json, ensure_ascii=False)

def fix_common_json_errors(json_str: str) -> str:
    """è‡ªåŠ¨ä¿®å¤JSONæ ¼å¼é”™è¯¯ï¼ˆé«˜æ€§èƒ½ç‰ˆï¼‰"""
    json_str = re.sub(r'([{,]\s*)([\w_]+)(\s*:)', r'\1"\2"\3', json_str)  # è¡¥é”®å¼•å·
    json_str = re.sub(r"([{,]\s*)'([\w_]+)'(\s*:)", r'\1"\2"\3', json_str)  # å•å¼•å·æ”¹åŒå¼•å·
    json_str = re.sub(r'("[\w_]+":\s*[^,}]+)\s+("[\w_]+":)', r'\1,\2', json_str)  # è¡¥é€—å·
    json_str = re.sub(r',\s*([}\]])', r'\1', json_str)  # åˆ æœ«å°¾é€—å·
    json_str = json_str.replace("ï¼š", ":").replace("ï¼Œ", ",").replace("â€œ", '"').replace("â€", '"')  # ä¸­æ–‡æ ‡ç‚¹è½¬è‹±æ–‡
    return json_str.strip()

def extract_json_from_text(text: str) -> Tuple[Optional[dict], str]:
    """å¹¶å‘å‹å¥½çš„JSONæå–ï¼ˆä¼˜å…ˆåˆ†éš”ç¬¦ï¼‰"""
    if not text:
        return None, ""

    # 1. ä¸“å±åˆ†éš”ç¬¦æå–
    start_marker = "====JSON_BEGIN===="
    end_marker = "====JSON_END===="
    start_idx = text.find(start_marker)
    end_idx = text.find(end_marker)
    if start_idx != -1 and end_idx > start_idx:
        json_str = text[start_idx + len(start_marker):end_idx].strip()
        json_str = fix_common_json_errors(json_str)
        try:
            parsed = json.loads(json_str)
            return parsed, json_str
        except Exception as e:
            st.warning(f"åˆ†éš”ç¬¦JSONè§£æå¤±è´¥ï¼š{str(e)[:80]}")
            return None, json_str

    # 2. ä»£ç å—æå–
    json_block_pattern = re.compile(r'```(?:json)?\s*\n?([\s\S]*?)\n?```', re.IGNORECASE)
    for json_str in json_block_pattern.findall(text):
        json_str = fix_common_json_errors(json_str.strip())
        try:
            parsed = json.loads(json_str)
            return parsed, json_str
        except:
            continue

    # 3. å¤§æ‹¬å·æå–
    for json_str in re.findall(r'\{[\s\S]*\}', text):
        json_str = fix_common_json_errors(json_str.strip())
        try:
            parsed = json.loads(json_str)
            return parsed, json_str
        except:
            continue

    return None, text

def validate_score_worker(rule: dict, raw_val: Any) -> Tuple[str, int]:
    """å•è§„åˆ™åˆ†æ•°éªŒè¯ï¼ˆçº¿ç¨‹æ± ä»»åŠ¡ï¼‰"""
    rule_name = rule["name"]
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    
    # æ•°å­—ç›´æ¥éªŒè¯
    if isinstance(raw_val, (int, float)):
        raw_val = int(raw_val)
        if raw_val in (match_score, mismatch_score):
            return rule_name, raw_val
    
    # å­—ç¬¦ä¸²è½¬æ•°å­—
    if isinstance(raw_val, str):
        try:
            num_val = int(raw_val.strip())
            if num_val in (match_score, mismatch_score):
                return rule_name, num_val
        except:
            pass
    
    # å…œåº•è¿”å›ä¸åŒ¹é…åˆ†
    return rule_name, mismatch_score

def validate_scores_concurrent(pos: str, raw_scores: dict) -> Dict[str, int]:
    """å¤šçº¿ç¨‹éªŒè¯è¯ç±»åˆ†æ•°"""
    rules = RULE_SETS[pos]
    scores_out = {}
    
    # çº¿ç¨‹æ± å¹¶è¡ŒéªŒè¯è§„åˆ™åˆ†æ•°
    with ThreadPoolExecutor(max_workers=len(rules)) as executor:
        futures = {
            executor.submit(validate_score_worker, rule, raw_scores.get(rule["name"], rule["mismatch_score"])): rule
            for rule in rules
        }
        for future in as_completed(futures):
            rule_name, score = future.result()
            scores_out[rule_name] = score
    
    # è¡¥å…¨ç¼ºå¤±è§„åˆ™
    for rule in rules:
        if rule["name"] not in scores_out:
            scores_out[rule["name"]] = rule["mismatch_score"]
    
    return scores_out

def calculate_membership_concurrent(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    """å¹¶è¡Œè®¡ç®—éš¶å±åº¦"""
    membership = {}
    with ThreadPoolExecutor(max_workers=len(RULE_SETS)) as executor:
        futures = {
            executor.submit(lambda p: sum(scores_all[p].values()) / 100, pos): pos
            for pos in RULE_SETS.keys()
        }
        for future in as_completed(futures):
            pos = futures[future]
            normalized = future.result()
            membership[pos] = max(-1.0, min(1.0, normalized))
    return membership

# ===============================
# å¹¶å‘APIè°ƒç”¨å‡½æ•°
# ===============================
def call_llm_api_concurrent(provider: str, model: str, api_key: str, messages: list) -> Tuple[bool, Dict[str, Any], str]:
    """å¹¶å‘å®‰å…¨çš„APIè°ƒç”¨ï¼ˆè¿æ¥æ± +è¶…æ—¶ï¼‰"""
    if not api_key:
        return False, {"error": "API Keyä¸ºç©º"}, "API Keyæœªæä¾›"
    if provider not in MODEL_CONFIGS:
        return False, {"error": f"æœªçŸ¥æä¾›å•†{provider}"}, f"æœªçŸ¥æä¾›å•†{provider}"

    cfg = MODEL_CONFIGS[provider]
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](api_key)
    payload = cfg["payload"](model, messages, max_tokens=4096, temperature=0.0)

    try:
        # è¿æ¥æ± è¯·æ±‚ï¼ˆè¶…æ—¶120ç§’ï¼‰
        response = SESSION.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        return True, response.json(), ""
    except requests.exceptions.Timeout:
        return False, {"error": "è¯·æ±‚è¶…æ—¶"}, "æ¨¡å‹å“åº”è¶…æ—¶ï¼ˆ120ç§’ï¼‰"
    except requests.exceptions.RequestException as e:
        err_msg = f"APIè¯·æ±‚å¤±è´¥: {str(e)[:100]}"
        if hasattr(e, 'response') and e.response is not None:
            try:
                err_detail = e.response.json().get("error", {}).get("message", "")
                err_msg += f" è¯¦æƒ…: {err_detail[:50]}"
            except:
                err_msg += f" å“åº”: {e.response.text[:50]}"
        return False, {"error": err_msg}, err_msg
    except Exception as e:
        return False, {"error": str(e)}, f"æœªçŸ¥é”™è¯¯: {str(e)[:50]}"

def analyze_single_word(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str, str]:
    """å•è¯è¯­åˆ†æï¼ˆå¹¶å‘ä»»åŠ¡ï¼‰"""
    # æ„å»ºå¼ºçº¦æŸPromptï¼ˆç›´å‡ºåˆ†æ•°ï¼‰
    rule_text = []
    for pos, rules in RULE_SETS.items():
        rule_text.append(f"ã€{pos}ã€‘")
        for r in rules:
            rule_text.append(f"- {r['name']}: {r['desc']}ï¼ˆç¬¦åˆå¡«{r['match_score']}åˆ†ï¼Œä¸ç¬¦åˆå¡«{r['mismatch_score']}åˆ†ï¼‰")
    rule_text = "\n".join(rule_text)

    system_msg = f"""ä½ æ˜¯ä¸­æ–‡è¯æ³•ä¸“å®¶ï¼Œåˆ†æè¯è¯­ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦ï¼Œå¿…é¡»ä¸¥æ ¼è¾“å‡ºæ•°å­—åˆ†æ•°ï¼

ã€è§„åˆ™ã€‘
{rule_text}

ã€è¾“å‡ºæ ¼å¼ã€‘
1. æ¨ç†è¿‡ç¨‹ï¼ˆé€æ¡è¯´æ˜ç†ç”±+ä¾‹å¥+åˆ†æ•°ï¼‰
2. åˆ†éš”ç¬¦åŒ…è£¹çš„JSONï¼ˆä»…æ•°å­—åˆ†æ•°ï¼Œæ— å¸ƒå°”å€¼ï¼‰ï¼š
====JSON_BEGIN====
{{
  "explanation": "æ¨ç†è¿‡ç¨‹æ–‡æœ¬",
  "predicted_pos": "åè¯/åŠ¨è¯/ååŠ¨è¯",
  "scores": {{
    "åè¯": {{
      "N1_å¯å—æ•°é‡è¯ä¿®é¥°": 10,
      "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°": 20,
      ...
    }},
    "åŠ¨è¯": {{...}},
    "ååŠ¨è¯": {{...}}
  }}
}}
====JSON_END====

ã€å¼ºåˆ¶è¦æ±‚ã€‘
- JSONä¸­æ‰€æœ‰å€¼å¿…é¡»æ˜¯æ•´æ•°ï¼ˆå¦‚10ã€-20ã€0ï¼‰ï¼Œä¸èƒ½ç”¨true/false/å­—ç¬¦ä¸²
- é”®å¿…é¡»ç”¨åŒå¼•å·ï¼Œæ•°å­—ä¸åŠ å¼•å·
- åˆ†éš”ç¬¦å•ç‹¬æˆè¡Œï¼Œä¸èƒ½ä¿®æ”¹
"""

    messages = [
        {"role": "system", "content": system_msg},
        {"role": "user", "content": f"åˆ†æè¯è¯­ã€Œ{word}ã€ï¼Œè¾“å‡ºæ¨ç†è¿‡ç¨‹å’Œè§„èŒƒJSONï¼ˆæ‰€æœ‰è§„åˆ™å¡«æ•°å­—åˆ†æ•°ï¼‰ã€‚"}
    ]

    # è°ƒç”¨API
    ok, resp_json, err_msg = call_llm_api_concurrent(provider, model, api_key, messages)
    if not ok:
        st.error(f"è¯ã€Œ{word}ã€è°ƒç”¨å¤±è´¥: {err_msg}")
        return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", err_msg

    # æå–å“åº”
    raw_text = extract_text_from_response(resp_json)
    parsed_json, _ = extract_json_from_text(raw_text)

    # åˆå§‹åŒ–é»˜è®¤åˆ†æ•°
    default_scores = {
        pos: {r["name"]: r["mismatch_score"] for r in RULE_SETS[pos]} 
        for pos in RULE_SETS.keys()
    }

    if not parsed_json or not isinstance(parsed_json, dict):
        return default_scores, raw_text, "æœªçŸ¥", "JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤åˆ†æ•°"

    # æå–åŸºç¡€ä¿¡æ¯
    explanation = parsed_json.get("explanation", "æ— æ¨ç†è¿‡ç¨‹")
    predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
    raw_scores = parsed_json.get("scores", {})

    # å¤šçº¿ç¨‹éªŒè¯æ‰€æœ‰è¯ç±»åˆ†æ•°
    scores_out = {}
    with ThreadPoolExecutor(max_workers=len(RULE_SETS)) as executor:
        futures = {
            executor.submit(validate_scores_concurrent, pos, raw_scores.get(pos, {})): pos
            for pos in RULE_SETS.keys()
        }
        for future in as_completed(futures):
            pos = futures[future]
            scores_out[pos] = future.result()

    return scores_out, raw_text, predicted_pos, explanation

def analyze_batch_words(words: list, provider: str, model: str, api_key: str) -> Dict[str, dict]:
    """æ‰¹é‡åˆ†æè¯è¯­ï¼ˆæœ€é«˜å¹¶å‘MAX_WORKERSï¼‰"""
    results = {}
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        # æäº¤æ‰€æœ‰ä»»åŠ¡
        futures = {
            executor.submit(analyze_single_word, word, provider, model, api_key): word
            for word in words if word.strip()
        }
        # å®æ—¶æ›´æ–°è¿›åº¦
        progress_bar = st.progress(0)
        completed = 0
        total = len(futures)

        for future in as_completed(futures):
            word = futures[future]
            try:
                scores_all, raw_text, predicted_pos, explanation = future.result()
                membership = calculate_membership_concurrent(scores_all)
                results[word] = {
                    "scores_all": scores_all,
                    "raw_text": raw_text,
                    "predicted_pos": predicted_pos,
                    "explanation": explanation,
                    "membership": membership
                }
            except Exception as e:
                results[word] = {"error": f"åˆ†æå¤±è´¥: {str(e)[:50]}"}
            # æ›´æ–°è¿›åº¦
            completed += 1
            progress_bar.progress(completed / total)
        progress_bar.empty()

    return results

# ===============================
# é¡µé¢ä¸»é€»è¾‘
# ===============================
def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»ï¼ˆå¹¶å‘æé€Ÿç‰ˆï¼‰")

    # é¡¶éƒ¨æ§åˆ¶åŒº
    col1, col2, col3 = st.columns([2, 1, 3])
    with col1:
        st.subheader("âš™ï¸ æ¨¡å‹è®¾ç½®")
        selected_model_name = st.selectbox("é€‰æ‹©å¤§æ¨¡å‹", list(MODEL_OPTIONS.keys()), key="model_select")
        selected_model = MODEL_OPTIONS[selected_model_name]

        # æ£€æŸ¥API Key
        if not selected_model["api_key"]:
            st.error(f"âŒ æœªé…ç½® {selected_model_name} çš„API Key")
            st.code(f"# è®¾ç½®ç¯å¢ƒå˜é‡\n# Linux/Mac: export {selected_model['env_var']}='ä½ çš„API Key'\n# Windows: set {selected_model['env_var']}='ä½ çš„API Key'", language="bash")

    with col2:
        st.subheader("ğŸ”— è¿æ¥æµ‹è¯•")
        test_btn = st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", disabled=not selected_model["api_key"])
        if test_btn:
            with st.spinner("æµ‹è¯•ä¸­..."):
                ok, _, err_msg = call_llm_api_concurrent(
                    selected_model["provider"],
                    selected_model["model"],
                    selected_model["api_key"],
                    [{"role": "user", "content": "å›å¤pong"}]
                )
            if ok:
                st.success("âœ… æ¨¡å‹é“¾æ¥æˆåŠŸï¼")
            else:
                st.error(f"âŒ é“¾æ¥å¤±è´¥: {err_msg}")

    with col3:
        st.subheader("ğŸ”¤ è¯è¯­è¾“å…¥ï¼ˆæ”¯æŒæ‰¹é‡ï¼‰")
        input_mode = st.radio("è¾“å…¥æ¨¡å¼", ["å•è¯è¯­", "æ‰¹é‡è¯è¯­"], horizontal=True)
        if input_mode == "å•è¯è¯­":
            word = st.text_input("è¾“å…¥å•ä¸ªè¯è¯­", placeholder="ä¾‹å¦‚ï¼šè‹¹æœã€è·‘ã€ç ”ç©¶", key="single_word")
            analyze_btn = st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary", disabled=not (selected_model["api_key"] and word))
        else:
            words_text = st.text_area("æ‰¹é‡è¾“å…¥è¯è¯­ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰", placeholder="è‹¹æœ\nè·‘\nç ”ç©¶\nç¾ä¸½", key="batch_words")
            analyze_btn = st.button("ğŸš€ æ‰¹é‡åˆ†æ", type="primary", disabled=not (selected_model["api_key"] and words_text.strip()))

    st.markdown("---")

    # ä½¿ç”¨è¯´æ˜
    with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜ï¼ˆå¹¶å‘ç‰ˆï¼‰", expanded=False):
        st.info("""
        1. å•è¯è¯­æ¨¡å¼ï¼šè¾“å…¥ä¸€ä¸ªè¯è¯­ï¼Œç‚¹å‡»åˆ†æï¼Œç§’çº§è¿”å›ç»“æœï¼ˆå¹¶å‘æé€Ÿ30%+ï¼‰ï¼›
        2. æ‰¹é‡æ¨¡å¼ï¼šæ¯è¡Œè¾“å…¥ä¸€ä¸ªè¯è¯­ï¼Œæœ€å¤šåŒæ—¶åˆ†æ5ä¸ªï¼ˆå¯è°ƒæ•´MAX_WORKERSï¼‰ï¼›
        3. æ¨¡å‹é“¾æ¥æµ‹è¯•ï¼šéªŒè¯API Keyæœ‰æ•ˆæ€§ï¼Œé¿å…åˆ†æå¤±è´¥ï¼›
        4. å¹¶å‘ä¼˜åŒ–ï¼šAPIè°ƒç”¨/åˆ†æ•°è®¡ç®—å¹¶è¡Œå¤„ç†ï¼Œå¤§å¹…å‡å°‘ç­‰å¾…æ—¶é—´ã€‚
        """)

    # åˆ†æé€»è¾‘
    if analyze_btn and selected_model["api_key"]:
        start_time = time.time()
        provider = selected_model["provider"]
        model = selected_model["model"]
        api_key = selected_model["api_key"]

        if input_mode == "å•è¯è¯­" and word:
            # å•è¯è¯­åˆ†æï¼ˆå¹¶å‘åˆ†æ•°è®¡ç®—ï¼‰
            st.info(f"å¼€å§‹åˆ†æè¯è¯­ã€Œ{word}ã€ï¼ˆå¹¶å‘æ¨¡å¼ï¼‰...")
            scores_all, raw_text, predicted_pos, explanation = analyze_single_word(word, provider, model, api_key)
            membership = calculate_membership_concurrent(scores_all)

            # ç»“æœå±•ç¤º
            st.success(f"âœ… åˆ†æå®Œæˆï¼ˆè€—æ—¶: {time.time()-start_time:.2f}ç§’ï¼‰ï¼šã€Œ{word}ã€â†’ ã€{predicted_pos}ã€‘ï¼ˆéš¶å±åº¦: {membership.get(predicted_pos, 0):.4f}ï¼‰")
            
            col_res1, col_res2 = st.columns(2)
            with col_res1:
                st.subheader("ğŸ† éš¶å±åº¦æ’å")
                top10 = sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]
                st.table(pd.DataFrame(top10, columns=["è¯ç±»", "éš¶å±åº¦"]).round(4))

                st.subheader("ğŸ“Š éš¶å±åº¦é›·è¾¾å›¾")
                categories = [x[0] for x in top10] + [top10[0][0]]
                values = [x[1] for x in top10] + [top10[0][1]]
                fig = go.Figure(go.Scatterpolar(r=values, theta=categories, fill="toself"))
                fig.update_layout(polar=dict(radialaxis=dict(range=[0,1])), title=f"ã€Œ{word}ã€éš¶å±åº¦åˆ†å¸ƒ")
                st.plotly_chart(fig, use_container_width=True)

            with col_res2:
                st.subheader("ğŸ“‹ è¯¦ç»†å¾—åˆ†")
                for pos in RULE_SETS.keys():
                    total = sum(scores_all[pos].values())
                    with st.expander(f"**{pos}** (æ€»åˆ†: {total})"):
                        df = pd.DataFrame([
                            {"è§„åˆ™": r["name"], "æè¿°": r["desc"], "å¾—åˆ†": scores_all[pos][r["name"]]}
                            for r in RULE_SETS[pos]
                        ])
                        df_styled = df.style.applymap(lambda x: "color: red; font-weight: bold" if isinstance(x, int) and x < 0 else "", subset=["å¾—åˆ†"])
                        st.dataframe(df_styled, use_container_width=True)

                st.subheader("ğŸ” æ¨ç†è¿‡ç¨‹")
                st.text_area("", value=explanation, height=200)

        else:
            # æ‰¹é‡åˆ†æ
            words = [w.strip() for w in words_text.split("\n") if w.strip()]
            if not words:
                st.warning("è¯·è¾“å…¥è‡³å°‘ä¸€ä¸ªè¯è¯­ï¼")
                return

            st.info(f"å¼€å§‹æ‰¹é‡åˆ†æ {len(words)} ä¸ªè¯è¯­ï¼ˆå¹¶å‘æ•°: {MAX_WORKERS}ï¼‰...")
            results = analyze_batch_words(words, provider, model, api_key)

            # æ‰¹é‡ç»“æœå±•ç¤º
            st.success(f"âœ… æ‰¹é‡åˆ†æå®Œæˆï¼ˆæ€»è€—æ—¶: {time.time()-start_time:.2f}ç§’ï¼‰")
            for word, res in results.items():
                if "error" in res:
                    st.error(f"ã€Œ{word}ã€: {res['error']}")
                    continue

                with st.expander(f"ğŸ“ è¯è¯­ï¼š{word} â†’ é¢„æµ‹è¯ç±»ï¼š{res['predicted_pos']}", expanded=False):
                    col1, col2 = st.columns(2)
                    with col1:
                        # éš¶å±åº¦æ’å
                        top10 = sorted(res["membership"].items(), key=lambda x: x[1], reverse=True)[:10]
                        st.table(pd.DataFrame(top10, columns=["è¯ç±»", "éš¶å±åº¦"]).round(4))
                    with col2:
                        # æ€»åˆ†æ¦‚è§ˆ
                        total_scores = {pos: sum(res["scores_all"][pos].values()) for pos in RULE_SETS.keys()}
                        st.write("### å„è¯ç±»æ€»åˆ†")
                        st.bar_chart(total_scores)

                    # è¯¦ç»†å¾—åˆ†
                    st.write("### è¯¦ç»†è§„åˆ™å¾—åˆ†")
                    all_scores = []
                    for pos, rules in RULE_SETS.items():
                        for r in rules:
                            all_scores.append({
                                "è¯ç±»": pos,
                                "è§„åˆ™": r["name"],
                                "æè¿°": r["desc"],
                                "å¾—åˆ†": res["scores_all"][pos][r["name"]]
                            })
                    df = pd.DataFrame(all_scores)
                    df_styled = df.style.applymap(lambda x: "color: red; font-weight: bold" if isinstance(x, int) and x < 0 else "", subset=["å¾—åˆ†"])
                    st.dataframe(df_styled, use_container_width=True)

if __name__ == "__main__":
    main()

# é¡µé¢åº•éƒ¨
st.markdown("---")
st.markdown("<div style='text-align:center; color:#666;'>Â© 2025 æ±‰è¯­è¯ç±»æ£€æµ‹ï¼ˆå¹¶å‘æé€Ÿç‰ˆï¼‰</div>", unsafe_allow_html=True)
