import streamlit as st
import requests
import json
import re
import os
import pandas as pd
import plotly.graph_objects as go
import io
import time
from typing import Tuple, Dict, Any, List
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ===============================
# é¡µé¢é…ç½®
# ===============================
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items=None
)

# è‡ªå®šä¹‰CSSæ ·å¼
hide_streamlit_style = """
<style>
header {visibility: hidden;}
footer {visibility: hidden;}
.dataframe {font-size: 12px;}
[data-testid="stSidebar"] {display: none !important;}
.stApp > div:first-child {padding-top: 2rem;}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# ===============================
# è¯ç±»è§„åˆ™å®šä¹‰ï¼ˆå…¨å±€ï¼Œä¿®å¤æ ¸å¿ƒï¼šæå–åˆ°å…¨å±€é¿å…å¤æ‚è¯»å–ï¼‰
# ===============================
RULE_SETS = {
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V, Väº†V, Vä¸V, Väº†æ²¡æœ‰'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®æˆ–è·Ÿåœ¨'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®ï¼Œä¸èƒ½è·Ÿåœ¨'å¤šä¹ˆ'ä¹‹åè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
    ],
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®š", "match_score": 10, "mismatch_score": -10},
        {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰\"VVã€Vä¸€Vã€Väº†Vã€Vä¸V\"ç­‰é‡å å’Œæ­£åé‡å å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°ï¼Œæˆ–è€…å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åæé—®", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š\"ä¹‹åå¯¹æ€§è´¨çš„ç¨‹åº¦è¿›è¡Œæé—®", "match_score": 10, "mismatch_score": -10},
        {"name": "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
    ]
}

# ===============================
# æ¨¡å‹é…ç½® (å¯ç”¨æµå¼ Stream)
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True, 
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        "headers": lambda key: {
            "Authorization": f"Bearer {key}", 
            "Content-Type": "application/json",
            "X-DashScope-SSE": "enable",
            "Accept": "text/event-stream"
        },
        "payload": lambda model, messages, **kw: {
            "model": model, 
            "input": {"messages": messages}, 
            "parameters": {
                "max_tokens": kw.get("max_tokens", 4096), 
                "temperature": kw.get("temperature", 0.0),
                "result_format": "message",
                "incremental_output": True 
            },
        },
    },
}

# æ¨¡å‹é€‰é¡¹ï¼ˆä»…ä»ç¯å¢ƒå˜é‡è·å–API Keyï¼‰
MODEL_OPTIONS = {
    "DeepSeek Chat": {
        "provider": "deepseek", 
        "model": "deepseek-chat", 
        "api_key": os.getenv("DEEPSEEK_API_KEY"),
        "env_var": "DEEPSEEK_API_KEY"
    },
    "OpenAI GPT-4oï¼ˆæ¨èï¼‰": {
        "provider": "openai", 
        "model": "gpt-4o-mini", 
        "api_key": os.getenv("OPENAI_API_KEY"),
        "env_var": "OPENAI_API_KEY"
    },
    "Moonshotï¼ˆKimiï¼‰": {
        "provider": "moonshot", 
        "model": "moonshot-v1-32k", 
        "api_key": os.getenv("MOONSHOT_API_KEY"),
        "env_var": "MOONSHOT_API_KEY"
    },
    "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰": {
        "provider": "qwen", 
        "model": "qwen-max", 
        "api_key": os.getenv("QWEN_API_KEY"),
        "env_var": "QWEN_API_KEY"
    },
}

# è¿‡æ»¤æ‰æ²¡æœ‰é…ç½® API Key çš„æ¨¡å‹
AVAILABLE_MODEL_OPTIONS = {
    name: info for name, info in MODEL_OPTIONS.items() if info["api_key"]
}

if not AVAILABLE_MODEL_OPTIONS:
    AVAILABLE_MODEL_OPTIONS = MODEL_OPTIONS

# ===============================
# å·¥å…·å‡½æ•°
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    """ä»ä¸åŒæ ¼å¼çš„LLMå“åº”ä¸­å®‰å…¨æå–æ–‡æœ¬å†…å®¹ã€‚"""
    if not isinstance(resp_json, dict):
        return ""
    try:
        # Qwen æ ¼å¼
        if "output" in resp_json and "text" in resp_json["output"]:
            return resp_json["output"]["text"]
        
        # OpenAI/DeepSeek/Moonshot æ ¼å¼
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
            
        return json.dumps(resp_json, ensure_ascii=False)
    except Exception as e:
        return json.dumps(resp_json, ensure_ascii=False)

def extract_json_from_text(text: str) -> Tuple[Dict[str, Any], str]:
    """ä»æ··åˆæ–‡æœ¬ä¸­æå–å¹¶è§£æJSONå¯¹è±¡ã€‚"""
    match = re.search(r"(\{.*\})", text.strip(), re.DOTALL)
    if not match:
        return None, text

    json_text = match.group(1).strip()
    try:
        parsed_json = json.loads(json_text)
        return parsed_json, json_text
    except json.JSONDecodeError:
        return None, json_text

def normalize_key(k: str, pos_rules: list) -> str:
    """æ ‡å‡†åŒ–æ¨¡å‹è¿”å›çš„è§„åˆ™åç§°"""
    if not isinstance(k, str): return None
    k_norm = re.sub(r'[\s_]+', '', k).upper()
    for r in pos_rules:
        r_norm = re.sub(r'[\s_]+', '', r["name"]).upper()
        if r_norm == k_norm:
            return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    """å°†æ¨¡å‹è¿”å›å€¼æ˜ å°„ä¸ºè§„åˆ™å¾—åˆ†"""
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    if isinstance(raw_val, bool):
        return match_score if raw_val else mismatch_score
    if isinstance(raw_val, str):
        s = raw_val.strip().lower()
        if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"):
            return match_score
        if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"):
            return mismatch_score
    if isinstance(raw_val, (int, float)):
        raw_val_int = int(raw_val)
        if raw_val_int == match_score: return match_score
        if raw_val_int == mismatch_score: return mismatch_score
    return mismatch_score

def calculate_membership(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    """è®¡ç®—éš¶å±åº¦"""
    membership = {}
    for pos, scores in scores_all.items():
        total_score = sum(scores.values())
        normalized = total_score / 100
        membership[pos] = max(-1.0, min(1.0, normalized))
    return membership

def get_top_10_positions(membership: Dict[str, float]) -> List[Tuple[str, float]]:
    """è·å–éš¶å±åº¦æœ€é«˜çš„å‰ 10 ä¸ªè¯ç±»"""
    return sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]

def get_history_count(backup_file):
    """è·å–æœ€æ–°çš„å†å²è®°å½•æ•°é‡ï¼ˆå®æ—¶æ›´æ–°ç”¨ï¼‰"""
    if not os.path.exists(backup_file):
        return 0
    try:
        temp_history = pd.read_csv(backup_file, encoding='utf-8-sig')
        return len(temp_history)
    except Exception as e:
        st.warning(f"è¯»å–å†å²è®°å½•æ•°é‡å¤±è´¥: {e}")
        return 0

# ===============================
# å®‰å…¨çš„ LLM è°ƒç”¨å‡½æ•° (æµå¼ç‰ˆ)
# ===============================
def call_llm_api_cached(_provider, _model, _api_key, messages, max_tokens=4096, temperature=0.0):
    """å°è£…LLMè°ƒç”¨é€»è¾‘"""
    if not _api_key: return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"
    if _provider not in MODEL_CONFIGS: return False, {"error": f"æœªçŸ¥æä¾›å•† {_provider}"}, f"æœªçŸ¥æä¾›å•† {_provider}"

    cfg = MODEL_CONFIGS[_provider]
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](_api_key)
    payload = cfg["payload"](_model, messages, max_tokens=max_tokens, temperature=temperature)

    streaming_placeholder = st.empty()
    full_content = ""

    try:
        with requests.post(url, headers=headers, json=payload, stream=True, timeout=60) as response:
            response.raise_for_status()
            for line in response.iter_lines():
                if not line: continue
                line_text = line.decode('utf-8').strip()
                json_str = line_text[5:].strip() if line_text.startswith("data:") else line_text
                if json_str == "[DONE]": break
                try:
                    chunk = json.loads(json_str)
                    delta_text = ""
                    if "choices" in chunk and len(chunk["choices"]) > 0:
                        delta = chunk["choices"][0].get("delta", {})
                        delta_text = delta.get("content", "")
                    elif "output" in chunk:
                        output = chunk["output"]
                        if "choices" in output and len(output["choices"]) > 0:
                            msg = output["choices"][0].get("message", {})
                            delta_text = msg.get("content", "")
                        elif "text" in output:
                            delta_text = output["text"]
                    if delta_text:
                        full_content += delta_text
                except json.JSONDecodeError:
                    continue
        
        streaming_placeholder.empty()
        mock_response = {
            "choices": [{"message": {"content": full_content}}],
            "output": {"text": full_content}
        }
        
        if not full_content:
             return False, {"error": "æœªæ¥æ”¶åˆ°æœ‰æ•ˆå†…å®¹"}, "æ¨¡å‹æœªè¿”å›å†…å®¹"

        return True, mock_response, ""

    except requests.exceptions.RequestException as e:
        error_msg = f"ç½‘ç»œè¯·æ±‚å¼‚å¸¸: {str(e)}"
        return False, {"error": error_msg}, error_msg
    except Exception as e:
        error_msg = f"æµå¼å¤„ç†æœªçŸ¥é”™è¯¯: {str(e)}\nå·²æ¥æ”¶å†…å®¹: {full_content[:100]}..."
        return False, {"error": error_msg}, error_msg

# ===============================
# è¯ç±»åˆ¤å®šä¸»å‡½æ•°
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str, str]:
    """è¯ç±»åˆ¤å®šæ ¸å¿ƒå‡½æ•°"""
    if not word:
        return {}, "", "æœªçŸ¥", ""

    # æ„å»ºè§„åˆ™è¯´æ˜æ–‡æœ¬ï¼ˆä½¿ç”¨å…¨å±€RULE_SETSï¼‰
    full_rules_by_pos = {
        pos: "\n".join([f"- {r['name']}: {r['desc']}ï¼ˆç¬¦åˆ: {r['match_score']} åˆ†ï¼Œä¸ç¬¦åˆ: {r['mismatch_score']} åˆ†ï¼‰" for r in rules])
        for pos, rules in RULE_SETS.items()
    }

    # ç³»ç»Ÿæç¤ºè¯
    system_msg = f"""ä½ æ˜¯ä¸€åä¸­æ–‡è¯æ³•ä¸è¯­æ³•æ–¹é¢çš„ä¸“å®¶ã€‚ç°åœ¨è¦åˆ†æè¯è¯­ã€Œ{word}ã€åœ¨ä¸‹åˆ—è¯ç±»ä¸­çš„è¡¨ç°ï¼š
- éœ€è¦åˆ¤æ–­çš„è¯ç±»ï¼šåè¯ã€åŠ¨è¯ã€ååŠ¨è¯
- è¯„åˆ†è§„åˆ™å·²ç»ç”±ç³»ç»Ÿå®šä¹‰ï¼Œä½ **ä¸è¦**è‡ªå·±è®¾è®¡åˆ†å€¼ï¼Œä¹Ÿ**ä¸è¦**åœ¨ JSON ä¸­ç»™å‡ºå…·ä½“æ•°å­—åˆ†æ•°ã€‚ç¨‹åºå°†æ ¹æ®ä½ çš„åˆ¤æ–­ï¼ˆtrue/falseï¼‰è‡ªåŠ¨èµ‹å€¼ã€‚
- ä½ åªéœ€è¦åˆ¤æ–­æ¯ä¸€æ¡è§„åˆ™æ˜¯â€œç¬¦åˆâ€è¿˜æ˜¯â€œä¸ç¬¦åˆâ€ã€‚

ã€å„è¯ç±»çš„è§„åˆ™è¯´æ˜ï¼ˆä»…ä¾›ä½ åˆ¤æ–­ä½¿ç”¨ï¼‰ã€‘
ã€åè¯ã€‘
{full_rules_by_pos["åè¯"]}

ã€åŠ¨è¯ã€‘
{full_rules_by_pos["åŠ¨è¯"]}

ã€ååŠ¨è¯ã€‘
{full_rules_by_pos["ååŠ¨è¯"]}

ã€è¾“å‡ºè¦æ±‚ã€‘
1. åœ¨ explanation å­—æ®µä¸­ï¼Œå¿…é¡»**é€æ¡è§„åˆ™**è¯´æ˜åˆ¤æ–­ä¾æ®ï¼Œå¹¶ä¸¾ä¾‹ï¼ˆå¯ä»¥è‡ªå·±é€ å¥ï¼‰ï¼š
   - æ ¼å¼ç¤ºä¾‹ï¼š
     - ã€Œåè¯-N1_å¯å—æ•°é‡è¯ä¿®é¥°ï¼šç¬¦åˆã€‚ç†ç”±ï¼šâ€¦â€¦ã€‚ä¾‹å¥ï¼šâ€¦â€¦ã€‚ã€
     - ã€ŒåŠ¨è¯-V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼šä¸ç¬¦åˆã€‚ç†ç”±ï¼šâ€¦â€¦ã€‚ä¾‹å¥ï¼šâ€¦â€¦ã€‚ã€
   - explanation é‡Œè¦è¦†ç›– **ä¸‰ä¸ªè¯ç±»çš„æ‰€æœ‰è§„åˆ™**ï¼Œä¸èƒ½åªå†™å‡ æ¡ã€‚

2. åœ¨ JSON ä¸­çš„ scores å­—æ®µé‡Œï¼š
   - æ¯ä¸€ç±»ä¸‹çš„æ¯ä¸€æ¡è§„åˆ™ï¼Œåªèƒ½ç»™å‡º **å¸ƒå°”å€¼ true / false**ï¼Œè¡¨ç¤ºæ˜¯å¦ç¬¦åˆè¯¥è§„åˆ™
   - ä¸¥ç¦åœ¨ scores é‡Œä½¿ç”¨æ•°å€¼åˆ†æ•°ï¼ˆä¾‹å¦‚ 0, 5, 10 ç­‰ï¼‰
   - å¦‚æœä½ ä¸ç¡®å®šï¼Œä¹Ÿå¿…é¡»åšå‡ºåˆ¤æ–­ï¼ˆtrue æˆ– falseï¼‰ï¼Œä¸è¦ç”¨ nullã€0 æˆ–å…¶å®ƒå€¼
   - JSON ç»“æ„å¿…é¡»æ˜¯ï¼š{{"explanation": "...", "predicted_pos": "...", "scores": {{"åè¯": {{...}}, "åŠ¨è¯": {{...}}, "ååŠ¨è¯": {{...}}}}}}

3. predicted_posï¼š
   - è¯·é€‰æ‹©ã€Œåè¯ã€ã€ŒåŠ¨è¯ã€ã€ŒååŠ¨è¯ã€ä¹‹ä¸€ï¼Œä½œä¸ºè¯¥è¯è¯­æœ€å…¸å‹çš„è¯ç±»ã€‚

4. **æœ€åè¾“å‡ºæ—¶ï¼Œå…ˆå†™è¯¦ç»†çš„æ–‡å­—æ¨ç†ï¼Œæœ€åå•ç‹¬ä¸”å®Œæ•´åœ°ç»™å‡ºä¸€æ®µåˆæ³•çš„ JSONï¼ˆä¸è¦å†åŠ æ³¨é‡Šï¼‰ã€‚**
"""

    user_prompt = f"""
è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚åˆ†æè¯è¯­ã€Œ{word}ã€ã€‚
ç‰¹åˆ«æ³¨æ„ï¼š
- åœ¨ JSON çš„ scores éƒ¨åˆ†ï¼Œåªèƒ½ç”¨ true/false è¡¨ç¤ºâ€œæ˜¯å¦ç¬¦åˆè§„åˆ™â€ï¼Œä¸èƒ½ä½¿ç”¨ä»»ä½•æ•°å­—ã€‚
- explanation ä¸­å¿…é¡»å¯¹æ¯ä¸€æ¡è§„åˆ™å†™æ˜â€œç¬¦åˆ/ä¸ç¬¦åˆ + ç†ç”± + ä¾‹å¥â€ã€‚

è¯·å…ˆç»™å‡ºè¯¦ç»†æ¨ç†è¿‡ç¨‹ï¼Œç„¶ååœ¨æœ€åå•ç‹¬è¾“å‡ºä¸€ä¸ª JSON å¯¹è±¡ã€‚
"""

    with st.spinner(f"æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹ ({model}) è¿›è¡Œåˆ†æï¼Œè¯·ç¨å€™..."):
        ok, resp_json, err_msg = call_llm_api_cached(
            _provider=provider,
            _model=model,
            _api_key=api_key,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt}
            ]
        )

    if not ok:
        st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {err_msg}")
        return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {err_msg}"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, cleaned_json_text = extract_json_from_text(raw_text)

    if parsed_json and isinstance(parsed_json, dict):
        explanation = parsed_json.get("explanation", "æ¨¡å‹æœªæä¾›è¯¦ç»†æ¨ç†è¿‡ç¨‹ã€‚")
        predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
        raw_scores = parsed_json.get("scores", {})
        if predicted_pos not in RULE_SETS:
             st.warning(f"æ¨¡å‹é¢„æµ‹çš„è¯ç±» '{predicted_pos}' ä¸åœ¨åˆ†æèŒƒå›´å†… ('åè¯', 'åŠ¨è¯', 'ååŠ¨è¯')ã€‚")
    else:
        st.error("âŒ æœªèƒ½ä»æ¨¡å‹å“åº”ä¸­è§£æå‡ºæœ‰æ•ˆçš„JSONã€‚è¯·æ£€æŸ¥æ¨¡å‹è¾“å‡ºæ˜¯å¦ç¬¦åˆè¦æ±‚ã€‚")
        explanation = "æ— æ³•è§£ææ¨¡å‹è¾“å‡ºã€‚åŸå§‹å“åº”ï¼š\n" + raw_text
        predicted_pos = "æœªçŸ¥"
        raw_scores = {}
        cleaned_json_text = raw_text

    # åˆå§‹åŒ–å¾—åˆ†å­—å…¸
    scores_out = {pos: {} for pos in RULE_SETS.keys()}
    for pos, rules in RULE_SETS.items():
        raw_pos_scores = raw_scores.get(pos, {})
        if isinstance(raw_pos_scores, dict):
            for k, v in raw_pos_scores.items():
                normalized_key = normalize_key(k, rules)
                if normalized_key:
                    rule_def = next(r for r in rules if r["name"] == normalized_key)
                    scores_out[pos][normalized_key] = map_to_allowed_score(rule_def, v)

    # è¡¥å…¨ç¼ºå¤±çš„è§„åˆ™å¾—åˆ†ï¼ˆé»˜è®¤0åˆ†ï¼‰
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            rule_name = rule["name"]
            if rule_name not in scores_out[pos]:
                scores_out[pos][rule_name] = 0

    return scores_out, raw_text, predicted_pos, explanation

# ===============================
# é›·è¾¾å›¾ç»˜åˆ¶å‡½æ•°
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    """ç»˜åˆ¶è¯ç±»éš¶å±åº¦é›·è¾¾å›¾"""
    if not scores_norm:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return
    
    categories = list(scores_norm.keys())
    if not categories:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆè¯ç±»ã€‚")
        return
        
    values = list(scores_norm.values())
    categories += [categories[0]]
    values += [values[0]]
    
    min_val = min(values)
    max_val = max(values)
    axis_min = min(min_val, -0.1) 
    axis_max = max(max_val, 1.0)
    
    fig = go.Figure(data=[
        go.Scatterpolar(
            r=values, 
            theta=categories, 
            fill="toself", 
            name="éš¶å±åº¦",
            hovertemplate = '<b>%{theta}</b><br>éš¶å±åº¦: %{r:.4f}<extra></extra>'
        )
    ])
    fig.update_layout(
        polar=dict(
            radialaxis=dict(
                visible=True, 
                range=[axis_min, axis_max],
                tickvals=[0, 0.25, 0.5, 0.75, 1.0] if axis_min >= 0 else [-1.0, -0.5, 0, 0.5, 1.0]
            )
        ),
        showlegend=False,
        title=dict(text=title, x=0.5, font=dict(size=16))
    )
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# æ‰¹é‡å¤„ç†å‡½æ•°
# ===============================
def process_and_style_excel(df, selected_model_info, target_col_name, metric_placeholder, BACKUP_FILE):
    """æ‰¹é‡å¤„ç†Excelå¹¶å®æ—¶æ›´æ–°æ•°æ®é‡"""
    output = io.BytesIO()
    if 'processed_history' not in st.session_state:
        st.session_state.processed_history = []
    
    progress_bar = st.progress(0)
    status_text = st.empty()
    backup_info_placeholder = st.container()
    total = len(df)
    backup_file = BACKUP_FILE

    try:
        for index, row in df.iterrows():
            word = str(row[target_col_name]).strip()
            max_retries = 3
            success = False
            scores_all, raw_text, predicted_pos, explanation = {}, "", "è¯·æ±‚å¤±è´¥", ""
            
            for attempt in range(max_retries):
                try:
                    status_text.text(f"æ­£åœ¨å¤„ç† ({index + 1}/{total}): {word} ... (å°è¯• {attempt + 1})")
                    scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
                        word=word,
                        provider=selected_model_info["provider"],
                        model=selected_model_info["model"],
                        api_key=selected_model_info["api_key"]
                    )
                    if scores_all:
                        success = True
                        break
                    time.sleep(2)
                except Exception:
                    time.sleep(2)
            
            # æ„é€ æ•°æ®è¡Œ
            membership = calculate_membership(scores_all) if success else {}
            new_row = {
                "åºæ•°": index + 1,
                "è¯è¯­": word,
                "åŠ¨è¯": membership.get("åŠ¨è¯", 0.0),
                "åè¯": membership.get("åè¯", 0.0),
                "ååŠ¨è¯": membership.get("ååŠ¨è¯", 0.0),
                "å·®å€¼/è·ç¦»": round(abs(membership.get("åŠ¨è¯", 0.0) - membership.get("åè¯", 0.0)), 4),
                "é¢„æµ‹è¯ç±»": predicted_pos,
                "åŸå§‹å“åº”": raw_text if success else f"é”™è¯¯: {explanation}",
                "æ—¶é—´æˆ³": time.strftime("%Y-%m-%d %H:%M:%S")
            }
            
            # ä¿å­˜åˆ°SessionState
            st.session_state.processed_history.append(new_row)
            
            # å†™å…¥CSVå¹¶å®æ—¶æ›´æ–°æ•°æ®é‡
            try:
                temp_df = pd.DataFrame([new_row])
                header_needed = not os.path.exists(backup_file)
                temp_df.to_csv(backup_file, mode='a', header=header_needed, index=False, encoding='utf-8-sig')
                # æ ¸å¿ƒï¼šæ›´æ–°å·²å­˜æ•°æ®é‡æŒ‡æ ‡
                latest_count = get_history_count(backup_file)
                metric_placeholder.metric("å·²å­˜æ•°æ®é‡", f"{latest_count} æ¡")
            except Exception as csv_err:
                st.error(f"ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•å¤±è´¥: {csv_err}")

            with backup_info_placeholder:
                st.info(f"ğŸ’¾ å·²è‡ªåŠ¨ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•ã€‚å¦‚é‡ä¸­æ–­ï¼Œè¯·æ£€æŸ¥ç›®å½•ä¸‹ `{backup_file}`")

            progress_bar.progress((index + 1) / total)
            time.sleep(0.5)

    except Exception as e:
        st.error(f"âš ï¸ æ‰¹é‡å¤„ç†æ„å¤–ä¸­æ–­: {e}")
    
    # å¯¼å‡ºExcel
    final_data = st.session_state.processed_history
    if not final_data:
        return None

    result_df = pd.DataFrame(final_data)
    try:
        with pd.ExcelWriter(output, engine='openpyxl') as writer:
            cols = ["è¯è¯­", "åŠ¨è¯", "åè¯", "ååŠ¨è¯", "å·®å€¼/è·ç¦»", "é¢„æµ‹è¯ç±»", "åŸå§‹å“åº”"]
            result_df[cols].to_excel(writer, index=False, sheet_name='åˆ†æç»“æœ')
            
            workbook = writer.book
            worksheet = writer.sheets['åˆ†æç»“æœ']
            yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
            
            for i, data_row in enumerate(final_data):
                row_num = i + 2
                pred = data_row["é¢„æµ‹è¯ç±»"]
                target_idx = {"åŠ¨è¯": 2, "åè¯": 3, "ååŠ¨è¯": 4}.get(pred)
                if target_idx:
                    worksheet.cell(row=row_num, column=target_idx).fill = yellow_fill
                    
        return output.getvalue()
    except Exception as e:
        st.error(f"Excel ç”Ÿæˆå¤±è´¥: {e}")
        return None

# ===============================
# ä¸»é¡µé¢é€»è¾‘
# ===============================
def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»")
    
    # é¡¶éƒ¨æ§åˆ¶åŒº
    control_container = st.container()
    with control_container:
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.subheader("âš™ï¸ æ¨¡å‹è®¾ç½®")
            if not AVAILABLE_MODEL_OPTIONS:
                st.error("âŒ æ‰¾ä¸åˆ°å¯ç”¨çš„ API Keyï¼è¯·è®¾ç½®ä»¥ä¸‹ä»»æ„ä¸€ä¸ªç¯å¢ƒå˜é‡æ¥å¯ç”¨æ¨¡å‹:")
                for name, info in MODEL_OPTIONS.items():
                      st.code(f"export {info['env_var']}='ä½ çš„API Key'", language="bash")
                selected_model_display_name = list(MODEL_OPTIONS.keys())[0]
                selected_model_info = MODEL_OPTIONS[selected_model_display_name]
                st.selectbox("é€‰æ‹©å¤§æ¨¡å‹ (ä¸å¯ç”¨)", list(MODEL_OPTIONS.keys()), disabled=True)
            else:
                selected_model_display_name = st.selectbox(
                    "é€‰æ‹©å¤§æ¨¡å‹", 
                    list(AVAILABLE_MODEL_OPTIONS.keys()), 
                    key="model_select"
                )
                selected_model_info = AVAILABLE_MODEL_OPTIONS[selected_model_display_name]
                
        with col2:
            st.subheader("ğŸ”— è¿æ¥æµ‹è¯•")
            st.write("")
            if not selected_model_info["api_key"]:
                st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥ (ä¸å¯ç”¨)", type="secondary", disabled=True)
            else:
                if st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary"):
                    with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                        ok, _, err_msg = call_llm_api_cached(
                            _provider=selected_model_info["provider"],
                            _model=selected_model_info["model"],
                            _api_key=selected_model_info["api_key"],
                            messages=[{"role": "user", "content": "è¯·å›å¤'pong'"}],
                            max_tokens=10
                        )
                    if ok:
                        st.success("âœ… æˆåŠŸï¼")
                    else:
                        st.error(f"âŒ å¤±è´¥: {err_msg}")

    st.markdown("---")

    # åˆ†é¡µ
    tab1, tab2 = st.tabs(["ğŸ” å•ä¸ªè¯è¯­è¯¦ç»†åˆ†æ", "ğŸ“‚ Excel æ‰¹é‡å¤„ç†"])

    # å•ä¸ªè¯è¯­åˆ†æ
    with tab1:
        st.subheader("ğŸ”¤ è¯è¯­è¾“å…¥")
        word = st.text_input("è¯·è¾“å…¥è¦åˆ†æçš„æ±‰è¯­è¯è¯­", placeholder="ä¾‹å¦‚ï¼šè‹¹æœã€è·‘ã€ç¾ä¸½...", key="word_input")
        analyze_button = st.button(
            "ğŸš€ å¼€å§‹åˆ†æ", 
            type="primary",
            disabled=not (selected_model_info["api_key"] and word)
        )

        with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜", expanded=False):
            st.info("""
            1. **é…ç½® API Key**: è¯·åœ¨è¿è¡Œç¨‹åºå‰è®¾ç½®å¿…è¦çš„ç¯å¢ƒå˜é‡ã€‚
            2. **è¯è¯­è¾“å…¥**ï¼šåœ¨ä¸Šæ–¹çš„â€œè¯è¯­è¾“å…¥â€æ¡†ä¸­è¾“å…¥ä¸€ä¸ªæ±‰è¯­è¯ã€‚
            3. **å¼€å§‹åˆ†æ**ï¼šç‚¹å‡»â€œå¼€å§‹åˆ†æâ€æŒ‰é’®ã€‚
            4. **ç»“æœè§£æ**ï¼šç³»ç»Ÿå°†æ˜¾ç¤ºéš¶å±åº¦ã€é›·è¾¾å›¾å’Œè¯¦ç»†è§„åˆ™å¾—åˆ†ã€‚
            """)

        if analyze_button and word and selected_model_info["api_key"]:
            status_placeholder = st.empty()
            status_placeholder.info(f"æ­£åœ¨ä¸ºè¯è¯­ã€Œ{word}ã€å¯åŠ¨åˆ†æï¼Œä½¿ç”¨æ¨¡å‹ï¼š{selected_model_display_name}...")

            scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
                word=word,
                provider=selected_model_info["provider"],
                model=selected_model_info["model"],
                api_key=selected_model_info["api_key"]
            )
            
            status_placeholder.empty()
            
            if scores_all:
                membership = calculate_membership(scores_all)
                final_membership = membership.get(predicted_pos, 0)
                st.success(f'**åˆ†æå®Œæˆ**ï¼šè¯è¯­ã€Œ{word}ã€æœ€å¯èƒ½çš„è¯ç±»æ˜¯ **ã€{predicted_pos}ã€‘**ï¼Œéš¶å±åº¦ä¸º **{final_membership:.4f}**')
                
                col_results_1, col_results_2 = st.columns(2)
                
                with col_results_1:
                    st.subheader("ğŸ† è¯ç±»éš¶å±åº¦æ’å")
                    top10 = get_top_10_positions(membership)
                    top10_df = pd.DataFrame(top10, columns=["è¯ç±»", "éš¶å±åº¦"])
                    top10_df["éš¶å±åº¦"] = top10_df["éš¶å±åº¦"].apply(lambda x: f"{x:.4f}")
                    st.table(top10_df)
                    
                    st.subheader("ğŸ“Š è¯ç±»éš¶å±åº¦é›·è¾¾å›¾")
                    plot_radar_chart_streamlit(dict(top10), f"ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦åˆ†å¸ƒ")

                with col_results_2:
                    st.subheader("ğŸ“‹ å„è¯ç±»è¯¦ç»†å¾—åˆ†")
                    pos_total_scores = {pos: sum(scores_all[pos].values()) for pos in scores_all.keys()}
                    sorted_pos_names = sorted(pos_total_scores.keys(), key=lambda pos: pos_total_scores[pos], reverse=True)
                    
                    for pos in sorted_pos_names:
                        total_score = pos_total_scores[pos]
                        max_rule = max(scores_all[pos].items(), key=lambda x: x[1], default=("æ— ", 0))
                        with st.expander(f"**{pos}** (æ€»åˆ†: {total_score}, æœ€é«˜åˆ†è§„åˆ™: {max_rule[0]} - {max_rule[1]}åˆ†)"):
                            rule_data = []
                            for rule_name, rule_score in scores_all[pos].items():
                                # ä¿®å¤æ ¸å¿ƒï¼šç®€åŒ–è§„åˆ™æè¿°æŸ¥æ‰¾ï¼ˆç›´æ¥ç”¨å…¨å±€RULE_SETSï¼‰
                                rule_desc = ""
                                if pos in RULE_SETS:
                                    for rule in RULE_SETS[pos]:
                                        if rule["name"] == rule_name:
                                            rule_desc = rule["desc"]
                                            break
                                rule_data.append({
                                    "è§„åˆ™ä»£ç ": rule_name,
                                    "è§„åˆ™æè¿°": rule_desc,
                                    "å¾—åˆ†": rule_score
                                })
                            rule_data_sorted = sorted(rule_data, key=lambda x: x["å¾—åˆ†"], reverse=True)
                            rule_df = pd.DataFrame(rule_data_sorted)
                            styled_df = rule_df.style.applymap(
                                lambda x: "color: #ff4b4b; font-weight: bold" if isinstance(x, int) and x < 0 else "",
                                subset=["å¾—åˆ†"]
                            )
                            st.dataframe(
                                styled_df,
                                use_container_width=True,
                                height=min(len(rule_df) * 30 + 50, 400)
                            )
                    
                    st.subheader("ğŸ“¥ æ¨¡å‹åŸå§‹å“åº”")
                    with st.expander("ç‚¹å‡»å±•å¼€æŸ¥çœ‹åŸå§‹å“åº”", expanded=False):
                        st.code(raw_text, language="text")

    # æ‰¹é‡å¤„ç†
    with tab2:
        st.header("ğŸ“‚ æ‰¹é‡ä»»åŠ¡å®æ—¶ç›‘æ§")
        BACKUP_FILE = "batch_history_log.csv"

        # æ§åˆ¶é¢æ¿
        st.subheader("ğŸ› ï¸ æ§åˆ¶é¢æ¿")
        ctrl_col1, ctrl_col2, ctrl_col3 = st.columns([2, 1, 1])
        
        with ctrl_col1:
            # å¯å®æ—¶æ›´æ–°çš„metricå ä½ç¬¦
            metric_placeholder = st.empty()
            # åˆå§‹åŒ–æ˜¾ç¤ºæœ€æ–°æ•°é‡
            history_count = get_history_count(BACKUP_FILE)
            metric_placeholder.metric("å·²å­˜æ•°æ®é‡", f"{history_count} æ¡")
            
            has_history = os.path.exists(BACKUP_FILE)
            if has_history:
                st.caption(f"å­˜å‚¨ä½ç½®: `{BACKUP_FILE}`")
        
        with ctrl_col2:
            if os.path.exists(BACKUP_FILE):
                with open(BACKUP_FILE, "rb") as f:
                    st.download_button(
                        label="ğŸ“¥ ä¸‹è½½å†å²æ–‡ä»¶(CSV)",
                        data=f,
                        file_name=f"batch_results_{time.strftime('%Y%m%d_%H%M%S')}.csv",
                        mime="text/csv",
                        use_container_width=True
                    )
            else:
                st.button("ğŸ“¥ ä¸‹è½½å†å²æ–‡ä»¶", disabled=True, use_container_width=True)

        with ctrl_col3:
            if st.button("ğŸ—‘ï¸ æ¸…ç©ºæœ¬åœ°è®°å½•", use_container_width=True, type="secondary"):
                if os.path.exists(BACKUP_FILE):
                    try:
                        os.remove(BACKUP_FILE)
                        st.success("âœ… å·²æ¸…ç©ºæœ¬åœ°è®°å½•")
                        # æ¸…ç©ºåæ›´æ–°æ•°æ®é‡æ˜¾ç¤º
                        metric_placeholder.metric("å·²å­˜æ•°æ®é‡", "0 æ¡")
                        st.rerun()
                    except Exception as e:
                        st.error(f"æ¸…ç©ºè®°å½•å¤±è´¥: {e}")
                else:
                    st.info("ğŸ“„ æš‚æ— æœ¬åœ°è®°å½•å¯æ¸…ç©º")

        st.divider()

        # è¿è¡ŒçŠ¶æ€
        st.subheader("ğŸ“ˆ è¿è¡ŒçŠ¶æ€")
        progress_bar = st.progress(0)
        status_info = st.empty()
        
        # å®æ—¶ç»“æœé¢„è§ˆ
        st.subheader("ğŸ“‹ å®æ—¶ç»“æœé¢„è§ˆ")
        table_placeholder = st.empty()
        if os.path.exists(BACKUP_FILE):
            try:
                table_placeholder.dataframe(
                    pd.read_csv(BACKUP_FILE, encoding='utf-8-sig'), 
                    use_container_width=True, 
                    height=300
                )
            except Exception as e:
                table_placeholder.error(f"æ˜¾ç¤ºå†å²è®°å½•å¤±è´¥: {e}")
        else:
            table_placeholder.info("æš‚æ— æ•°æ®ã€‚ä¸Šä¼ æ–‡ä»¶å¹¶ç‚¹å‡»å¼€å§‹åï¼Œç»“æœå°†åœ¨æ­¤é€è¡Œå®æ—¶æ˜¾ç¤ºã€‚")

        st.divider()

        # ä¸Šä¼ ä»»åŠ¡
        st.subheader("ğŸ“¤ ä¸Šä¼ æ–°ä»»åŠ¡")
        uploaded_file = st.file_uploader("é€‰æ‹© Excel æ–‡ä»¶", type=["xlsx", "xls"])
        
        if uploaded_file:
            try:
                df_input = pd.read_excel(uploaded_file)
                target_col = next((col for col in df_input.columns if "è¯" in str(col) or "word" in str(col).lower()), None)
                
                if target_col:
                    st.write(f"âœ… è¯†åˆ«åˆ°ç›®æ ‡åˆ—: `{target_col}` | å¾…åˆ†ææ€»æ•°: {len(df_input)}")
                    
                    if st.button("ğŸš€ å¼€å§‹å¤„ç† (è‡ªåŠ¨ç»­ä¼ )", type="primary", use_container_width=True):
                        if not selected_model_info["api_key"]:
                            st.error("âŒ è¯·å…ˆåœ¨ä¸Šæ–¹é…ç½®æœ‰æ•ˆçš„ API Key")
                        else:
                            # è·å–å·²å¤„ç†çš„è¯è¯­
                            existing_words = set()
                            if os.path.exists(BACKUP_FILE):
                                try:
                                    existing_df = pd.read_csv(BACKUP_FILE, encoding='utf-8-sig')
                                    if "è¯è¯­" in existing_df.columns:
                                        existing_words = set(existing_df["è¯è¯­"].astype(str).tolist())
                                    st.info(f"â„¹ï¸ å·²è·³è¿‡ {len(existing_words)} æ¡å·²å¤„ç†è®°å½•")
                                except Exception as e:
                                    st.warning(f"è¯»å–å·²å¤„ç†è®°å½•å¤±è´¥ï¼Œå°†é‡æ–°å¤„ç†æ‰€æœ‰æ•°æ®: {e}")

                            total_rows = len(df_input)
                            
                            for index, row in df_input.iterrows():
                                word = str(row[target_col]).strip()
                                if not word:
                                    status_info.write(f"â© **è·³è¿‡ç©ºå€¼**: ç¬¬ {index+1}/{total_rows} è¡Œ")
                                    progress_bar.progress((index + 1) / total_rows)
                                    continue
                                
                                pct = int((index + 1) / total_rows * 100)
                                progress_bar.progress((index + 1) / total_rows)
                                
                                if word in existing_words:
                                    status_info.write(f"â© **è·³è¿‡å·²å¤„ç†**: {word} ({index+1}/{total_rows}) | è¿›åº¦: {pct}%")
                                    continue
                                
                                status_info.write(f"ğŸ” **æ­£åœ¨åˆ†æ**: `{word}` | è¿›åº¦: {index+1}/{total_rows} ({pct}%)")
                                
                                # è°ƒç”¨APIå¤„ç†
                                max_retries = 3
                                success = False
                                scores, raw_text, pred_pos, explanation = {}, "", "å¤„ç†å¤±è´¥", "æ— å“åº”"
                                for attempt in range(max_retries):
                                    try:
                                        scores, raw_text, pred_pos, explanation = ask_model_for_pos_and_scores(
                                            word=word,
                                            provider=selected_model_info["provider"],
                                            model=selected_model_info["model"],
                                            api_key=selected_model_info["api_key"]
                                        )
                                        success = bool(scores)
                                        if success:
                                            break
                                        time.sleep(2)
                                    except Exception as e:
                                        explanation = f"è°ƒç”¨å¼‚å¸¸: {str(e)}"
                                        time.sleep(2)
                                
                                # æ„é€ æ•°æ®è¡Œ
                                membership = calculate_membership(scores) if success else {}
                                new_row = {
                                    "åºæ•°": index + 1,
                                    "è¯è¯­": word,
                                    "åŠ¨è¯": membership.get("åŠ¨è¯", 0.0),
                                    "åè¯": membership.get("åè¯", 0.0),
                                    "ååŠ¨è¯": membership.get("ååŠ¨è¯", 0.0),
                                    "å·®å€¼/è·ç¦»": round(abs(membership.get("åŠ¨è¯", 0.0) - membership.get("åè¯", 0.0)), 4),
                                    "é¢„æµ‹è¯ç±»": pred_pos,
                                    "åŸå§‹å“åº”": raw_text if success else f"é”™è¯¯: {explanation}",
                                    "æ—¶é—´æˆ³": time.strftime("%Y-%m-%d %H:%M:%S")
                                }
                                
                                # ä¿å­˜æ•°æ®å¹¶å®æ—¶æ›´æ–°æ•°é‡
                                try:
                                    temp_df = pd.DataFrame([new_row])
                                    header_needed = not os.path.exists(BACKUP_FILE)
                                    temp_df.to_csv(
                                        BACKUP_FILE, 
                                        mode='a', 
                                        header=header_needed, 
                                        index=False, 
                                        encoding='utf-8-sig'
                                    )
                                    existing_words.add(word)
                                    # å®æ—¶æ›´æ–°å·²å­˜æ•°æ®é‡
                                    latest_count = get_history_count(BACKUP_FILE)
                                    metric_placeholder.metric("å·²å­˜æ•°æ®é‡", f"{latest_count} æ¡")
                                except Exception as csv_err:
                                    st.error(f"âš ï¸ ä¿å­˜ç¬¬ {index+1} æ¡è®°å½•å¤±è´¥: {csv_err}")
                                
                                # åˆ·æ–°è¡¨æ ¼
                                try:
                                    updated_df = pd.read_csv(BACKUP_FILE, encoding='utf-8-sig')
                                    table_placeholder.dataframe(updated_df, use_container_width=True, height=300)
                                except Exception as read_err:
                                    st.warning(f"åˆ·æ–°è¡¨æ ¼å¤±è´¥: {read_err}")
                                
                                time.sleep(0.1)
                            
                            progress_bar.progress(100)
                            status_info.success(f"ğŸ‰ æ‰¹é‡å¤„ç†å®Œæˆï¼æ€»å¤„ç†é‡: {total_rows} æ¡ï¼Œå·²ä¿å­˜åˆ° {BACKUP_FILE}")
                            st.rerun()
                else:
                    st.error("âŒ æœªè¯†åˆ«åˆ°åŒ…å«'è¯'æˆ–'word'çš„åˆ—ï¼Œè¯·æ£€æŸ¥Excelæ–‡ä»¶ç»“æ„")
            except Exception as e:
                st.error(f"è¯»å–Excelæ–‡ä»¶å¤±è´¥: {e}")

# ===============================
# è¿è¡Œä¸»å‡½æ•°
# ===============================
if __name__ == "__main__":
    main()

# ===============================
# é¡µé¢åº•éƒ¨è¯´æ˜
# ===============================
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:#666;'>"
    "Â© 2025 æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»  "
    "</div>",
    unsafe_allow_html=True
)
