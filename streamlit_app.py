
import streamlit as st
import requests
import json
import re
import os
import pandas as pd
import plotly.graph_objects as go
from typing import Tuple, Dict, Any, List

# ===============================
# é¡µé¢é…ç½®
# ===============================
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»",
    page_icon="ğŸ“°",
    layout="wide",  # ä½¿ç”¨å®½å¸ƒå±€
    initial_sidebar_state="collapsed",  # é»˜è®¤æŠ˜å ä¾§è¾¹æ 
    menu_items=None
)

# è‡ªå®šä¹‰CSSæ ·å¼
hide_streamlit_style = """
<style>
/* éšè—é¡¶éƒ¨èœå•æ å’Œé¡µè„š */
header {visibility: hidden;}
footer {visibility: hidden;}

/* è°ƒæ•´è¡¨æ ¼æ ·å¼ */
.dataframe {font-size: 12px;}

/* éšè—é»˜è®¤çš„ä¾§è¾¹æ  */
[data-testid="stSidebar"] {
    display: none !important;
}

/* ä¸ºé¡¶éƒ¨æ§åˆ¶åŒºæ·»åŠ è¾¹æ¡†å’ŒèƒŒæ™¯è‰²ï¼Œä½¿å…¶çœ‹èµ·æ¥åƒä¸€ä¸ªå›ºå®šçš„é¢æ¿ */
.stApp > div:first-child {
    padding-top: 2rem;
}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# ===============================
# æ¨¡å‹é…ç½® (ä»…ä»ç¯å¢ƒå˜é‡è·å–API Key)
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "input": {"messages": messages}, "parameters": {"max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0),},
        },
    },
}

# æ¨¡å‹é€‰é¡¹ï¼ˆä»…ä»ç¯å¢ƒå˜é‡è·å–API Keyï¼Œä¸æä¾›æ‰‹åŠ¨è¾“å…¥ï¼‰
MODEL_OPTIONS = {
    "DeepSeek Chat": {
        "provider": "deepseek", 
        "model": "deepseek-chat", 
        "api_key": os.getenv("DEEPSEEK_API_KEY", "sk-1f346646d29947d0a5e29dbaa37476b8"),
        "env_var": "DEEPSEEK_API_KEY"
    },
    "OpenAI GPT-4oï¼ˆå°šä¸æ”¯æŒï¼‰": {
        "provider": "openai", 
        "model": "gpt-4o-mini", 
        "api_key": os.getenv("OPENAI_API_KEY", "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"),
        "env_var": "OPENAI_API_KEY"
    },
    "Moonshotï¼ˆKimiï¼‰": {
        "provider": "moonshot", 
        "model": "moonshot-v1-32k", 
        "api_key": os.getenv("MOONSHOT_API_KEY", "sk-l5FvRWegjM5DEk4AU71YPQ1QgvFPTHZIJOmq6qdssPY4sNtE"),
        "env_var": "MOONSHOT_API_KEY"
    },
    "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰": {
        "provider": "qwen", 
        "model": "qwen-max", 
        "api_key": os.getenv("QWEN_API_KEY", "sk-b3f7a1153e6f4a44804a296038aa86c5"),
        "env_var": "QWEN_API_KEY"
    },
}

# ===============================
# è¯ç±»è§„åˆ™ä¸æœ€å¤§å¾—åˆ†
# ===============================
RULE_SETS = {
    # 1.1 åè¯
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸èƒ½å¸¦å®¾è¯­ï¼Œä¸èƒ½å—çŠ¶è¯­å’Œè¡¥è¯­ï¼Œä¸èƒ½åé™„æ—¶ä½“åŠ©è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    # 1.5 åŠ¨è¯
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼Œæˆ–è¿›å…¥'...äº†æ²¡æœ‰'æ ¼å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œæˆ–é€šè¿‡'å’Œ/ä¸º/å¯¹/å‘/æ‹¿/äº'ç­‰ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­ï¼ˆæŒ‰æ¡ç›®ç»™äºˆå¾—åˆ†ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V, Väº†V, Vä¸V, Väº†æ²¡æœ‰'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸€èˆ¬å¯å—çŠ¶è¯­æˆ–è¡¥è¯­ä¿®é¥°ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®æˆ–è·Ÿåœ¨'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®ï¼Œä¸èƒ½è·Ÿåœ¨'å¤šä¹ˆ'ä¹‹åè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
    ],
    # 4.6 ååŠ¨è¯
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®šï¼Œå¹¶ä¸”\"æ²¡æœ‰â€¦â€¦\"çš„è‚¯å®šå½¢å¼å¯ä»¥æ˜¯\"â€¦â€¦äº†\"å’Œ\"æœ‰â€¦â€¦\"(å‰ä¸€ç§æƒ…å†µä¸­çš„\"æ²¡æœ‰\"æ˜¯å‰¯è¯ï¼Œåä¸€ç§æƒ…å†µä¸­çš„\"æ²¡æœ‰\"æ˜¯åŠ¨è¯)", "match_score": 10, "mismatch_score": -10},            {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"ï¼Œæˆ–è€…å¯ä»¥è¿›å…¥\"â€¦â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰\"VVã€Vä¸€Vã€Väº†Vã€Vä¸V\"ç­‰é‡å å’Œæ­£åé‡å å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­ï¼Œå¹¶ä¸”ï¼Œå¯ä»¥ä½œå½¢å¼åŠ¨è¯\"ä½œã€è¿›è¡Œã€åŠ ä»¥ã€ç»™äºˆã€å—åˆ°\"ç­‰çš„å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°ï¼Œæˆ–è€…å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åï¼Œå¯¹åŠ¨ä½œçš„æ–¹å¼è¿›è¡Œæé—®ï¼Œå¹¶ä¸”å¯ä»¥è·Ÿåœ¨\"è¿™ä¹ˆã€è¿™æ ·ã€é‚£ä¹ˆã€é‚£æ ·\"ä¹‹åï¼Œç”¨ä»¥ä½œå‡ºç›¸åº”çš„å›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š\"ä¹‹åï¼Œå¯¹æ€§è´¨çš„ç¨‹åº¦è¿›è¡Œæé—®ï¼Œä¹Ÿä¸èƒ½è·Ÿåœ¨\"å¤šä¹ˆ\"ä¹‹åï¼Œè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10}
    ]
}

# é¢„è®¡ç®—æ¯ä¸ªè¯ç±»çš„æœ€å¤§å¯èƒ½å¾—åˆ†
MAX_SCORES = {pos: sum(abs(r["match_score"]) for r in rules) for pos, rules in RULE_SETS.items()}

# ===============================
# å·¥å…·å‡½æ•°
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    if not isinstance(resp_json, dict): return ""
    try:
        # --- æ–°å¢ï¼šå¤„ç†é€šä¹‰åƒé—® (Qwen) çš„å“åº”æ ¼å¼ ---
        if "output" in resp_json and "text" in resp_json["output"]:
            return resp_json["output"]["text"]
            
        # --- åŸæœ‰çš„ï¼šå¤„ç† OpenAI ç³»åˆ—çš„å“åº”æ ¼å¼ ---
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
            for k in ("content", "text"):
                if k in choice: return choice[k]
    except Exception: 
        pass
    # å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œè¿”å›æ•´ä¸ªå“åº”çš„å­—ç¬¦ä¸²å½¢å¼ï¼Œç”¨äºè°ƒè¯•
    return json.dumps(resp_json, ensure_ascii=False)
    
def extract_json_from_text(text: str) -> Tuple[dict, str]:
    if not text: return None, ""
    text = text.strip()
    # å°è¯•ç›´æ¥è§£æ
    try: return json.loads(text), text
    except: pass
    
    # å°è¯•æå–æ–‡æœ¬ä¸­çš„JSONå—
    match = re.search(r"(\{[\s\S]*\})", text)
    if not match: return None, text
    
    json_str = match.group(1)
    # æ¸…ç†å¸¸è§çš„æ ¼å¼é—®é¢˜
    json_str = json_str.replace("ï¼š", ":").replace("ï¼Œ", ",").replace("â€œ", '"').replace("â€", '"')
    json_str = re.sub(r"'(\s*[^']+?\s*)'\s*:", r'"\1":', json_str)
    json_str = re.sub(r":\s*'([^']*?)'", r': "\1"', json_str)
    json_str = re.sub(r",\s*([}\]])", r"\1", json_str) # å»é™¤ trailing commas
    json_str = re.sub(r"\bTrue\b", "true", json_str)
    json_str = re.sub(r"\bFalse\b", "false", json_str)
    json_str = re.sub(r"\bNone\b", "null", json_str)
    
    try: return json.loads(json_str), json_str
    except Exception as e:
        st.warning(f"è§£æJSONå¤±è´¥: {e}")
        return None, text

def normalize_key(k: str, pos_rules: list) -> str:
    if not isinstance(k, str): return None
    k_upper = re.sub(r'\s+', '', k).upper()
    for r in pos_rules:
        if re.sub(r'\s+', '', r["name"]).upper() == k_upper:
            return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    # å¼ºåˆ¶ä¿ç•™åŸå§‹å¾—åˆ†ä¸­çš„è´Ÿåˆ†ï¼ˆå¦‚æœæ˜¯æœ‰æ•ˆè§„åˆ™åˆ†ï¼‰
    if isinstance(raw_val, (int, float)):
        # å…è®¸åŒ¹é…å¾—åˆ†æˆ–ä¸åŒ¹é…å¾—åˆ†ï¼ˆåŒ…æ‹¬è´Ÿåˆ†ï¼‰
        if raw_val == match_score or raw_val == mismatch_score:
            return int(raw_val)
    if isinstance(raw_val, bool):
        return match_score if raw_val else mismatch_score
    if isinstance(raw_val, str):
        s = raw_val.strip().lower()
        if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"):
            return match_score
        if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"):
            return mismatch_score
    # æ— æ•ˆå€¼æ—¶è¿”å›ä¸åŒ¹é…å¾—åˆ†ï¼ˆä¿ç•™è´Ÿåˆ†ï¼‰
    return mismatch_score

def calculate_membership(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    membership = {}
    for pos, scores in scores_all.items():
        total_score = sum(scores.values())
        # æ”¹ä¸ºï¼šæ€»å¾—åˆ†é™¤ä»¥100å¾—åˆ°éš¶å±åº¦ï¼ˆå‡ ååˆ†å¯¹åº”é›¶ç‚¹å‡ ï¼‰
        # åŒæ—¶é™åˆ¶åœ¨ [0, 1] åŒºé—´å†…
        # è´Ÿåˆ†å¯é™ä½éš¶å±åº¦ï¼Œä¿ç•™åŸå§‹è®¡ç®—é€»è¾‘ä½†ä¸å¼ºåˆ¶æˆªæ–­ä¸º0ï¼ˆå¯é€‰è°ƒæ•´ï¼‰
        normalized = total_score / 100
        # è‹¥éœ€å…è®¸éš¶å±åº¦ä¸ºè´Ÿï¼ˆæ›´å‡†ç¡®åæ˜ è´Ÿåˆ†å½±å“ï¼‰ï¼Œå¯æ”¹ä¸ºï¼š
        # membership[pos] = normalized
        # è‹¥éœ€é™åˆ¶åœ¨[-1, 1]åŒºé—´ï¼š
        membership[pos] = max(-1.0, min(1.0, normalized))
    return membership

def get_top_10_positions(membership: Dict[str, float]) -> List[Tuple[str, float]]:
    return sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]

def prepare_detailed_scores_df(scores_all: Dict[str, Dict[str, int]]) -> pd.DataFrame:
    rows = []
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            rows.append({
                "è¯ç±»": pos,
                "è§„åˆ™ä»£ç ": rule["name"],
                "è§„åˆ™æè¿°": rule["desc"],
                "å¾—åˆ†": scores_all[pos].get(rule["name"], 0)
            })
    return pd.DataFrame(rows)

# ===============================
# å®‰å…¨çš„ LLM è°ƒç”¨å‡½æ•° (å¢åŠ è¶…æ—¶)
# ===============================
def call_llm_api_cached(_provider, _model, _api_key, messages, max_tokens=4096, temperature=0.0):
    if not _api_key: return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"
    if _provider not in MODEL_CONFIGS: return False, {"error": f"æœªçŸ¥æä¾›å•† {_provider}"}, f"æœªçŸ¥æä¾›å•† {_provider}"

    cfg = MODEL_CONFIGS[_provider]
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](_api_key)
    payload = cfg["payload"](_model, messages, max_tokens=max_tokens, temperature=temperature)

    try:
        # å¢åŠ è¶…æ—¶è®¾ç½®åˆ°120ç§’
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        return True, response.json(), ""
    except requests.exceptions.Timeout:
        error_msg = "è¯·æ±‚è¶…æ—¶ã€‚æ¨¡å‹å¯èƒ½æ­£å¿™æˆ–ç½‘ç»œè¿æ¥è¾ƒæ…¢ã€‚å»ºè®®å°è¯•å…¶ä»–æ¨¡å‹æˆ–ç¨åå†è¯•ã€‚"
        return False, {"error": error_msg}, error_msg
    except requests.exceptions.RequestException as e:
        # å¯¹äº4xxå’Œ5xxé”™è¯¯ï¼Œæå–æ›´å¤šä¿¡æ¯
        error_msg = f"APIè¯·æ±‚å¤±è´¥: {str(e)}"
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_details = e.response.json()
                if 'error' in error_details:
                    error_msg += f" è¯¦æƒ…: {error_details['error']['message']}"
            except:
                error_msg += f" å“åº”å†…å®¹: {e.response.text[:200]}..." # åªæ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
        return False, {"error": error_msg}, error_msg
    except Exception as e:
        error_msg = f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        return False, {"error": error_msg}, error_msg

# ===============================
# è¯ç±»åˆ¤å®šä¸»å‡½æ•° (ä¼˜åŒ–Prompt)
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str, str]:
    if not word:
        return {}, "", "æœªçŸ¥", ""

    # ä¼˜åŒ–1ï¼šç­›é€‰æ¯ä¸ªè¯ç±»çš„æ ¸å¿ƒè§„åˆ™ï¼ˆmatch_scoreâ‰¥20ï¼‰ï¼Œå‡å°‘ä¼ è¾“é‡
    core_rules_text = "\n".join([
        f'"{pos}": {{' + ', '.join([f'"{r["name"]}": {r["match_score"]}' for r in rules if r["match_score"] >= 20]) + '}' 
        for pos, rules in RULE_SETS.items()
    ])
    core_rules_text = "{\n" + core_rules_text + "\n}"

    # ä¼˜åŒ–2ï¼šå®Œæ•´è§„åˆ™ä»…ä¿ç•™å€™é€‰è¯ç±»çš„ï¼Œé€šè¿‡è§„åˆ™åˆ¤æ–­åˆ†é˜¶æ®µå¤„ç†
    full_rules_by_pos = {
        pos: "\n".join([f'"{r["name"]}": {r["match_score"]}' for r in rules])
        for pos, rules in RULE_SETS.items()
    }

    # ä¼˜åŒ–3ï¼šåˆ†é˜¶æ®µæç¤ºè¯ï¼Œç›´æ¥åŸºäºè§„åˆ™åˆ¤æ–­
    system_msg = f"""ä½ æ˜¯ä¸€ä½ä¸­æ–‡è¯­è¨€å­¦ä¸“å®¶ã€‚ä½ çš„ä»»åŠ¡æ˜¯æ ¹æ®æä¾›çš„è§„åˆ™ï¼Œä¸ºç»™å®šçš„è¯è¯­ã€Œ{word}ã€è¿›è¡Œè¯ç±»éš¶å±åº¦è¯„åˆ†ã€‚è¯·ä¸¥æ ¼æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

#### æ­¥éª¤1ï¼šåŸºäºè§„åˆ™è¿›è¡Œç›´æ¥åˆ¤æ–­ï¼ˆå¿…é¡»åŒ…å«æ­¤æ€è€ƒè¿‡ç¨‹ï¼‰
1. åˆ†æè¯è¯­ã€Œ{word}ã€çš„è¯­æ³•ç‰¹å¾ï¼Œå¯¹ç…§ä»¥ä¸‹æ ¸å¿ƒè§„åˆ™è¿›è¡ŒåŒ¹é…ï¼š
{core_rules_text}
2. é’ˆå¯¹å…¨éƒ¨3ä¸ªè¯ç±»é€æ¡è§„åˆ™åˆ¤æ–­åŒ¹é…æƒ…å†µ
3. è¯´æ˜åˆ¤æ–­ä¾æ®ï¼ˆå¦‚ï¼š"ç¬¦åˆåè¯è§„åˆ™N1ï¼Œèƒ½å—æ•°é‡è¯ä¿®é¥°ï¼›ä¸ç¬¦åˆåŠ¨è¯è§„åˆ™V3ï¼Œä¸èƒ½å¸¦å®¾è¯­"ï¼‰

#### æ­¥éª¤2ï¼šå¯¹æ‰€æœ‰è¯ç±»è¿›è¡Œè§„åˆ™è¯„åˆ†
1. é’ˆå¯¹å…¨éƒ¨3ä¸ªè¯ç±»ï¼Œä½¿ç”¨å„ç±»åˆ«çš„å…¨éƒ¨è§„åˆ™é€æ¡åˆ¤æ–­
2. æ¯æ¡è§„åˆ™åŒ¹é…åˆ™å¾—å¯¹åº”match_scoreï¼Œä¸åŒ¹é…åˆ™å¾—mismatch_scoreï¼ˆåŒ…æ‹¬è´Ÿåˆ†ï¼‰
3. å¿…é¡»ä¸¥æ ¼ä½¿ç”¨è§„åˆ™å®šä¹‰çš„åˆ†æ•°ï¼Œ**ä¸åŒ¹é…æ—¶å¿…é¡»ä½¿ç”¨è´Ÿåˆ†ï¼Œç»å¯¹ä¸èƒ½ç”¨0åˆ†ä»£æ›¿**
4. æ‰€æœ‰è¯ç±»çš„å®Œæ•´è§„åˆ™ï¼š
"""
    # æ‹¼æ¥æ‰€æœ‰è¯ç±»çš„å®Œæ•´è§„åˆ™ï¼ˆä¾›æ¨¡å‹åœ¨æ­¥éª¤2ä½¿ç”¨ï¼‰
    for pos, rules_str in full_rules_by_pos.items():
        system_msg += f'\n{pos}çš„å®Œæ•´è§„åˆ™ï¼š\n{{{rules_str}}}'
    
    system_msg += f"""

#### æ­¥éª¤3ï¼šè¿”å›æœ€ç»ˆç»“æœï¼ˆä»…è¾“å‡ºJSONï¼Œæ— å…¶ä»–æ–‡å­—ï¼‰
è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹æ ¼å¼è¿”å›ï¼Œç¡®ä¿JSONå®Œæ•´ä¸”æ ¼å¼æ­£ç¡®ï¼š
{{
  "predicted_pos": "æœ€å¯èƒ½çš„è¯ç±»åç§°ï¼ˆä»3ä¸ªè¯ç±»ä¸­é€‰æ‹©ï¼‰",
  "scores": {{
    "è¯ç±»1": {{ "è§„åˆ™1": å¾—åˆ†, "è§„åˆ™2": å¾—åˆ†, ... }},
    "è¯ç±»2": {{ "è§„åˆ™1": å¾—åˆ†, "è§„åˆ™2": å¾—åˆ†, ... }},
    "è¯ç±»3": {{ "è§„åˆ™1": å¾—åˆ†, "è§„åˆ™2": å¾—åˆ†, ... }}
  }},
  "explanation": "ç®€è¦è¯´æ˜åˆ¤å®šä¸ºæœ€å¯èƒ½è¯ç±»çš„ä¸»è¦ä¾æ®ï¼ˆ1-2å¥è¯ï¼‰"
}}

å…³é”®è¯´æ˜ï¼š
1. æ­¥éª¤1éœ€åŸºäºè§„åˆ™ç›´æ¥åˆ¤æ–­ï¼Œæ˜ç¡®è¯´æ˜æ¯ä¸ªè¯ç±»åŒ¹é…æˆ–ä¸åŒ¹é…çš„å…·ä½“è§„åˆ™
2. æ­¥éª¤2å¯¹å…¨éƒ¨3ä¸ªè¯ç±»è¿›è¡Œå®Œæ•´è¯„åˆ†ï¼Œä¸¥æ ¼æ‰§è¡Œè§„åˆ™åˆ†æ•°ä½“ç³»
3. ç¡®ä¿"scores"ä¸­çš„è§„åˆ™åç§°ä¸æä¾›çš„å®Œå…¨ä¸€è‡´
4. ä¸¥æ ¼ä½¿ç”¨è§„åˆ™å®šä¹‰çš„mismatch_scoreï¼ˆåŒ…æ‹¬è´Ÿåˆ†ï¼‰ï¼Œç¦æ­¢ç”¨0åˆ†æ›¿ä»£
"""

    # ç”¨æˆ·æç¤ºä»…éœ€è§¦å‘æ¨¡å‹å¼€å§‹åˆ†æ
    user_prompt = f"è¯·æ ¹æ®ä¸Šè¿°è§„åˆ™åˆ¤æ–­æ­¥éª¤ï¼Œä¸ºè¯è¯­ã€Œ{word}ã€è¿›è¡Œè¯ç±»éš¶å±åº¦è¯„åˆ†å¹¶è¿”å›JSONç»“æœã€‚"

    # æ˜¾ç¤ºåŠ è½½çŠ¶æ€
    with st.spinner("æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æï¼Œè¯·ç¨å€™..."):
        # ä½¿ç”¨ç¼“å­˜è°ƒç”¨API
        ok, resp_json, err_msg = call_llm_api_cached(
            _provider=provider,
            _model=model,
            _api_key=api_key,
            messages=[{"role": "system", "content": system_msg}, {"role": "user", "content": user_prompt}]
        )

    if not ok:
        st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {err_msg}")
        return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", f"è°ƒç”¨å¤±è´¥: {err_msg}"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, cleaned_json_text = extract_json_from_text(raw_text)
    
    # å¤„ç†è§£æç»“æœ
    if parsed_json:
        explanation = parsed_json.get("explanation", "æ¨¡å‹æœªæä¾›è¯¦ç»†æ¨ç†è¿‡ç¨‹ã€‚")
        predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
        raw_scores = parsed_json.get("scores", {})
    else:
        st.warning("æœªèƒ½ä»æ¨¡å‹å“åº”ä¸­è§£æå‡ºæœ‰æ•ˆçš„JSONã€‚")
        explanation = "æ— æ³•è§£ææ¨¡å‹è¾“å‡ºã€‚"
        predicted_pos = "æœªçŸ¥"
        raw_scores = {}
        cleaned_json_text = raw_text  # å±•ç¤ºåŸå§‹æ–‡æœ¬

    # --- å…³é”®ä¿®å¤ï¼šåœ¨å¾ªç¯å¼€å§‹å‰ï¼Œåˆå§‹åŒ– scores_out ---
    # ä¸ºäº†é¿å… KeyErrorï¼Œå…ˆä¸ºæ¯ä¸ªè¯ç±»ï¼ˆposï¼‰åœ¨ scores_out ä¸­åˆ›å»ºä¸€ä¸ªç©ºå­—å…¸
    scores_out = {pos: {} for pos in RULE_SETS.keys()}

    # æ ¼å¼åŒ–å¾—åˆ†ï¼ˆç¡®ä¿æ‰€æœ‰è¯ç±»çš„è§„åˆ™éƒ½æœ‰å¯¹åº”æ¡ç›®ï¼Œæœªè¯„åˆ†çš„è§„åˆ™å¡«0ï¼‰
    # æ”¹ä¸ºï¼šè®¤å¯åŒ¹é…å¾—åˆ†æˆ–ä¸åŒ¹é…å¾—åˆ†ï¼ˆåŒ…æ‹¬è´Ÿåˆ†ï¼‰
    for pos, rules in RULE_SETS.items():
        raw_pos_scores = raw_scores.get(pos, {})
        if isinstance(raw_pos_scores, dict):
            for k, v in raw_pos_scores.items():
                normalized_key = normalize_key(k, rules)
                if normalized_key:
                    # æŸ¥æ‰¾å½“å‰è§„åˆ™çš„å®šä¹‰
                    rule_def = next(r for r in rules if r["name"] == normalized_key)
                    # å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ map_to_allowed_score å‡½æ•°å¤„ç†å¾—åˆ†ï¼Œä¿ç•™è´Ÿåˆ†
                    scores_out[pos][normalized_key] = map_to_allowed_score(rule_def, v)
    
    # å¾ªç¯ç»“æŸåï¼Œç¡®ä¿æ‰€æœ‰è§„åˆ™éƒ½æœ‰ä¸€ä¸ªå¾—åˆ†ï¼ˆæœªè¢«æ¨¡å‹è¯„åˆ†çš„è§„åˆ™ï¼Œå…¶å¾—åˆ†ä¸º0ï¼‰
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            rule_name = rule["name"]
            # å¦‚æœè§„åˆ™åœ¨ scores_out ä¸­æ²¡æœ‰å¾—åˆ†ï¼Œåˆ™é»˜è®¤ä¸º0
            if rule_name not in scores_out[pos]:
                scores_out[pos][rule_name] = 0
    
    return scores_out, cleaned_json_text, predicted_pos, explanation
# ===============================
# é›·è¾¾å›¾
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    if not scores_norm:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return
    categories = list(scores_norm.keys())
    if not categories:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆè¯ç±»ã€‚")
        return
    values = list(scores_norm.values())
    
    # é—­åˆé›·è¾¾å›¾
    categories += [categories[0]]
    values += [values[0]]

    fig = go.Figure(data=[go.Scatterpolar(r=values, theta=categories, fill="toself", name="éš¶å±åº¦")])
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=False,
        title=dict(text=title, x=0.5, font=dict(size=16))
    )
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# ä¸»é¡µé¢é€»è¾‘
# ===============================
def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»")
    
    # --- é¡¶éƒ¨å›ºå®šæ§åˆ¶åŒº ---
    control_container = st.container()
    with control_container:
        col1, col2, col3 = st.columns([2, 1, 3])
        
        with col1:
            st.subheader("âš™ï¸ æ¨¡å‹è®¾ç½®")
            selected_model_display_name = st.selectbox("é€‰æ‹©å¤§æ¨¡å‹", list(MODEL_OPTIONS.keys()), key="model_select")
            selected_model_info = MODEL_OPTIONS[selected_model_display_name]
            
            # æ£€æŸ¥API Keyæ˜¯å¦å­˜åœ¨
            if not selected_model_info["api_key"]:
                st.error(f"âŒ æœªæ‰¾åˆ° {selected_model_display_name} çš„API Key")
                st.info(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ **{selected_model_info['env_var']}** åé‡è¯•")
                st.code(f"# Linux/Mac\n export {selected_model_info['env_var']}='ä½ çš„API Key'\n\n# Windows\n set {selected_model_info['env_var']}='ä½ çš„API Key'", language="bash")
        
        with col2:
            st.subheader("ğŸ”— è¿æ¥æµ‹è¯•")
            if not selected_model_info["api_key"]:
                st.disabled(True)
                st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary", disabled=True)
            else:
                if st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary"):
                    with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„pingè¯·æ±‚æ¥æµ‹è¯•è¿æ¥
                        ok, _, err_msg = call_llm_api_cached(
                            _provider=selected_model_info["provider"],
                            _model=selected_model_info["model"],
                            _api_key=selected_model_info["api_key"],
                            messages=[{"role": "user", "content": "è¯·å›å¤'pong'"}],
                            max_tokens=10
                        )
                    if ok:
                        st.success("âœ… æ¨¡å‹é“¾æ¥æµ‹è¯•æˆåŠŸï¼")
                    else:
                        st.error(f"âŒ æ¨¡å‹é“¾æ¥æµ‹è¯•å¤±è´¥: {err_msg}")

        with col3:
            st.subheader("ğŸ”¤ è¯è¯­è¾“å…¥")
            word = st.text_input("è¯·è¾“å…¥è¦åˆ†æçš„æ±‰è¯­è¯è¯­", placeholder="ä¾‹å¦‚ï¼šè‹¹æœã€è·‘ã€ç¾ä¸½...", key="word_input")
            
            # å¼€å§‹åˆ†ææŒ‰é’®ï¼ˆAPI Keyä¸ºç©ºæ—¶ç¦ç”¨ï¼‰
            analyze_button = st.button(
                "ğŸš€ å¼€å§‹åˆ†æ", 
                type="primary",
                disabled=not (selected_model_info["api_key"] and word)
            )

    st.markdown("---")

    
    # --- ä½¿ç”¨è¯´æ˜ ---
    info_container = st.container()
    with info_container:
        with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜", expanded=False):
            st.info("""
            1. åœ¨ä¸Šæ–¹çš„â€œè¯è¯­è¾“å…¥â€æ¡†ä¸­è¾“å…¥ä¸€ä¸ªæ±‰è¯­è¯ã€‚
            2. ï¼ˆå¯é€‰ï¼‰åœ¨æ¨¡å‹é€‰æ‹©åŒºåŸŸç‚¹å‡»å‘ä¸‹ç®­å¤´å±•å¼€ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ã€‚
            3. ï¼ˆå¯é€‰ï¼‰ç‚¹å‡»â€œæµ‹è¯•æ¨¡å‹é“¾æ¥â€æŒ‰é’®ï¼Œç¡®è®¤æ‰€é€‰æ¨¡å‹å¯ä»¥æ­£å¸¸è®¿é—®ã€‚
            4. ç‚¹å‡»â€œå¼€å§‹åˆ†æâ€æŒ‰é’®ï¼Œç³»ç»Ÿå°†ä½¿ç”¨é€‰å®šçš„å¤§æ¨¡å‹åˆ†æè¯¥è¯è¯­çš„è¯ç±»éš¶å±åº¦ã€‚
            5. åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨ä¸‹æ–¹ï¼ŒåŒ…æ‹¬éš¶å±åº¦æ’åã€è¯¦ç»†å¾—åˆ†ã€æ¨ç†è¿‡ç¨‹å’ŒåŸå§‹å“åº”ã€‚
            """)

     # --- ç»“æœæ˜¾ç¤ºåŒº ---
    if analyze_button and word and selected_model_info["api_key"]:
        status_placeholder = st.empty()
        status_placeholder.info(f"æ­£åœ¨ä¸ºè¯è¯­ã€Œ{word}ã€å¯åŠ¨åˆ†æ...")

        scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
            word=word,
            provider=selected_model_info["provider"],
            model=selected_model_info["model"],
            api_key=selected_model_info["api_key"]
        )
        
        status_placeholder.empty()
        
        membership = calculate_membership(scores_all)
        st.success(f'**åˆ†æå®Œæˆ**ï¼šè¯è¯­ã€Œ{word}ã€æœ€å¯èƒ½çš„è¯ç±»æ˜¯ ã€{predicted_pos}ã€‘ï¼Œéš¶å±åº¦ä¸º {membership.get(predicted_pos, 0):.4f}')
        
        col_results_1, col_results_2 = st.columns(2)
        
        # --- å…³é”®ä¿®å¤ï¼šå°†ä¸¤ä¸ªåˆ—çš„å†…å®¹ç¼©è¿›ï¼Œæ”¾å…¥ if è¯­å¥å—å†… ---
        
        with col_results_1:
            st.subheader("ğŸ† è¯ç±»éš¶å±åº¦æ’åï¼ˆå‰åï¼‰")
            top10 = get_top_10_positions(membership)
            top10_df = pd.DataFrame(top10, columns=["è¯ç±»", "éš¶å±åº¦"])
            top10_df["éš¶å±åº¦"] = top10_df["éš¶å±åº¦"].apply(lambda x: f"{x:.4f}")
            st.table(top10_df)
            
            st.subheader("ğŸ“Š è¯ç±»éš¶å±åº¦é›·è¾¾å›¾ï¼ˆå‰åï¼‰")
            plot_radar_chart_streamlit(dict(top10), f"ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦åˆ†å¸ƒ")

        with col_results_2:
            st.subheader("ğŸ“‹ å„è¯ç±»è¯¦ç»†å¾—åˆ†ï¼ˆæŒ‰æ€»åˆ†æ’åå‰10ï¼‰")
            
            # 1. è®¡ç®—æ‰€æœ‰è¯ç±»çš„æ€»åˆ†å¹¶æ’åºï¼Œå–å‰10å
            pos_total_scores = {pos: sum(scores_all[pos].values()) for pos in RULE_SETS.keys()}
            # æŒ‰æ€»åˆ†é™åºæ’åºï¼Œå–å‰10
            top10_pos = sorted(pos_total_scores.items(), key=lambda x: x[1], reverse=True)[:10]
            
            # 2. åªæ˜¾ç¤ºæ’åå‰10çš„è¯ç±»
            for pos, total_score in top10_pos:
                # æ‰¾åˆ°è¯¥è¯ç±»ä¸‹å¾—åˆ†æœ€é«˜çš„è§„åˆ™
                max_rule = max(scores_all[pos].items(), key=lambda x: x[1], default=("æ— ", 0))
                
                # åˆ›å»ºexpanderï¼Œæ˜¾ç¤ºè¯ç±»åç§°ã€æ€»åˆ†å’Œæœ€é«˜åˆ†è§„åˆ™
                with st.expander(f"**{pos}** (æ€»åˆ†: {total_score}, æœ€é«˜åˆ†è§„åˆ™: {max_rule[0]} - {max_rule[1]}åˆ†)"):
                    # æ˜¾ç¤ºè¯¥è¯ç±»ä¸‹çš„æ‰€æœ‰è§„åˆ™å¾—åˆ†ï¼ˆæŒ‰è§„åˆ™å¾—åˆ†é™åºæ’åˆ—ï¼‰
                    rule_data = []
                    for rule in RULE_SETS[pos]:
                        rule_score = scores_all[pos][rule["name"]]
                        rule_data.append({
                            "è§„åˆ™ä»£ç ": rule["name"],
                            "è§„åˆ™æè¿°": rule["desc"],
                            "å¾—åˆ†": rule_score
                        })
                    
                    # æŒ‰å¾—åˆ†é™åºæ’åºè§„åˆ™ï¼Œè®©é«˜åˆ†è§„åˆ™æ’åœ¨å‰é¢
                    rule_data_sorted = sorted(rule_data, key=lambda x: x["å¾—åˆ†"], reverse=True)
                    rule_df = pd.DataFrame(rule_data_sorted)
                    
                    # è´Ÿåˆ†æ ‡çº¢
                    styled_df = rule_df.style.applymap(
                        lambda x: "color: #ff4b4b; font-weight: bold" if isinstance(x, int) and x < 0 else "",
                        subset=["å¾—åˆ†"]
                    )
                    
                    st.dataframe(
                        styled_df,
                        use_container_width=True,
                        height=min(len(rule_df) * 30 + 50, 800)
                    )
            
            st.subheader("ğŸ” æ¨¡å‹æ¨ç†è¿‡ç¨‹")
            st.text_area("æ¨ç†è¯¦æƒ…", explanation, height=200, disabled=True)
            
            st.subheader("ğŸ“¥ æ¨¡å‹åŸå§‹å“åº”")
            with st.expander("ç‚¹å‡»å±•å¼€æŸ¥çœ‹åŸå§‹å“åº”", expanded=False):
                st.code(raw_text, language="json")

    # --- if è¯­å¥å—ç»“æŸ ---



if __name__ == "__main__":
    main()
# ===============================
# é¡µé¢åº•éƒ¨è¯´æ˜
# ===============================
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:#666;'>"
    "Â© 2025 æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±» "
    "</div>",
    unsafe_allow_html=True
)
