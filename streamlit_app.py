import re
import json
import requests
import traceback
from typing import Dict, Any, Tuple, List
import streamlit as st
import plotly.graph_objects as go

# å‡è®¾MODEL_CONFIGSå’ŒMODEL_OPTIONSå·²å®šä¹‰ï¼ˆä¿æŒåŸæœ‰é…ç½®ï¼‰
MODEL_CONFIGS = {
    # è¿™é‡Œä¿æŒåŸæœ‰æ¨¡å‹é…ç½®ç»“æ„
    "OpenAI": {"base_url": "https://api.openai.com", "endpoint": "/v1/chat/completions", 
               "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
               "payload": lambda model, messages, max_tokens, temperature: {
                   "model": model, "messages": messages, "max_tokens": max_tokens, "temperature": temperature
               }},
    # å…¶ä»–æ¨¡å‹é…ç½®...
}

MODEL_OPTIONS = {
    # è¿™é‡Œä¿æŒåŸæœ‰æ¨¡å‹é€‰é¡¹
    "OpenAI (GPT-3.5)": {"provider": "OpenAI", "model": "gpt-3.5-turbo", "api_key_env": "OPENAI_API_KEY"},
    # å…¶ä»–æ¨¡å‹é€‰é¡¹...
}

# è¯ç±»è§„åˆ™é›†ï¼ˆä¿æŒä¸å˜ï¼‰
RULE_SETS = {
    # 2.4 è¯­æ°”è¯
    "è¯­æ°”è¯": [
        {"name": "MOD1_ä¸èƒ½å•ç‹¬å›ç­”ï¼ˆé»ç€è¯ï¼‰", "desc": "ä¸èƒ½å•ç‹¬å›ç­”é—®é¢˜ï¼ˆé»ç€è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "MOD2_åªèƒ½é™„ç€åœ¨å…¶ä»–æˆåˆ†ä¹‹åï¼ˆå››ç§ç”¨æ³•ä¹‹ä¸€å¾—60ï¼‰", "desc": "åªèƒ½é™„ç€åœ¨å…¶ä»–æˆåˆ†ä¹‹åï¼ˆå¥æœ«/è¯é¢˜æ€§æˆåˆ†å/å¹¶åˆ—é¡¹å/å‡è®¾åˆ†å¥åï¼‰", "match_score": 60, "mismatch_score": -60},
        {"name": "MOD3_ä¸èƒ½ä½œä¸»å®¾/ä¸èƒ½å—å®šè¯­", "desc": "ä¸èƒ½ä½œä¸»è¯­å’Œå®¾è¯­ï¼Œä¸èƒ½å—å®šè¯­ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "MOD4_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½ä½œè°“è¯­å’Œè°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "MOD5_ä¸èƒ½ä½œä¿®é¥°æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ã€å®šè¯­å’Œè¡¥è¯­ç­‰ä¿®é¥°æˆåˆ†", "match_score": 10, "mismatch_score": -10},
    ],
    # å…¶ä»–è¯ç±»è§„åˆ™...
}

MAX_SCORES = {pos: sum(abs(r["match_score"]) for r in rules) for pos, rules in RULE_SETS.items()}

# ===============================
# å·¥å…·å‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    if not isinstance(resp_json, dict):
        return ""
    try:
        choices = resp_json.get("choices")
        if choices and isinstance(choices, list) and len(choices) > 0:
            first = choices[0]
            msg = first.get("message")
            if isinstance(msg, dict) and "content" in msg:
                return msg["content"]
            for k in ("content", "text", "message"):
                if k in first and isinstance(first[k], str):
                    return first[k]
    except:
        pass
    return json.dumps(resp_json, ensure_ascii=False)

def extract_json_from_text(text: str) -> Tuple[dict, str]:
    if not text:
        return None, ""
    s = text.strip()
    try:
        return json.loads(s), s
    except:
        m = re.search(r"(\{[\s\S]*\})", s)
        if not m:
            return None, s
        cand = m.group(1)
        c = cand.replace("ï¼š", ":").replace("ï¼Œ", ",").replace("â€œ", '"').replace("â€", '"')
        c = re.sub(r"'(\s*[^']+?\s*)'\s*:", r'"\1":', c)
        c = re.sub(r":\s*'([^']*?)'", r': "\1"', c)
        c = re.sub(r",\s*([}\]])", r"\1", c)
        c = re.sub(r"\bTrue\b", "true", c)
        c = re.sub(r"\bFalse\b", "false", c)
        c = re.sub(r"\bNone\b", "null", c)
        try:
            return json.loads(c), c
        except:
            return None, s

def normalize_key(k: str, pos_rules: list) -> str:
    if not isinstance(k, str):
        return None
    kk = re.sub(r'\s+', '', k).upper()
    for r in pos_rules:
        if r["name"].upper() == kk or re.sub(r'\s+', '', r["name"]).upper() == kk:
            return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    match = rule["match_score"]
    mismatch = rule["mismatch_score"]
    if isinstance(raw_val, (int, float)):
        cand = [match, mismatch]
        return min(cand, key=lambda x: abs(x - float(raw_val)))
    if isinstance(raw_val, bool):
        return match if raw_val else mismatch
    if isinstance(raw_val, str):
        s = raw_val.strip().lower()
        if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"):
            return match
        if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"):
            return mismatch
    return mismatch

# ===============================
# å®‰å…¨çš„ LLM è°ƒç”¨å‡½æ•°
# ===============================
def call_llm_api(messages: list, provider: str, model: str, api_key: str,
                 max_tokens: int = 1024, temperature: float = 0.0, timeout: int = 30) -> Tuple[bool, dict, str]:
    """
    è°ƒç”¨æŒ‡å®š LLM API è·å–å“åº”ã€‚
    è¿”å›: (æˆåŠŸæ ‡å¿—, å“åº” dict, é”™è¯¯ä¿¡æ¯)
    """
    if not api_key:
        return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"

    if provider not in MODEL_CONFIGS:
        return False, {"error": f"æœªçŸ¥æä¾›å•† {provider}"}, f"æœªçŸ¥æä¾›å•† {provider}"

    cfg = MODEL_CONFIGS[provider]
    url = cfg["base_url"].rstrip("/") + cfg.get("endpoint", "/chat/completions")
    headers = cfg["headers"](api_key)
    payload = cfg["payload"](model, messages, max_tokens=max_tokens, temperature=temperature)

    try:
        r = requests.post(url, headers=headers, json=payload, timeout=timeout)
        
        if r.status_code != 200:
            return False, {"error": f"HTTPé”™è¯¯ {r.status_code}", "content": r.text}, f"HTTPé”™è¯¯ {r.status_code}: {r.text[:200]}"
            
        r.raise_for_status()
        resp_json = r.json()
        return True, resp_json, ""
    except Exception as e:
        error_msg = str(e)
        return False, {"error": error_msg}, error_msg

# æ–°å¢ï¼šæµ‹è¯•æ¨¡å‹è¿æ¥å‡½æ•°
def test_model_connection(provider: str, model: str, api_key: str) -> Tuple[bool, str]:
    """æµ‹è¯•æ¨¡å‹è¿æ¥æ˜¯å¦æˆåŠŸ"""
    if not api_key:
        return False, "API Key æœªæä¾›"
    
    # ä½¿ç”¨ç®€å•æ¶ˆæ¯æµ‹è¯•è¿æ¥
    test_messages = [
        {"role": "system", "content": "è¯·è¿”å›'è¿æ¥æµ‹è¯•æˆåŠŸ'"},
        {"role": "user", "content": "æµ‹è¯•è¿æ¥"}
    ]
    
    ok, _, err_msg = call_llm_api(
        messages=test_messages,
        provider=provider,
        model=model,
        api_key=api_key,
        max_tokens=10,
        temperature=0.0
    )
    
    return ok, err_msg if not ok else "è¿æ¥æˆåŠŸ"

# ===============================
# å®‰å…¨çš„è¯ç±»åˆ¤å®šå‡½æ•°ï¼ˆä¿æŒä¸å˜ï¼‰
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str]:
    if not word:
        return {}, "", "æœªçŸ¥"

    rules_summary_lines = []
    for pos, rules in RULE_SETS.items():
        rules_summary_lines.append(f"{pos}:")
        for r in rules:
            rules_summary_lines.append(f"  - {r['name']}: {r['desc']} (match={r['match_score']}, mismatch={r['mismatch_score']})")
    rules_text = "\n".join(rules_summary_lines)

    system_msg = (
        "ä½ æ˜¯è¯­è¨€å­¦ç ”ç©¶ä¸“å®¶ï¼Œæ‹¥æœ‰ä¸­å¤–è¯­è¨€å­¦ç•Œçš„æ‰€æœ‰çŸ¥è¯†ã€‚åœ¨è¾“å…¥ä¸€ä¸ªä¸­æ–‡è¯è¯­åï¼Œè¯·æ£€ç´¢å…¨ç½‘çš„ç›¸å…³çŸ¥è¯†ï¼Œä¸¥æ ¼æŒ‰ç…§å®šä¹‰çš„è§„åˆ™ï¼Œè¯·åˆ¤æ–­æœ€å¯èƒ½çš„è¯ç±»å¹¶è¿”å› JSONï¼š"
        '{"predicted_pos":"<è¯ç±»å>", "scores": {"<è¯ç±»å>": {"<è§„åˆ™å>": <å€¼>, ...}, ...}, "explanation":"è¯´æ˜"}ã€‚'
    )
    user_prompt = f"è¯è¯­ï¼šã€{word}ã€\nè¯·åŸºäºä¸‹åˆ—è§„åˆ™åˆ¤å®šå¹¶è¯„åˆ†ï¼š\n\n{rules_text}\n\nä»…è¿”å›ä¸¥æ ¼ JSONã€‚"

    ok, resp_json, err_msg = call_llm_api(
        messages=[{"role": "system", "content": system_msg},
                  {"role": "user", "content": user_prompt}],
        provider=provider,
        model=model,
        api_key=api_key
    )

    if not ok or not resp_json:
        return {}, f"è°ƒç”¨å¤±è´¥æˆ–è¿”å›å¼‚å¸¸: {err_msg}", "æœªçŸ¥"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, _ = extract_json_from_text(raw_text)
    if not parsed_json:
        return {}, raw_text, "æœªçŸ¥"

    scores_out = {}
    predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
    raw_scores = parsed_json.get("scores", {})

    for pos, rules in RULE_SETS.items():
        scores_out[pos] = {r["name"]: 0 for r in rules}
        raw_for_pos = raw_scores.get(pos, {})
        if isinstance(raw_for_pos, dict):
            for k, v in raw_for_pos.items():
                nk = normalize_key(k, rules)
                if nk:
                    rule_def = next(r for r in rules if r["name"] == nk)
                    scores_out[pos][nk] = map_to_allowed_score(rule_def, v)

    return scores_out, raw_text, predicted_pos

# ===============================
# é›·è¾¾å›¾ï¼ˆä¿æŒä¸å˜ï¼‰
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    if not scores_norm:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return
    categories = list(scores_norm.keys())
    if not categories:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆè¯ç±»ã€‚")
        return
    values = [float(scores_norm[c]) for c in categories]
    categories += [categories[0]]
    values += [values[0]]

    fig = go.Figure(
        data=[go.Scatterpolar(r=values, theta=categories, fill="toself", name="éš¶å±åº¦")]
    )
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=False, title=dict(text=title, x=0.5)
    )
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# Streamlit UI
# ===============================

# ======== ä¾§è¾¹æ éƒ¨åˆ† ========
st.sidebar.markdown("## æ¨¡å‹è®¾ç½®")
model_choice = st.sidebar.selectbox("é€‰æ‹©æ¨¡å‹", list(MODEL_OPTIONS.keys()))
selected_model = MODEL_OPTIONS[model_choice]

st.sidebar.markdown(f"**å½“å‰æ¨¡å‹ï¼š** {model_choice}")
st.sidebar.markdown(f"**æ¨¡å‹åç§°ï¼š** `{selected_model['model']}`")

# è¾“å…¥API Keyï¼ˆå¯†ç æ¡†å½¢å¼ï¼Œä¸æ˜¾ç¤ºæ˜æ–‡ï¼‰
api_key_input = st.sidebar.text_input(
    "API Key",
    type="password",
    placeholder=f"è¯·è¾“å…¥{model_choice}çš„API Key",
    help=f"éœ€è¦{selected_model['api_key_env']}ç¯å¢ƒå˜é‡å¯¹åº”çš„å¯†é’¥"
)

# æµ‹è¯•è¿æ¥æŒ‰é’®
if st.sidebar.button("æµ‹è¯•æ¨¡å‹è¿æ¥"):
    if not api_key_input:
        st.sidebar.error("è¯·å…ˆè¾“å…¥API Key")
    else:
        with st.sidebar.spinner("æµ‹è¯•è¿æ¥ä¸­..."):
            ok, msg = test_model_connection(
                selected_model["provider"],
                selected_model["model"],
                api_key_input
            )
            if ok:
                st.sidebar.success(f"âœ… {msg}")
            else:
                st.sidebar.error(f"âŒ è¿æ¥å¤±è´¥ï¼š{msg}")

# ======== ä¸»ä½“éƒ¨åˆ† ========
st.markdown("<h1 style='text-align: center;'>ğŸ“Šæ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ¤ç±»</h1>", unsafe_allow_html=True)
st.markdown("<p style='text-align: center; color: grey;'>è¾“å…¥å•ä¸ªè¯ â†’ æ¨¡å‹è‡ªåŠ¨åˆ¤ç±»å¹¶è¿”å›å„è¯ç±»è§„åˆ™å¾—åˆ†ä¸éš¶å±åº¦ï¼ˆæ ‡å‡†åŒ– 0~1ï¼‰</p>", unsafe_allow_html=True)
st.write("")

c1, c2, c3 = st.columns([1, 2, 1])
with c2:
    word_input = st.text_input("", placeholder="åœ¨æ­¤è¾“å…¥è¦åˆ†æçš„è¯ï¼ˆä¾‹å¦‚ï¼šå¾ˆ / è·‘ / ç¾ä¸½ï¼‰")
    confirm = st.button("ç¡®è®¤")

if confirm:
    word = (word_input or "").strip()
    if not word:
        st.warning("è¯·è¾“å…¥ä¸€ä¸ªè¯è¯­åç¡®è®¤ã€‚")
    else:
        if not api_key_input:
            st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ è¾“å…¥API Key")
            scores_all, raw_out, predicted_pos = {}, "", "æ— "
        else:
            with st.spinner("æ¨¡å‹æ‰“åˆ†åˆ¤ç±»ä¸­â€¦â€¦"):
                try:
                    scores_all, raw_out, predicted_pos = ask_model_for_pos_and_scores(
                        word, selected_model["provider"], selected_model["model"], api_key_input
                    )
                except Exception as e:
                    st.error(f"æ¨¡å‹è°ƒç”¨å‡ºé”™ï¼š{e}")
                    traceback.print_exc()
                    scores_all, raw_out, predicted_pos = {}, str(e), "é”™è¯¯"

        if scores_all:
            st.subheader(f"è¯ç±»é¢„æµ‹ç»“æœï¼š{predicted_pos}")
            st.json(scores_all)
            st.text_area("åŸå§‹è¾“å‡º", raw_out, height=200)
        else:
            st.info("æœªè·å¾—æœ‰æ•ˆè¯„åˆ†ç»“æœã€‚è¯·æ£€æŸ¥ API Key æˆ–ç½‘ç»œè¿æ¥ã€‚")
            st.text_area("é”™è¯¯ä¿¡æ¯", raw_out, height=200)
        
        # è®¡ç®—æ¯ä¸ªè¯ç±»æ€»åˆ†ä¸å½’ä¸€åŒ–éš¶å±åº¦
        pos_totals = {}
        pos_normed = {}
        for pos, score_map in scores_all.items():
            total = sum(score_map.values())
            pos_totals[pos] = total
            max_possible = MAX_SCORES.get(pos, sum(abs(x) for x in score_map.values()) or 1)
            norm = round(max(0, total) / max_possible, 3) if max_possible != 0 else 0.0
            pos_normed[pos] = norm

        # è¾“å‡ºé¡¶éƒ¨æ‘˜è¦
        st.markdown("---")
        st.subheader("åˆ¤å®šæ‘˜è¦")
        st.markdown(f"- **è¾“å…¥è¯**ï¼š `{word}`")
        st.markdown(f"- **æ¨¡å‹é¢„æµ‹è¯ç±»**ï¼š **{predicted_pos}**")

        # æ’åä¸è¡¨æ ¼
        ranked = []
        if pos_normed:
            ranked = sorted(pos_normed.items(), key=lambda x: x[1], reverse=True)
        
        st.subheader("éš¶å±åº¦æ’è¡Œï¼ˆå‰10ï¼‰")
        if ranked:
            for i, (p, s) in enumerate(ranked[:10]):
                st.write(f"{i+1}. **{p}** â€” éš¶å±åº¦ï¼š{s}")
