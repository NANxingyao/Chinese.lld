import streamlit as st
import requests
import json
import re
import os
import pandas as pd
import plotly.graph_objects as go
import io
from typing import Tuple, Dict, Any, List
from openpyxl import load_workbook
from openpyxl.styles import PatternFill

# ===============================
# é¡µé¢é…ç½®
# ===============================
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±» (ä¸“ä¸šç‰ˆ)",
    page_icon="ğŸ“°",
    layout="wide",
    initial_sidebar_state="collapsed",
    menu_items=None
)

# è‡ªå®šä¹‰CSSæ ·å¼
hide_streamlit_style = """
<style>
header {visibility: hidden;}
footer {visibility: hidden;}
.dataframe {font-size: 12px;}
[data-testid="stSidebar"] { display: none !important; }
.stApp > div:first-child { padding-top: 2rem; }
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# ===============================
# æ¨¡å‹é…ç½® (å¯ç”¨æµå¼ Streaming ä»¥è§£å†³è¶…æ—¶å’ŒStatus 0é—®é¢˜)
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True, 
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), 
            "temperature": kw.get("temperature", 0.0), 
            "stream": True,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        # Qwen Native API éœ€è¦ Accept: text/event-stream æ¥è§¦å‘ SSE
        "headers": lambda key: {
            "Authorization": f"Bearer {key}", 
            "Content-Type": "application/json",
            "X-DashScope-SSE": "enable",
            "Accept": "text/event-stream"
        },
        "payload": lambda model, messages, **kw: {
            "model": model, 
            "input": {"messages": messages}, 
            "parameters": {
                "max_tokens": kw.get("max_tokens", 4096), 
                "temperature": kw.get("temperature", 0.0),
                "result_format": "message",
                "incremental_output": True 
            },
        },
    },
}

MODEL_OPTIONS = {
    "DeepSeek Chat": {"provider": "deepseek", "model": "deepseek-chat", "api_key": os.getenv("DEEPSEEK_API_KEY"), "env_var": "DEEPSEEK_API_KEY"},
    "OpenAI GPT-4o-mini (æ¨è)": {"provider": "openai", "model": "gpt-4o-mini", "api_key": os.getenv("OPENAI_API_KEY"), "env_var": "OPENAI_API_KEY"},
    "Moonshot (Kimi)": {"provider": "moonshot", "model": "moonshot-v1-32k", "api_key": os.getenv("MOONSHOT_API_KEY"), "env_var": "MOONSHOT_API_KEY"},
    "Qwen Turbo (é€Ÿåº¦å¿«)": {"provider": "qwen", "model": "qwen-turbo", "api_key": os.getenv("QWEN_API_KEY"), "env_var": "QWEN_API_KEY"},
    "Qwen Max": {"provider": "qwen", "model": "qwen-max", "api_key": os.getenv("QWEN_API_KEY"), "env_var": "QWEN_API_KEY"},
}

AVAILABLE_MODEL_OPTIONS = {name: info for name, info in MODEL_OPTIONS.items() if info["api_key"]}
if not AVAILABLE_MODEL_OPTIONS: AVAILABLE_MODEL_OPTIONS = MODEL_OPTIONS

# ===============================
# è§„åˆ™å®šä¹‰
# ===============================
RULE_SETS = {
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸èƒ½å¸¦å®¾è¯­ï¼Œä¸èƒ½å—çŠ¶è¯­å’Œè¡¥è¯­ï¼Œä¸èƒ½åé™„æ—¶ä½“åŠ©è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼Œæˆ–è¿›å…¥'...äº†æ²¡æœ‰'æ ¼å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œæˆ–é€šè¿‡'å’Œ/ä¸º/å¯¹/å‘/æ‹¿/äº'ç­‰ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V, Väº†V, Vä¸V, Väº†æ²¡æœ‰'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®æˆ–è·Ÿåœ¨'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®ï¼Œä¸èƒ½è·Ÿåœ¨'å¤šä¹ˆ'ä¹‹åè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
    ],
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®šï¼Œè‚¯å®šå½¢å¼å¯ä»¥æ˜¯\"â€¦â€¦äº†\"å’Œ\"æœ‰â€¦â€¦\"", "match_score": 10, "mismatch_score": -10},
        {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"ï¼Œæˆ–è€…å¯ä»¥è¿›å…¥\"â€¦â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­ï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­ï¼Œä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°ï¼Œæˆ–è€…å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åæé—®ï¼Œè·Ÿåœ¨\"è¿™ä¹ˆ\"ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "match_score": 10, "mismatch_score": -10},
        {"name": "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
    ]
}

# ===============================
# å·¥å…·å‡½æ•°
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    if not isinstance(resp_json, dict): return ""
    try:
        # Qwen / OpenAI å…¼å®¹å¤„ç†
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
        if "output" in resp_json and "text" in resp_json["output"]:
            return resp_json["output"]["text"]
        return json.dumps(resp_json, ensure_ascii=False)
    except Exception:
        return json.dumps(resp_json, ensure_ascii=False)

def extract_json_from_text(text: str) -> Tuple[Dict[str, Any], str]:
    match = re.search(r"(\{.*\})", text.strip(), re.DOTALL)
    if not match: return None, text
    json_text = match.group(1).strip()
    try:
        parsed_json = json.loads(json_text)
        return parsed_json, json_text
    except json.JSONDecodeError:
        return None, json_text

def normalize_key(k: str, pos_rules: list) -> str:
    if not isinstance(k, str): return None
    k_norm = re.sub(r'[\s_]+', '', k).upper()
    for r in pos_rules:
        r_norm = re.sub(r'[\s_]+', '', r["name"]).upper()
        if r_norm == k_norm: return r["name"]
    return None

def map_to_allowed_score(rule: dict, raw_val) -> int:
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    if isinstance(raw_val, bool): return match_score if raw_val is True else mismatch_score
    if isinstance(raw_val, str):
        s = raw_val.strip().lower()
        if s in ("yes", "y", "true", "æ˜¯", "âˆš", "ç¬¦åˆ"): return match_score
        if s in ("no", "n", "false", "å¦", "Ã—", "ä¸ç¬¦åˆ"): return mismatch_score
    return mismatch_score

def calculate_membership(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    membership = {}
    for pos, scores in scores_all.items():
        total_score = sum(scores.values())
        normalized = total_score / 100
        membership[pos] = max(-1.0, min(1.0, normalized))
    return membership

def get_top_10_positions(membership: Dict[str, float]) -> List[Tuple[str, float]]:
    return sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]

# ===============================
# API è°ƒç”¨å‡½æ•° (æµå¼å¤„ç†)
# ===============================
def call_llm_api_cached(_provider, _model, _api_key, messages, max_tokens=4096, temperature=0.0):
    if not _api_key: return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"
    if _provider not in MODEL_CONFIGS: return False, {"error": f"æœªçŸ¥æä¾›å•† {_provider}"}, f"æœªçŸ¥æä¾›å•† {_provider}"

    cfg = MODEL_CONFIGS[_provider]
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](_api_key)
    payload = cfg["payload"](_model, messages, max_tokens=max_tokens, temperature=temperature)
    
    full_content = ""
    # ä»…åœ¨å•æ¬¡åˆ†ææ¨¡å¼ä¸‹æ˜¾ç¤ºæµå¼è¿‡ç¨‹ï¼Œé˜²æ­¢æ‰¹é‡å¤„ç†æ—¶UIæ··ä¹±ï¼ˆå¯é€‰ï¼‰
    # streaming_placeholder = st.empty() 

    try:
        with requests.post(url, headers=headers, json=payload, stream=True, timeout=60) as response:
            response.raise_for_status()
            for line in response.iter_lines():
                if not line: continue
                line_text = line.decode('utf-8').strip()
                if line_text.startswith("data:"): json_str = line_text[5:].strip()
                else: json_str = line_text
                
                if json_str == "[DONE]": break
                try:
                    chunk = json.loads(json_str)
                    delta_text = ""
                    if "choices" in chunk and len(chunk["choices"]) > 0:
                        delta = chunk["choices"][0].get("delta", {})
                        delta_text = delta.get("content", "")
                    elif "output" in chunk: # Qwen
                        output = chunk["output"]
                        if "choices" in output and len(output["choices"]) > 0:
                             msg = output["choices"][0].get("message", {})
                             delta_text = msg.get("content", "")
                        elif "text" in output:
                             delta_text = output["text"]
                    
                    if delta_text:
                        full_content += delta_text
                        # streaming_placeholder.markdown(full_content + "â–Œ") 
                except json.JSONDecodeError: continue
        
        # streaming_placeholder.empty()
        mock_response = {"choices": [{"message": {"content": full_content}}], "output": {"text": full_content}}
        if not full_content: return False, {"error": "æ— å†…å®¹"}, "æ— å†…å®¹"
        return True, mock_response, ""

    except Exception as e:
        return False, {"error": str(e)}, str(e)

# ===============================
# æ ¸å¿ƒåˆ†æé€»è¾‘ (Prompt å·²ä¼˜åŒ–æé€Ÿ)
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str, str]:
    if not word: return {}, "", "æœªçŸ¥", ""

    # ç®€åŒ–çš„ Promptï¼Œä¸å†è¦æ±‚é€ å¥ï¼Œå¤§å¹…æé€Ÿ
    full_rules_by_pos = {
        pos: "\n".join([f"- {r['name']}: {r['desc']}" for r in rules])
        for pos, rules in RULE_SETS.items()
    }

    system_msg = f"""ä½ æ˜¯ä¸€åæ±‰è¯­è¯­è¨€å­¦ä¸“å®¶ã€‚åˆ†æè¯è¯­ã€Œ{word}ã€ã€‚
ä»»åŠ¡ï¼šåˆ¤æ–­è¯¥è¯æ˜¯å¦ç¬¦åˆåè¯ã€åŠ¨è¯ã€ååŠ¨è¯çš„å„é¡¹è§„åˆ™ã€‚
è¦æ±‚ï¼š
1. ç›´æ¥è¾“å‡º JSON æ ¼å¼ç»“æœã€‚
2. scores å­—æ®µä¸­ï¼Œå¿…é¡»å¯¹æ¯ä¸€æ¡è§„åˆ™è¿”å› true æˆ– falseã€‚
3. explanation å­—æ®µè¯·ç”¨ä¸€å¥è¯ç®€è¦æ¦‚æ‹¬ç†ç”±ï¼Œä¸éœ€è¦è¯¦ç»†é€ å¥ã€‚
4. predicted_pos è¯·åœ¨'åè¯','åŠ¨è¯','ååŠ¨è¯'ä¸­é€‰ä¸€ä¸ªã€‚

è§„åˆ™å‚è€ƒï¼š
ã€åè¯ã€‘
{full_rules_by_pos["åè¯"]}
ã€åŠ¨è¯ã€‘
{full_rules_by_pos["åŠ¨è¯"]}
ã€ååŠ¨è¯ã€‘
{full_rules_by_pos["ååŠ¨è¯"]}
"""
    user_prompt = f"è¯·åˆ†æã€Œ{word}ã€å¹¶è¿”å› JSONã€‚"

    ok, resp_json, err_msg = call_llm_api_cached(provider, model, api_key, [{"role": "system", "content": system_msg}, {"role": "user", "content": user_prompt}])

    if not ok: return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", f"Fail: {err_msg}"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, _ = extract_json_from_text(raw_text)

    if parsed_json and isinstance(parsed_json, dict):
        explanation = parsed_json.get("explanation", "æ— ")
        predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
        raw_scores = parsed_json.get("scores", {})
    else:
        return {}, raw_text, "æœªçŸ¥", "JSONè§£æå¤±è´¥"

    scores_out = {pos: {} for pos in RULE_SETS.keys()}
    for pos, rules in RULE_SETS.items():
        raw_pos_scores = raw_scores.get(pos, {})
        if isinstance(raw_pos_scores, dict):
            for k, v in raw_pos_scores.items():
                normalized_key = normalize_key(k, rules)
                if normalized_key:
                    rule_def = next(r for r in rules if r["name"] == normalized_key)
                    scores_out[pos][normalized_key] = map_to_allowed_score(rule_def, v)
        # è¡¥å…¨ç¼ºå¤±è§„åˆ™
        for rule in rules:
            if rule["name"] not in scores_out[pos]: scores_out[pos][rule["name"]] = 0

    return scores_out, raw_text, predicted_pos, explanation

# ===============================
# Excel å¤„ç†ä¸æ ‡é»„é€»è¾‘
# ===============================
def process_and_style_excel(df, selected_model_info, target_col_name):
    output = io.BytesIO()
    processed_rows = []
    
    # è¿›åº¦æ˜¾ç¤º
    progress_bar = st.progress(0)
    status_text = st.empty()
    total = len(df)

    for index, row in df.iterrows():
        word = str(row[target_col_name]).strip()
        status_text.text(f"æ­£åœ¨å¤„ç† ({index + 1}/{total}): {word}")
        
        # 1. è°ƒç”¨æ¨¡å‹
        scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
            word=word,
            provider=selected_model_info["provider"],
            model=selected_model_info["model"],
            api_key=selected_model_info["api_key"]
        )
        
        # 2. è®¡ç®—éš¶å±åº¦
        membership = calculate_membership(scores_all) if scores_all else {}
        score_v = membership.get("åŠ¨è¯", 0.0)
        score_n = membership.get("åè¯", 0.0)
        score_nv = membership.get("ååŠ¨è¯", 0.0)
        
        # 3. è®¡ç®—å·®å€¼ (åŠ¨è¯ - åè¯ çš„ç»å¯¹å€¼)
        diff_val = round(abs(score_v - score_n), 4)
        
        # 4. æ„é€ æ•°æ®è¡Œ (é¡ºåºï¼šè¯è¯­, åŠ¨è¯, åè¯, ååŠ¨è¯, å·®å€¼/è·ç¦», åŸå§‹å“åº”)
        new_row = {
            "è¯è¯­": word,
            "åŠ¨è¯": score_v,
            "åè¯": score_n,
            "ååŠ¨è¯": score_nv,
            "å·®å€¼/è·ç¦»": diff_val,
            "åŸå§‹å“åº”": raw_text,
            "_predicted_pos": predicted_pos # éšè—è¾…åŠ©åˆ—
        }
        processed_rows.append(new_row)
        progress_bar.progress((index + 1) / total)

    result_df = pd.DataFrame(processed_rows)
    
    # ä½¿ç”¨ openpyxl å¯¼å‡ºå¹¶æ ‡é»„
    with pd.ExcelWriter(output, engine='openpyxl') as writer:
        cols = ["è¯è¯­", "åŠ¨è¯", "åè¯", "ååŠ¨è¯", "å·®å€¼/è·ç¦»", "åŸå§‹å“åº”"]
        result_df[cols].to_excel(writer, index=False, sheet_name='åˆ†æç»“æœ')
        
        worksheet = writer.sheets['åˆ†æç»“æœ']
        yellow_fill = PatternFill(start_color="FFFF00", end_color="FFFF00", fill_type="solid")
        
        for i, data_row in enumerate(processed_rows):
            row_num = i + 2 # Header is row 1
            pred = data_row["_predicted_pos"]
            
            # A=1(è¯), B=2(åŠ¨), C=3(å), D=4(ååŠ¨)
            target_idx = None
            if pred == "åŠ¨è¯": target_idx = 2
            elif pred == "åè¯": target_idx = 3
            elif pred == "ååŠ¨è¯": target_idx = 4
            
            if target_idx:
                worksheet.cell(row=row_num, column=target_idx).fill = yellow_fill

    status_text.success("âœ… å¤„ç†å®Œæˆï¼å·²è‡ªåŠ¨æ ‡é»„è·èƒœè¯ç±»ã€‚")
    return output.getvalue()

# ===============================
# UI æ¨¡å—
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    if not scores_norm: return
    categories = list(scores_norm.keys())
    values = list(scores_norm.values())
    categories += [categories[0]]
    values += [values[0]]
    fig = go.Figure(data=[go.Scatterpolar(r=values, theta=categories, fill="toself", name="éš¶å±åº¦")])
    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[-1, 1])), showlegend=False, title=dict(text=title, x=0.5))
    st.plotly_chart(fig, use_container_width=True)

def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹ ")
    
    # é¡¶éƒ¨è®¾ç½®æ 
    with st.container():
        col1, col2 = st.columns([3, 1])
        with col1:
            if not AVAILABLE_MODEL_OPTIONS:
                st.error("âŒ æ‰¾ä¸åˆ° API Keyï¼Œè¯·è®¾ç½®ç¯å¢ƒå˜é‡ (å¦‚ QWEN_API_KEY)ï¼")
                selected_model_info = {"api_key": None}
            else:
                s_name = st.selectbox("é€‰æ‹©æ¨¡å‹", list(AVAILABLE_MODEL_OPTIONS.keys()))
                selected_model_info = AVAILABLE_MODEL_OPTIONS[s_name]
        with col2:
            st.write("") # Spacer
            if st.button("æµ‹è¯•è¿æ¥"):
                ok, _, msg = call_llm_api_cached(selected_model_info["provider"], selected_model_info["model"], selected_model_info["api_key"], [{"role":"user","content":"hi"}], max_tokens=5)
                if ok: st.success("è¿æ¥æˆåŠŸ")
                else: st.error(f"è¿æ¥å¤±è´¥: {msg}")

    st.markdown("---")
    
    # åˆ†é¡µç­¾ï¼šå•è¯æµ‹è¯• vs æ‰¹é‡å¤„ç†
    tab1, tab2 = st.tabs(["ğŸ” å•ä¸ªè¯è¯­è¯¦ç»†åˆ†æ", "ğŸ“‚ Excel æ‰¹é‡å¤„ç†"])
    
    # --- Tab 1: å•è¯åˆ†æ ---
    with tab1:
        word = st.text_input("è¾“å…¥è¯è¯­", placeholder="ä¾‹å¦‚ï¼šå‘å±•")
        if st.button("å¼€å§‹åˆ†æ", type="primary", disabled=not (word and selected_model_info["api_key"])):
            with st.spinner("åˆ†æä¸­..."):
                scores, raw, pred, expl = ask_model_for_pos_and_scores(word, selected_model_info["provider"], selected_model_info["model"], selected_model_info["api_key"])
                
                if scores:
                    mem = calculate_membership(scores)
                    st.success(f"æœ€å¯èƒ½è¯ç±»ï¼š**{pred}** (éš¶å±åº¦: {mem.get(pred,0):.2f})")
                    
                    c1, c2 = st.columns(2)
                    with c1:
                        top10_df = pd.DataFrame(get_top_10_positions(mem), columns=["è¯ç±»", "éš¶å±åº¦"])
                        st.table(top10_df)
                        plot_radar_chart_streamlit(mem, f"{word} éš¶å±åº¦é›·è¾¾å›¾")
                    with c2:
                        st.subheader("æ¨ç†ç®€è¿°")
                        st.info(expl)
                        with st.expander("æŸ¥çœ‹åŸå§‹å“åº”"): st.code(raw)

    # --- Tab 2: æ‰¹é‡å¤„ç† ---
    with tab2:
        st.info("ä¸Šä¼  Excel æ–‡ä»¶ï¼Œå¿…é¡»åŒ…å«è¡¨å¤´ä¸º **'è¯è¯­'** çš„åˆ—ã€‚ç³»ç»Ÿå°†ç”ŸæˆåŒ…å« **[åŠ¨è¯|åè¯|ååŠ¨è¯|å·®å€¼]** çš„ç»“æœè¡¨ï¼Œå¹¶è‡ªåŠ¨æ ‡é»„ã€‚")
        uploaded_file = st.file_uploader("ä¸Šä¼  Excel", type=["xlsx", "xls"])
        
        if uploaded_file and selected_model_info["api_key"]:
            try:
                df = pd.read_excel(uploaded_file)
                # å¯»æ‰¾ç›®æ ‡åˆ—
                target_col = next((c for c in df.columns if "è¯" in str(c) or "word" in str(c).lower()), None)
                
                if target_col:
                    st.write(f"âœ… è¯†åˆ«åˆ°ç›®æ ‡åˆ—ï¼š`{target_col}`ï¼Œå…± {len(df)} ä¸ªè¯ã€‚")
                    if st.button("ğŸš€ å¼€å§‹æ‰¹é‡åˆ†æ"):
                        excel_data = process_and_style_excel(df, selected_model_info, target_col)
                        st.download_button("ğŸ“¥ ä¸‹è½½ç»“æœ (å·²æ ‡é»„)", excel_data, file_name="åˆ†æç»“æœ.xlsx", mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")
                else:
                    st.error("âŒ æœªæ‰¾åˆ°åŒ…å« 'è¯' çš„åˆ—åï¼Œè¯·ä¿®æ”¹ Excel è¡¨å¤´ã€‚")
            except Exception as e:
                st.error(f"æ–‡ä»¶è¯»å–é”™è¯¯: {e}")

if __name__ == "__main__":
    main()

