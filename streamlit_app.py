import streamlit as st
import requests
import json
import re
import os
import pandas as pd
import plotly.graph_objects as go
from typing import Tuple, Dict, Any, List

# ===============================
# é¡µé¢é…ç½®
# ===============================
st.set_page_config(
    page_title="æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»",
    page_icon="ğŸ“°",
    layout="wide",  # ä½¿ç”¨å®½å¸ƒå±€
    initial_sidebar_state="collapsed",  # é»˜è®¤æŠ˜å ä¾§è¾¹æ 
    menu_items=None
)

# è‡ªå®šä¹‰CSSæ ·å¼
hide_streamlit_style = """
<style>
/* éšè—é¡¶éƒ¨èœå•æ å’Œé¡µè„š */
header {visibility: hidden;}
footer {visibility: hidden;}

/* è°ƒæ•´è¡¨æ ¼æ ·å¼ */
.dataframe {font-size: 12px;}

/* éšè—é»˜è®¤çš„ä¾§è¾¹æ  */
[data-testid="stSidebar"] {
    display: none !important;
}

/* ä¸ºé¡¶éƒ¨æ§åˆ¶åŒºæ·»åŠ è¾¹æ¡†å’ŒèƒŒæ™¯è‰²ï¼Œä½¿å…¶çœ‹èµ·æ¥åƒä¸€ä¸ªå›ºå®šçš„é¢æ¿ */
.stApp > div:first-child {
    padding-top: 2rem;
}
</style>
"""
st.markdown(hide_streamlit_style, unsafe_allow_html=True)

# ===============================
# æ¨¡å‹é…ç½® (ä»…ä»ç¯å¢ƒå˜é‡è·å–API Key)
# ===============================
MODEL_CONFIGS = {
    "deepseek": {
        "base_url": "https://api.deepseek.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "openai": {
        "base_url": "https://api.openai.com/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "moonshot": {
        "base_url": "https://api.moonshot.cn/v1",
        "endpoint": "/chat/completions",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "messages": messages, "max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0), "stream": False,
        },
    },
    "qwen": {
        "base_url": "https://dashscope.aliyuncs.com/api/v1",
        "endpoint": "/services/aigc/text-generation/generation",
        "headers": lambda key: {"Authorization": f"Bearer {key}", "Content-Type": "application/json"},
        "payload": lambda model, messages, **kw: {
            "model": model, "input": {"messages": messages}, "parameters": {"max_tokens": kw.get("max_tokens", 4096), "temperature": kw.get("temperature", 0.0),},
        },
    },
}

# æ¨¡å‹é€‰é¡¹ï¼ˆä»…ä»ç¯å¢ƒå˜é‡è·å–API Keyï¼Œä¸æä¾›æ‰‹åŠ¨è¾“å…¥ï¼‰
MODEL_OPTIONS = {
    "DeepSeek Chat": {
        "provider": "deepseek", 
        "model": "deepseek-chat", 
        "api_key": os.getenv("DEEPSEEK_API_KEY", "sk-759d66c83f374a2aaac0db5814ccb016"),
        "env_var": "DEEPSEEK_API_KEY"
    },
    "OpenAI GPT-4oï¼ˆå°šä¸æ”¯æŒï¼‰": {
        "provider": "openai", 
        "model": "gpt-4o-mini", 
        "api_key": os.getenv("OPENAI_API_KEY", "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"),
        "env_var": "OPENAI_API_KEY"
    },
    "Moonshotï¼ˆKimiï¼‰": {
        "provider": "moonshot", 
        "model": "moonshot-v1-32k", 
        "api_key": os.getenv("MOONSHOT_API_KEY", "sk-l5FvRWegjM5DEk4AU71YPQ1QgvFPTHZIJOmq6qdssPY4sNtE"),
        "env_var": "MOONSHOT_API_KEY"
    },
    "Qwenï¼ˆé€šä¹‰åƒé—®ï¼‰": {
        "provider": "qwen", 
        "model": "qwen-max", 
        "api_key": os.getenv("QWEN_API_KEY", "sk-b3f7a1153e6f4a44804a296038aa86c5"),
        "env_var": "QWEN_API_KEY"
    },
}

# ===============================
# è¯ç±»è§„åˆ™ä¸å¾—åˆ†ï¼ˆæ ¸å¿ƒï¼šæ˜ç¡®match/mismatchåˆ†æ•°ï¼‰
# ===============================
RULE_SETS = {
    # 1.1 åè¯
    "åè¯": [
        {"name": "N1_å¯å—æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "desc": "ä¸èƒ½å—å‰¯è¯ä¿®é¥°", "match_score": 20, "mismatch_score": -20},
        {"name": "N3_å¯ä½œä¸»å®¾è¯­", "desc": "å¯ä»¥åšå…¸å‹çš„ä¸»è¯­æˆ–å®¾è¯­", "match_score": 20, "mismatch_score": 0},
        {"name": "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­", "desc": "å¯ä»¥åšä¸­å¿ƒè¯­å—å…¶ä»–åè¯ä¿®é¥°ï¼Œæˆ–è€…ä½œå®šè¯­ç›´æ¥ä¿®é¥°å…¶ä»–åè¯", "match_score": 10, "mismatch_score": 0},
        {"name": "N5_å¯åé™„çš„å­—ç»“æ„", "desc": "å¯ä»¥åé™„åŠ©è¯â€œçš„â€æ„æˆâ€œçš„â€å­—ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "match_score": 10, "mismatch_score": 0},
        {"name": "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ", "desc": "ä¸èƒ½åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸èƒ½å¸¦å®¾è¯­ï¼Œä¸èƒ½å—çŠ¶è¯­å’Œè¡¥è¯­ï¼Œä¸èƒ½åé™„æ—¶ä½“åŠ©è¯ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ä½œè¡¥è¯­ï¼Œå¹¶ä¸”ä¸€èˆ¬ä¸èƒ½åšçŠ¶è¯­ç›´æ¥ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
    ],
    # 1.5 åŠ¨è¯
    "åŠ¨è¯": [
        {"name": "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°", "desc": "å¯ä»¥å—å¦å®šå‰¯è¯'ä¸'æˆ–'æ²¡æœ‰'ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'", "desc": "å¯ä»¥åé™„æˆ–ä¸­é—´æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'ï¼Œæˆ–è¿›å…¥'...äº†æ²¡æœ‰'æ ¼å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œæˆ–é€šè¿‡'å’Œ/ä¸º/å¯¹/å‘/æ‹¿/äº'ç­‰ä»‹è¯å¼•å¯¼è®ºå…ƒ", "match_score": 20, "mismatch_score": 0},
        {"name": "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»", "desc": "ä¸èƒ½å—ç¨‹åº¦å‰¯è¯'å¾ˆ'ä¿®é¥°ï¼Œæˆ–èƒ½åŒæ—¶å—'å¾ˆ'ä¿®é¥°å¹¶å¸¦å®¾è¯­ï¼ˆæŒ‰æ¡ç›®ç»™äºˆå¾—åˆ†ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰'VV, Vä¸€V, Väº†V, Vä¸V, Väº†æ²¡æœ‰'ç­‰å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ", "desc": "å¯ä»¥åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼ˆä¸€èˆ¬å¯å—çŠ¶è¯­æˆ–è¡¥è¯­ä¿®é¥°ï¼‰", "match_score": 10, "mismatch_score": -10},
        {"name": "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "desc": "ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": 0},
        {"name": "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”", "desc": "å¯ä»¥è·Ÿåœ¨'æ€ä¹ˆ/æ€æ ·'ä¹‹åæé—®æˆ–è·Ÿåœ¨'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'ä¹‹åå›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹", "desc": "ä¸èƒ½è·Ÿåœ¨'å¤š'ä¹‹åå¯¹æ€§è´¨æé—®ï¼Œä¸èƒ½è·Ÿåœ¨'å¤šä¹ˆ'ä¹‹åè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
    ],
    # 4.6 ååŠ¨è¯
    "ååŠ¨è¯": [
        {"name": "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1", "desc": "å¯ä»¥ç”¨\"ä¸\"å’Œ\"æ²¡æœ‰\"æ¥å¦å®šï¼Œå¹¶ä¸”\"æ²¡æœ‰â€¦â€¦\"çš„è‚¯å®šå½¢å¼å¯ä»¥æ˜¯\"â€¦â€¦äº†\"å’Œ\"æœ‰â€¦â€¦\"(å‰ä¸€ç§æƒ…å†µä¸­çš„\"æ²¡æœ‰\"æ˜¯å‰¯è¯ï¼Œåä¸€ç§æƒ…å†µä¸­çš„\"æ²¡æœ‰\"æ˜¯åŠ¨è¯)", "match_score": 10, "mismatch_score": -10},
        {"name": "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "desc": "å¯ä»¥åé™„æ—¶ä½“åŠ©è¯\"ç€ã€äº†ã€è¿‡\"ï¼Œæˆ–è€…å¯ä»¥è¿›å…¥\"â€¦â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼", "match_score": 10, "mismatch_score": -10},
        {"name": "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°", "desc": "å¯ä»¥å¸¦çœŸå®¾è¯­ï¼Œå¹¶ä¸”ä¸èƒ½å—ç¨‹åº¦å‰¯è¯\"å¾ˆ\"ç­‰ä¿®é¥°", "match_score": 10, "mismatch_score": -10},
        {"name": "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼", "desc": "å¯ä»¥æœ‰\"VVã€Vä¸€Vã€Väº†Vã€Vä¸V\"ç­‰é‡å å’Œæ­£åé‡å å½¢å¼", "match_score": 10, "mismatch_score": 0},
        {"name": "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­", "desc": "æ—¢å¯ä»¥ä½œè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒï¼Œåˆå¯ä»¥ä½œä¸»è¯­æˆ–å®¾è¯­ï¼Œå¹¶ä¸”ï¼Œå¯ä»¥ä½œå½¢å¼åŠ¨è¯\"ä½œã€è¿›è¡Œã€åŠ ä»¥ã€ç»™äºˆã€å—åˆ°\"ç­‰çš„å®¾è¯­", "match_score": 10, "mismatch_score": -10},
        {"name": "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­", "desc": "ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†", "match_score": 10, "mismatch_score": -10},
        {"name": "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°", "desc": "å¯ä»¥ä¿®é¥°åè¯æˆ–è€…å—åè¯ä¿®é¥°ï¼Œæˆ–è€…å¯ä»¥å—æ•°é‡è¯ä¿®é¥°", "match_score": 10, "mismatch_score": 0},
        {"name": "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å", "desc": "å¯ä»¥è·Ÿåœ¨\"æ€ä¹ˆã€æ€æ ·\"ä¹‹åï¼Œå¯¹åŠ¨ä½œçš„æ–¹å¼è¿›è¡Œæé—®ï¼Œå¹¶ä¸”å¯ä»¥è·Ÿåœ¨\"è¿™ä¹ˆã€è¿™æ ·ã€é‚£ä¹ˆã€é‚£æ ·\"ä¹‹åï¼Œç”¨ä»¥ä½œå‡ºç›¸åº”çš„å›ç­”", "match_score": 10, "mismatch_score": 0},
        {"name": "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å", "desc": "ä¸èƒ½è·Ÿåœ¨\"å¤š\"ä¹‹åï¼Œå¯¹æ€§è´¨çš„ç¨‹åº¦è¿›è¡Œæé—®ï¼Œä¹Ÿä¸èƒ½è·Ÿåœ¨\"å¤šä¹ˆ\"ä¹‹åï¼Œè¡¨ç¤ºæ„Ÿå¹", "match_score": 10, "mismatch_score": -10},
        {"name": "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„", "desc": "å¯ä»¥åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„(ç„¶åä½œâ€œåœ¨ã€åˆ°ã€ä»â€ç­‰ä»‹è¯çš„å®¾è¯­ï¼Œè¿™ç§ä»‹è¯ç»“æ„åˆå¯ä»¥ä½œçŠ¶è¯­æˆ–è¡¥è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†)", "match_score": 10, "mismatch_score": 0},
    ]
}

# é¢„è®¡ç®—æ¯ä¸ªè¯ç±»çš„æœ€å¤§å¯èƒ½å¾—åˆ†
MAX_SCORES = {pos: sum(abs(r["match_score"]) for r in rules) for pos, rules in RULE_SETS.items()}

# ===============================
# å·¥å…·å‡½æ•°ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šç›´æ¥è¯»å–åˆ†æ•°ï¼ŒæŠ›å¼ƒå¸ƒå°”å€¼ï¼‰
# ===============================
def extract_text_from_response(resp_json: Dict[str, Any]) -> str:
    if not isinstance(resp_json, dict): return ""
    try:
        # --- å¤„ç†é€šä¹‰åƒé—® (Qwen) çš„å“åº”æ ¼å¼ ---
        if "output" in resp_json and "text" in resp_json["output"]:
            return resp_json["output"]["text"]
            
        # --- å¤„ç† OpenAI ç³»åˆ—çš„å“åº”æ ¼å¼ ---
        if "choices" in resp_json and len(resp_json["choices"]) > 0:
            choice = resp_json["choices"][0]
            if "message" in choice and "content" in choice["message"]:
                return choice["message"]["content"]
            for k in ("content", "text"):
                if k in choice: return choice[k]
    except Exception: 
        pass
    # å¦‚æœä»¥ä¸Šéƒ½å¤±è´¥ï¼Œè¿”å›æ•´ä¸ªå“åº”çš„å­—ç¬¦ä¸²å½¢å¼ï¼Œç”¨äºè°ƒè¯•
    return json.dumps(resp_json, ensure_ascii=False)

def fix_common_json_errors(json_str: str) -> str:
    """è‡ªåŠ¨ä¿®å¤å¸¸è§çš„JSONæ ¼å¼é”™è¯¯ï¼ˆæ— éœ€ä¾èµ–å¤–éƒ¨åº“ï¼‰"""
    # 1. ç»™æ— å¼•å·çš„é”®åŠ åŒå¼•å·ï¼ˆæ¯”å¦‚ key: â†’ "key":ï¼‰
    json_str = re.sub(r'([{,]\s*)([\w_]+)(\s*:)', r'\1"\2"\3', json_str)
    # 2. æŠŠå•å¼•å·é”®æ”¹æˆåŒå¼•å·ï¼ˆæ¯”å¦‚ 'key': â†’ "key":ï¼‰
    json_str = re.sub(r"([{,]\s*)'([\w_]+)'(\s*:)", r'\1"\2"\3', json_str)
    # 3. è¡¥å…¨é”®å€¼å¯¹åçš„ç¼ºå¤±é€—å·ï¼ˆæ¯”å¦‚ "a":10 "b":-20 â†’ "a":10, "b":-20ï¼‰
    json_str = re.sub(r'("[\w_]+":\s*[^,}]+)\s+("[\w_]+":)', r'\1,\2', json_str)
    # 4. ç§»é™¤æœ«å°¾å¤šä½™çš„é€—å·ï¼ˆæ¯”å¦‚ {"a":10,} â†’ {"a":10}ï¼‰
    json_str = re.sub(r',\s*([}\]])', r'\1', json_str)
    # 5. æ›¿æ¢ä¸­æ–‡æ ‡ç‚¹ä¸ºè‹±æ–‡
    json_str = json_str.replace("ï¼š", ":").replace("ï¼Œ", ",").replace("â€œ", '"').replace("â€", '"')
    # 6. ç§»é™¤å¤šä½™çš„ç©ºæ ¼/æ¢è¡Œ
    json_str = re.sub(r'\s+', ' ', json_str).replace('{ ', '{').replace(' }', '}')
    return json_str

def extract_json_from_text(text: str) -> Tuple[dict, str]:
    """
    å¢å¼ºç‰ˆJSONæå–å‡½æ•°ï¼š
    1. ä¼˜å…ˆç”¨ä¸“å±åˆ†éš”ç¬¦æå–
    2. è‡ªåŠ¨ä¿®å¤å¸¸è§æ ¼å¼é”™è¯¯
    3. å¤šå±‚çº§å®¹é”™
    """
    if not text:
        return None, ""

    # ç¬¬ä¸€æ­¥ï¼šç”¨ä¸“å±åˆ†éš”ç¬¦ç²¾å‡†æå–JSONå—ï¼ˆæœ€ä¼˜å…ˆï¼‰
    start_marker = "====JSON_BEGIN===="
    end_marker = "====JSON_END===="
    start_idx = text.find(start_marker)
    end_idx = text.find(end_marker)
    if start_idx != -1 and end_idx > start_idx:
        # æå–åˆ†éš”ç¬¦ä¹‹é—´çš„å†…å®¹
        json_str = text[start_idx + len(start_marker):end_idx].strip()
        # ä¿®å¤å¸¸è§é”™è¯¯
        json_str = fix_common_json_errors(json_str)
        # å°è¯•è§£æ
        try:
            parsed = json.loads(json_str)
            st.success("âœ… é€šè¿‡ä¸“å±åˆ†éš”ç¬¦æˆåŠŸè§£æJSON")
            return parsed, json_str
        except Exception as e:
            st.warning(f"åˆ†éš”ç¬¦æå–çš„JSONè§£æå¤±è´¥ï¼Œé”™è¯¯ï¼š{str(e)[:100]}")
            st.code(f"ä¿®å¤åçš„JSONï¼š\n{json_str}", language="json")

    # ç¬¬äºŒæ­¥ï¼šfallbackåˆ°ä»£ç å—æå–
    json_block_pattern = re.compile(r'```(?:json)?\s*\n?([\s\S]*?)\n?```', re.IGNORECASE)
    json_block_matches = json_block_pattern.findall(text)
    for json_str in json_block_matches:
        json_str = fix_common_json_errors(json_str.strip())
        try:
            parsed = json.loads(json_str)
            st.success("âœ… é€šè¿‡ä»£ç å—æˆåŠŸè§£æJSON")
            return parsed, json_str
        except Exception as e:
            continue

    # ç¬¬ä¸‰æ­¥ï¼šæœ€åå°è¯•æå–æ‰€æœ‰å¤§æ‹¬å·å†…å®¹
    all_json_matches = re.findall(r'\{[\s\S]*\}', text)
    for json_str in all_json_matches:
        json_str = fix_common_json_errors(json_str.strip())
        try:
            parsed = json.loads(json_str)
            st.success("âœ… é€šè¿‡å¤§æ‹¬å·åŒ¹é…æˆåŠŸè§£æJSON")
            return parsed, json_str
        except Exception as e:
            continue

    # æ‰€æœ‰æ–¹æ³•å¤±è´¥
    st.warning("âš ï¸ æ— æ³•æå–æœ‰æ•ˆJSONï¼Œå°†ä½¿ç”¨é»˜è®¤å¾—åˆ†")
    # æ˜¾ç¤ºåŸå§‹æ–‡æœ¬ä¾›è°ƒè¯•
    with st.expander("ğŸ“ åŸå§‹å“åº”æ–‡æœ¬ï¼ˆè°ƒè¯•ç”¨ï¼‰", expanded=False):
        st.code(text, language="text")
    return None, text

def normalize_key(k: str, pos_rules: list) -> str:
    if not isinstance(k, str): return None
    k_upper = re.sub(r'\s+', '', k).upper()
    for r in pos_rules:
        if re.sub(r'\s+', '', r["name"]).upper() == k_upper:
            return r["name"]
    return None

def validate_score(rule: dict, raw_val) -> int:
    """ç›´æ¥éªŒè¯åˆ†æ•°æ˜¯å¦åˆæ³•ï¼Œä¸è½¬æ¢å¸ƒå°”å€¼"""
    match_score, mismatch_score = rule["match_score"], rule["mismatch_score"]
    # å¦‚æœæ˜¯æ•°å­—ï¼Œç›´æ¥éªŒè¯æ˜¯å¦åœ¨å…è®¸çš„èŒƒå›´å†…
    if isinstance(raw_val, (int, float)):
        raw_val = int(raw_val)
        # åªå…è®¸åŒ¹é…åˆ†æˆ–ä¸åŒ¹é…åˆ†
        if raw_val == match_score or raw_val == mismatch_score:
            return raw_val
    # å¦‚æœæ˜¯å­—ç¬¦ä¸²ï¼Œå°è¯•è½¬æ•°å­—
    if isinstance(raw_val, str):
        try:
            num_val = int(raw_val.strip())
            if num_val == match_score or num_val == mismatch_score:
                return num_val
        except:
            pass
    # æ— æ•ˆå€¼è¿”å›ä¸åŒ¹é…åˆ†ï¼ˆå…œåº•ï¼‰
    return mismatch_score

def calculate_membership(scores_all: Dict[str, Dict[str, int]]) -> Dict[str, float]:
    membership = {}
    for pos, scores in scores_all.items():
        total_score = sum(scores.values())
        # æ€»å¾—åˆ†é™¤ä»¥100å¾—åˆ°éš¶å±åº¦ï¼Œé™åˆ¶åœ¨[-1, 1]åŒºé—´
        normalized = total_score / 100
        membership[pos] = max(-1.0, min(1.0, normalized))
    return membership

def get_top_10_positions(membership: Dict[str, float]) -> List[Tuple[str, float]]:
    return sorted(membership.items(), key=lambda x: x[1], reverse=True)[:10]

def prepare_detailed_scores_df(scores_all: Dict[str, Dict[str, int]]) -> pd.DataFrame:
    rows = []
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            rows.append({
                "è¯ç±»": pos,
                "è§„åˆ™ä»£ç ": rule["name"],
                "è§„åˆ™æè¿°": rule["desc"],
                "å¾—åˆ†": scores_all[pos].get(rule["name"], 0)
            })
    return pd.DataFrame(rows)

# ===============================
# å®‰å…¨çš„ LLM è°ƒç”¨å‡½æ•° (å¢åŠ è¶…æ—¶)
# ===============================
def call_llm_api_cached(_provider, _model, _api_key, messages, max_tokens=4096, temperature=0.0):
    if not _api_key: return False, {"error": "API Key ä¸ºç©º"}, "API Key æœªæä¾›"
    if _provider not in MODEL_CONFIGS: return False, {"error": f"æœªçŸ¥æä¾›å•† {_provider}"}, f"æœªçŸ¥æä¾›å•† {_provider}"

    cfg = MODEL_CONFIGS[_provider]
    url = f"{cfg['base_url'].rstrip('/')}{cfg['endpoint']}"
    headers = cfg["headers"](_api_key)
    payload = cfg["payload"](_model, messages, max_tokens=max_tokens, temperature=temperature)

    try:
        # å¢åŠ è¶…æ—¶è®¾ç½®åˆ°120ç§’
        response = requests.post(url, headers=headers, json=payload, timeout=120)
        response.raise_for_status()
        return True, response.json(), ""
    except requests.exceptions.Timeout:
        error_msg = "è¯·æ±‚è¶…æ—¶ã€‚æ¨¡å‹å¯èƒ½æ­£å¿™æˆ–ç½‘ç»œè¿æ¥è¾ƒæ…¢ã€‚å»ºè®®å°è¯•å…¶ä»–æ¨¡å‹æˆ–ç¨åå†è¯•ã€‚"
        return False, {"error": error_msg}, error_msg
    except requests.exceptions.RequestException as e:
        # å¯¹äº4xxå’Œ5xxé”™è¯¯ï¼Œæå–æ›´å¤šä¿¡æ¯
        error_msg = f"APIè¯·æ±‚å¤±è´¥: {str(e)}"
        if hasattr(e, 'response') and e.response is not None:
            try:
                error_details = e.response.json()
                if 'error' in error_details:
                    error_msg += f" è¯¦æƒ…: {error_details['error']['message']}"
            except:
                error_msg += f" å“åº”å†…å®¹: {e.response.text[:200]}..." # åªæ˜¾ç¤ºéƒ¨åˆ†å†…å®¹
        return False, {"error": error_msg}, error_msg
    except Exception as e:
        error_msg = f"å‘ç”ŸæœªçŸ¥é”™è¯¯: {str(e)}"
        return False, {"error": error_msg}, error_msg

# ===============================
# è¯ç±»åˆ¤å®šä¸»å‡½æ•°ï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šPromptå¼ºåˆ¶è¾“å‡ºåˆ†æ•°ï¼‰
# ===============================
def ask_model_for_pos_and_scores(word: str, provider: str, model: str, api_key: str) -> Tuple[Dict[str, Dict[str, int]], str, str, str]:
    if not word:
        return {}, "", "æœªçŸ¥", ""

    # ç”Ÿæˆå¸¦å…·ä½“åˆ†æ•°çš„è§„åˆ™è¯´æ˜ï¼ˆç»™æ¨¡å‹çœ‹ï¼‰
    full_rules_by_pos = {}
    for pos, rules in RULE_SETS.items():
        rule_text = []
        for r in rules:
            rule_text.append(f"- {r['name']}: {r['desc']}ï¼ˆç¬¦åˆå¡«{r['match_score']}åˆ†ï¼Œä¸ç¬¦åˆå¡«{r['mismatch_score']}åˆ†ï¼‰")
        full_rules_by_pos[pos] = "\n".join(rule_text)

    # ===== æ ¸å¿ƒä¿®æ”¹ï¼šPromptå¼ºåˆ¶è¾“å‡ºåˆ†æ•°ï¼ŒæŠ›å¼ƒå¸ƒå°”å€¼ =====
    system_msg = f"""ä½ æ˜¯ä¸­æ–‡è¯æ³•ä¸è¯­æ³•é¢†åŸŸçš„ä¸“å®¶ï¼Œéœ€ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚åˆ†æè¯è¯­ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦ï¼Œæ ¼å¼é”™è¯¯ä¼šå¯¼è‡´ä»»åŠ¡å®Œå…¨å¤±è´¥ï¼

ã€åˆ†æèŒƒå›´ã€‘
ä»…åˆ†æä»¥ä¸‹ä¸‰ç±»è¯ç±»ï¼šåè¯ã€åŠ¨è¯ã€ååŠ¨è¯ï¼Œæ¯æ¡è§„åˆ™å¿…é¡»è¾“å‡º**å…·ä½“çš„æ•°å­—å¾—åˆ†**ï¼ˆç¬¦åˆ=åŒ¹é…åˆ†ï¼Œä¸ç¬¦åˆ=ä¸åŒ¹é…åˆ†ï¼‰ã€‚

ã€è§„åˆ™ä¸å¾—åˆ†è¯´æ˜ã€‘
{chr(10).join([f"ã€{pos}ã€‘{full_rules_by_pos[pos]}" for pos in full_rules_by_pos.keys()])}

ã€è¾“å‡ºæ ¼å¼ï¼ˆå¿…é¡»100%éµå®ˆï¼Œç¼ºä¸€ä¸å¯ï¼‰ã€‘
1. é¦–å…ˆè¾“å‡º**è¯¦ç»†æ¨ç†è¿‡ç¨‹**ï¼š
   - é€æ¡è§„åˆ™è¯´æ˜åˆ¤æ–­ç»“æœï¼ˆç¬¦åˆ/ä¸ç¬¦åˆï¼‰+ ç†ç”± + ä¾‹å¥ + å¯¹åº”åˆ†æ•°
   - æ ¼å¼ç¤ºä¾‹ï¼šã€Œåè¯-N1_å¯å—æ•°é‡è¯ä¿®é¥°ï¼šç¬¦åˆï¼Œå¾—10åˆ†ã€‚ç†ç”±ï¼šè‹¹æœå¯ä»¥è¯´â€œä¸€ä¸ªè‹¹æœâ€ï¼Œå—æ•°é‡è¯ä¿®é¥°ã€‚ä¾‹å¥ï¼šæˆ‘ä¹°äº†ä¸€ä¸ªè‹¹æœã€‚ã€
   - å¿…é¡»è¦†ç›–åè¯ï¼ˆ8æ¡ï¼‰ã€åŠ¨è¯ï¼ˆ9æ¡ï¼‰ã€ååŠ¨è¯ï¼ˆ10æ¡ï¼‰çš„æ‰€æœ‰è§„åˆ™ï¼Œä¸èƒ½é—æ¼ä»»ä½•ä¸€æ¡

2. æ¨ç†è¿‡ç¨‹ç»“æŸåï¼Œå•ç‹¬è¾“å‡º**ä¸“å±åˆ†éš”ç¬¦åŒ…è£¹çš„JSON**ï¼ˆåˆ†éš”ç¬¦å¿…é¡»å•ç‹¬æˆè¡Œï¼Œä¸èƒ½ä¿®æ”¹ï¼‰ï¼š
====JSON_BEGIN====
{{
  "explanation": "è¿™é‡Œå¡«å†™å®Œæ•´çš„æ¨ç†è¿‡ç¨‹æ–‡æœ¬ï¼ˆåŒ…å«æ‰€æœ‰è§„åˆ™çš„åˆ¤æ–­ç†ç”±ã€ä¾‹å¥å’Œåˆ†æ•°ï¼‰",
  "predicted_pos": "ä»åè¯/åŠ¨è¯/ååŠ¨è¯ä¸­é€‰æ‹©ä¸€ä¸ªä½œä¸ºæœ€ç»ˆåˆ¤å®šç»“æœ",
  "scores": {{
    "åè¯": {{
      "N1_å¯å—æ•°é‡è¯ä¿®é¥°": 10,
      "N2_ä¸èƒ½å—å‰¯è¯ä¿®é¥°": 20,
      "N3_å¯ä½œä¸»å®¾è¯­": 20,
      "N4_å¯ä½œä¸­å¿ƒè¯­æˆ–ä½œå®šè¯­": 10,
      "N5_å¯åé™„çš„å­—ç»“æ„": 10,
      "N6_å¯åé™„æ–¹ä½è¯æ„å¤„æ‰€": 10,
      "N7_ä¸èƒ½ä½œè°“è¯­æ ¸å¿ƒ": 10,
      "N8_ä¸èƒ½ä½œè¡¥è¯­/ä¸€èˆ¬ä¸ä½œçŠ¶è¯­": 10
    }},
    "åŠ¨è¯": {{
      "V1_å¯å—å¦å®š'ä¸/æ²¡æœ‰'ä¿®é¥°": 10,
      "V2_å¯åé™„/æ’å…¥æ—¶ä½“åŠ©è¯'ç€/äº†/è¿‡'": 10,
      "V3_å¯å¸¦çœŸå®¾è¯­æˆ–é€šè¿‡ä»‹è¯å¼•å¯¼è®ºå…ƒ": 20,
      "V4_ç¨‹åº¦å‰¯è¯ä¸å¸¦å®¾è¯­çš„å…³ç³»": 10,
      "V5_å¯æœ‰é‡å /æ­£åé‡å å½¢å¼": 10,
      "V6_å¯åšè°“è¯­æˆ–è°“è¯­æ ¸å¿ƒ": 10,
      "V7_ä¸èƒ½ä½œçŠ¶è¯­ä¿®é¥°åŠ¨è¯æ€§æˆåˆ†": 10,
      "V8_å¯ä½œ'æ€ä¹ˆ/æ€æ ·'æé—®æˆ–'è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ'å›ç­”": 10,
      "V9_ä¸èƒ½è·Ÿåœ¨'å¤š/å¤šä¹ˆ'ä¹‹åæé—®æˆ–è¡¨ç¤ºæ„Ÿå¹": 10
    }},
    "ååŠ¨è¯": {{
      "NV1_å¯è¢«\"ä¸/æ²¡æœ‰\"å¦å®šä¸”è‚¯å®šå½¢å¼-1": 10,
      "NV2_å¯é™„æ—¶ä½“åŠ©è¯æˆ–è¿›å…¥\"â€¦â€¦äº†æ²¡æœ‰\"æ ¼å¼": 10,
      "NV3_å¯å¸¦çœŸå®¾è¯­ä¸”ä¸å—\"å¾ˆ\"ä¿®é¥°": 10,
      "NV4_æœ‰é‡å å’Œæ­£åé‡å å½¢å¼": 10,
      "NV5_å¯ä½œå¤šç§å¥æ³•æˆåˆ†ä¸”å¯ä½œå½¢å¼åŠ¨è¯å®¾è¯­": 10,
      "NV6_ä¸èƒ½ç›´æ¥ä½œçŠ¶è¯­": 10,
      "NV7_å¯ä¿®é¥°åè¯æˆ–å—åè¯/æ•°é‡è¯ä¿®é¥°": 10,
      "NV8_å¯è·Ÿåœ¨\"æ€ä¹ˆ/æ€æ ·/è¿™ä¹ˆ/è¿™æ ·/é‚£ä¹ˆ/é‚£æ ·\"ä¹‹å": 10,
      "NV9_ä¸èƒ½è·Ÿåœ¨\"å¤š/å¤šä¹ˆ\"ä¹‹å": 10,
      "NV10_å¯åé™„æ–¹ä½è¯æ„æˆå¤„æ‰€ç»“æ„": 10
    }}
  }}
}}
====JSON_END====

ã€å¼ºåˆ¶è¦æ±‚ã€‘
- JSONå¿…é¡»å’Œä¸Šè¿°æ¨¡æ¿ç»“æ„å®Œå…¨ä¸€è‡´ï¼ˆä¸èƒ½å¢åˆ å­—æ®µã€ä¸èƒ½ä¿®æ”¹è§„åˆ™åç§°ï¼‰ï¼Œä»…æ›¿æ¢å…·ä½“çš„æ•°å­—å¾—åˆ†å’Œæ–‡æœ¬å†…å®¹
- JSONä¸­æ‰€æœ‰å€¼å¿…é¡»æ˜¯**æ•´æ•°**ï¼ˆå¦‚10ã€-20ã€0ï¼‰ï¼Œä¸èƒ½ä½¿ç”¨å¸ƒå°”å€¼ï¼ˆtrue/falseï¼‰ã€ä¸­æ–‡ã€å­—ç¬¦ä¸²
- JSONä¸­æ‰€æœ‰é”®å¿…é¡»ç”¨åŒå¼•å·åŒ…è£¹ï¼Œæ•°å­—ä¸èƒ½åŠ å¼•å·ï¼Œæ¯”å¦‚"N1_å¯å—æ•°é‡è¯ä¿®é¥°": 10ï¼ˆæ­£ç¡®ï¼‰ï¼Œ"N1": "10"ï¼ˆé”™è¯¯ï¼‰
- åˆ†éš”ç¬¦====JSON_BEGIN====å’Œ====JSON_END====å¿…é¡»å•ç‹¬æˆè¡Œï¼Œä¸”å‰åä¸èƒ½æœ‰å…¶ä»–å†…å®¹
- æ¨ç†è¿‡ç¨‹å¿…é¡»åŒ…å«æ‰€æœ‰è§„åˆ™çš„åˆ¤æ–­ç†ç”±ã€ä¾‹å¥å’Œåˆ†æ•°ï¼Œä¸èƒ½çœç•¥
- è‹¥è¿åä»¥ä¸Šä»»ä½•ä¸€æ¡ï¼Œæœ¬æ¬¡åˆ†æè§†ä¸ºæ— æ•ˆ
"""

    user_prompt = f"""è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°è¦æ±‚ï¼Œåˆ†ææ±‰è¯­è¯è¯­ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦ï¼Œè¾“å‡ºæ¨ç†è¿‡ç¨‹å’Œè§„èŒƒçš„JSONï¼ˆæ‰€æœ‰è§„åˆ™å¿…é¡»å¡«å…·ä½“åˆ†æ•°ï¼‰ã€‚"""

    with st.spinner("æ­£åœ¨è°ƒç”¨å¤§æ¨¡å‹è¿›è¡Œåˆ†æï¼Œè¯·ç¨å€™..."):
        ok, resp_json, err_msg = call_llm_api_cached(
            _provider=provider,
            _model=model,
            _api_key=api_key,
            messages=[
                {"role": "system", "content": system_msg},
                {"role": "user", "content": user_prompt}
            ]
        )

    if not ok:
        st.error(f"æ¨¡å‹è°ƒç”¨å¤±è´¥: {err_msg}")
        return {}, f"è°ƒç”¨å¤±è´¥: {err_msg}", "æœªçŸ¥", f"è°ƒç”¨å¤±è´¥: {err_msg}"

    raw_text = extract_text_from_response(resp_json)
    parsed_json, cleaned_json_text = extract_json_from_text(raw_text)

    # è§£æJSONå¹¶è¡¥å…¨ç¼ºå¤±çš„è§„åˆ™ï¼ˆç›´æ¥è¯»åˆ†æ•°ï¼‰
    if parsed_json and isinstance(parsed_json, dict):
        explanation = parsed_json.get("explanation", "æ¨¡å‹æœªæä¾›è¯¦ç»†æ¨ç†è¿‡ç¨‹ã€‚")
        predicted_pos = parsed_json.get("predicted_pos", "æœªçŸ¥")
        raw_scores = parsed_json.get("scores", {})
        
        # å…³é”®ï¼šè¡¥å…¨æ‰€æœ‰ç¼ºå¤±çš„è¯ç±»å’Œè§„åˆ™ï¼ˆå…œåº•ï¼‰
        for pos in RULE_SETS.keys():
            if pos not in raw_scores:
                raw_scores[pos] = {}
            # è¡¥å…¨å½“å‰è¯ç±»çš„æ‰€æœ‰è§„åˆ™ï¼ˆé»˜è®¤å¡«ä¸åŒ¹é…åˆ†ï¼‰
            for rule in RULE_SETS[pos]:
                rule_name = rule["name"]
                if rule_name not in raw_scores[pos]:
                    raw_scores[pos][rule_name] = rule["mismatch_score"]
    else:
        # å®Œå…¨è§£æå¤±è´¥æ—¶ï¼Œåˆå§‹åŒ–æ‰€æœ‰è§„åˆ™ä¸ºä¸åŒ¹é…åˆ†
        explanation = "æ¨¡å‹è¾“å‡ºæ ¼å¼é”™è¯¯ï¼Œä½¿ç”¨é»˜è®¤å¾—åˆ†ã€‚"
        predicted_pos = "æœªçŸ¥"
        raw_scores = {
            pos: {rule["name"]: rule["mismatch_score"] for rule in RULE_SETS[pos]} 
            for pos in RULE_SETS.keys()
        }

    # éªŒè¯åˆ†æ•°ï¼ˆç›´æ¥è¯»æ•°å­—ï¼Œä¸è½¬æ¢å¸ƒå°”å€¼ï¼‰
    scores_out = {pos: {} for pos in RULE_SETS.keys()}
    for pos, rules in RULE_SETS.items():
        raw_pos_scores = raw_scores.get(pos, {})
        if isinstance(raw_pos_scores, dict):
            for k, v in raw_pos_scores.items():
                normalized_key = normalize_key(k, rules)
                if normalized_key:
                    rule_def = next(r for r in rules if r["name"] == normalized_key)
                    scores_out[pos][normalized_key] = validate_score(rule_def, v)

    # ä¿è¯æ¯æ¡è§„åˆ™éƒ½æœ‰å¾—åˆ†ï¼ˆæœ€ç»ˆå…œåº•ï¼‰
    for pos, rules in RULE_SETS.items():
        for rule in rules:
            rule_name = rule["name"]
            if rule_name not in scores_out[pos]:
                scores_out[pos][rule_name] = rule["mismatch_score"]

    return scores_out, raw_text, predicted_pos, explanation

# ===============================
# é›·è¾¾å›¾
# ===============================
def plot_radar_chart_streamlit(scores_norm: Dict[str, float], title: str):
    if not scores_norm:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆæ•°æ®ã€‚")
        return
    categories = list(scores_norm.keys())
    if not categories:
        st.warning("æ— æ³•ç»˜åˆ¶é›·è¾¾å›¾ï¼šæ²¡æœ‰æœ‰æ•ˆè¯ç±»ã€‚")
        return
    values = list(scores_norm.values())
    
    # é—­åˆé›·è¾¾å›¾
    categories += [categories[0]]
    values += [values[0]]

    fig = go.Figure(data=[go.Scatterpolar(r=values, theta=categories, fill="toself", name="éš¶å±åº¦")])
    fig.update_layout(
        polar=dict(radialaxis=dict(visible=True, range=[0, 1])),
        showlegend=False,
        title=dict(text=title, x=0.5, font=dict(size=16))
    )
    st.plotly_chart(fig, use_container_width=True)

# ===============================
# ä¸»é¡µé¢é€»è¾‘
# ===============================
def main():
    st.title("ğŸ“° æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±»")
    
    # --- é¡¶éƒ¨å›ºå®šæ§åˆ¶åŒº ---
    control_container = st.container()
    with control_container:
        col1, col2, col3 = st.columns([2, 1, 3])
        
        with col1:
            st.subheader("âš™ï¸ æ¨¡å‹è®¾ç½®")
            selected_model_display_name = st.selectbox("é€‰æ‹©å¤§æ¨¡å‹", list(MODEL_OPTIONS.keys()), key="model_select")
            selected_model_info = MODEL_OPTIONS[selected_model_display_name]
            
            # æ£€æŸ¥API Keyæ˜¯å¦å­˜åœ¨
            if not selected_model_info["api_key"]:
                st.error(f"âŒ æœªæ‰¾åˆ° {selected_model_display_name} çš„API Key")
                st.info(f"è¯·è®¾ç½®ç¯å¢ƒå˜é‡ **{selected_model_info['env_var']}** åé‡è¯•")
                st.code(f"# Linux/Mac\n export {selected_model_info['env_var']}='ä½ çš„API Key'\n\n# Windows\n set {selected_model_info['env_var']}='ä½ çš„API Key'", language="bash")
        
        with col2:
            st.subheader("ğŸ”— è¿æ¥æµ‹è¯•")
            if not selected_model_info["api_key"]:
                st.disabled(True)
                st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary", disabled=True)
            else:
                if st.button("æµ‹è¯•æ¨¡å‹é“¾æ¥", type="secondary"):
                    with st.spinner("æ­£åœ¨æµ‹è¯•è¿æ¥..."):
                        # ä½¿ç”¨ä¸€ä¸ªç®€å•çš„pingè¯·æ±‚æ¥æµ‹è¯•è¿æ¥
                        ok, _, err_msg = call_llm_api_cached(
                            _provider=selected_model_info["provider"],
                            _model=selected_model_info["model"],
                            _api_key=selected_model_info["api_key"],
                            messages=[{"role": "user", "content": "è¯·å›å¤'pong'"}],
                            max_tokens=10
                        )
                    if ok:
                        st.success("âœ… æ¨¡å‹é“¾æ¥æµ‹è¯•æˆåŠŸï¼")
                    else:
                        st.error(f"âŒ æ¨¡å‹é“¾æ¥æµ‹è¯•å¤±è´¥: {err_msg}")

        with col3:
            st.subheader("ğŸ”¤ è¯è¯­è¾“å…¥")
            word = st.text_input("è¯·è¾“å…¥è¦åˆ†æçš„æ±‰è¯­è¯è¯­", placeholder="ä¾‹å¦‚ï¼šè‹¹æœã€è·‘ã€ç¾ä¸½...", key="word_input")
            
            # å¼€å§‹åˆ†ææŒ‰é’®ï¼ˆAPI Keyä¸ºç©ºæ—¶ç¦ç”¨ï¼‰
            analyze_button = st.button(
                "ğŸš€ å¼€å§‹åˆ†æ", 
                type="primary",
                disabled=not (selected_model_info["api_key"] and word)
            )

    st.markdown("---")

    # --- ä½¿ç”¨è¯´æ˜ ---
    info_container = st.container()
    with info_container:
        with st.expander("â„¹ï¸ ä½¿ç”¨è¯´æ˜", expanded=False):
            st.info("""
            1. åœ¨ä¸Šæ–¹çš„â€œè¯è¯­è¾“å…¥â€æ¡†ä¸­è¾“å…¥ä¸€ä¸ªæ±‰è¯­è¯ã€‚
            2. ï¼ˆå¯é€‰ï¼‰åœ¨æ¨¡å‹é€‰æ‹©åŒºåŸŸç‚¹å‡»å‘ä¸‹ç®­å¤´å±•å¼€ï¼Œå¯ä»¥é€‰æ‹©ä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ã€‚
            3. ï¼ˆå¯é€‰ï¼‰ç‚¹å‡»â€œæµ‹è¯•æ¨¡å‹é“¾æ¥â€æŒ‰é’®ï¼Œç¡®è®¤æ‰€é€‰æ¨¡å‹å¯ä»¥æ­£å¸¸è®¿é—®ã€‚
            4. ç‚¹å‡»â€œå¼€å§‹åˆ†æâ€æŒ‰é’®ï¼Œç³»ç»Ÿå°†ä½¿ç”¨é€‰å®šçš„å¤§æ¨¡å‹åˆ†æè¯¥è¯è¯­çš„è¯ç±»éš¶å±åº¦ã€‚
            5. åˆ†æç»“æœå°†æ˜¾ç¤ºåœ¨ä¸‹æ–¹ï¼ŒåŒ…æ‹¬éš¶å±åº¦æ’åã€è¯¦ç»†å¾—åˆ†ã€æ¨ç†è¿‡ç¨‹å’ŒåŸå§‹å“åº”ã€‚
            """)

    # --- ç»“æœæ˜¾ç¤ºåŒº ---
    if analyze_button and word and selected_model_info["api_key"]:
        status_placeholder = st.empty()
        status_placeholder.info(f"æ­£åœ¨ä¸ºè¯è¯­ã€Œ{word}ã€å¯åŠ¨åˆ†æ...")

        scores_all, raw_text, predicted_pos, explanation = ask_model_for_pos_and_scores(
            word=word,
            provider=selected_model_info["provider"],
            model=selected_model_info["model"],
            api_key=selected_model_info["api_key"]
        )
        
        status_placeholder.empty()
        
        membership = calculate_membership(scores_all)
        st.success(f'**åˆ†æå®Œæˆ**ï¼šè¯è¯­ã€Œ{word}ã€æœ€å¯èƒ½çš„è¯ç±»æ˜¯ ã€{predicted_pos}ã€‘ï¼Œéš¶å±åº¦ä¸º {membership.get(predicted_pos, 0):.4f}')
        
        col_results_1, col_results_2 = st.columns(2)
        
        with col_results_1:
            st.subheader("ğŸ† è¯ç±»éš¶å±åº¦æ’å")
            top10 = get_top_10_positions(membership)
            top10_df = pd.DataFrame(top10, columns=["è¯ç±»", "éš¶å±åº¦"])
            top10_df["éš¶å±åº¦"] = top10_df["éš¶å±åº¦"].apply(lambda x: f"{x:.4f}")
            st.table(top10_df)
            
            st.subheader("ğŸ“Š è¯ç±»éš¶å±åº¦é›·è¾¾å›¾")
            plot_radar_chart_streamlit(dict(top10), f"ã€Œ{word}ã€çš„è¯ç±»éš¶å±åº¦åˆ†å¸ƒ")

        with col_results_2:
            st.subheader("ğŸ“‹ å„è¯ç±»è¯¦ç»†å¾—åˆ†")
            
            # 1. è®¡ç®—æ‰€æœ‰è¯ç±»çš„æ€»åˆ†å¹¶æ’åºï¼Œå–å‰10å
            pos_total_scores = {pos: sum(scores_all[pos].values()) for pos in RULE_SETS.keys()}
            # æŒ‰æ€»åˆ†é™åºæ’åºï¼Œå–å‰10
            top10_pos = sorted(pos_total_scores.items(), key=lambda x: x[1], reverse=True)[:10]
            
            # 2. åªæ˜¾ç¤ºæ’åå‰10çš„è¯ç±»
            for pos, total_score in top10_pos:
                # æ‰¾åˆ°è¯¥è¯ç±»ä¸‹å¾—åˆ†æœ€é«˜çš„è§„åˆ™
                max_rule = max(scores_all[pos].items(), key=lambda x: x[1], default=("æ— ", 0))
                
                # åˆ›å»ºexpanderï¼Œæ˜¾ç¤ºè¯ç±»åç§°ã€æ€»åˆ†å’Œæœ€é«˜åˆ†è§„åˆ™
                with st.expander(f"**{pos}** (æ€»åˆ†: {total_score}, æœ€é«˜åˆ†è§„åˆ™: {max_rule[0]} - {max_rule[1]}åˆ†)"):
                    # æ˜¾ç¤ºè¯¥è¯ç±»ä¸‹çš„æ‰€æœ‰è§„åˆ™å¾—åˆ†ï¼ˆæŒ‰è§„åˆ™å¾—åˆ†é™åºæ’åˆ—ï¼‰
                    rule_data = []
                    for rule in RULE_SETS[pos]:
                        rule_score = scores_all[pos][rule["name"]]
                        rule_data.append({
                            "è§„åˆ™ä»£ç ": rule["name"],
                            "è§„åˆ™æè¿°": rule["desc"],
                            "å¾—åˆ†": rule_score
                        })
                    
                    # æŒ‰å¾—åˆ†é™åºæ’åºè§„åˆ™ï¼Œè®©é«˜åˆ†è§„åˆ™æ’åœ¨å‰é¢
                    rule_data_sorted = sorted(rule_data, key=lambda x: x["å¾—åˆ†"], reverse=True)
                    rule_df = pd.DataFrame(rule_data_sorted)
                    
                    # è´Ÿåˆ†æ ‡çº¢
                    styled_df = rule_df.style.applymap(
                        lambda x: "color: #ff4b4b; font-weight: bold" if isinstance(x, int) and x < 0 else "",
                        subset=["å¾—åˆ†"]
                    )
                    
                    st.dataframe(
                        styled_df,
                        use_container_width=True,
                        height=min(len(rule_df) * 30 + 50, 800)
                    )
            
            st.subheader("ğŸ“¥ æ¨¡å‹åŸå§‹å“åº”")
            with st.expander("ç‚¹å‡»å±•å¼€æŸ¥çœ‹åŸå§‹å“åº”", expanded=False):
                st.code(raw_text, language="text")
            
            st.subheader("ğŸ” æ¨¡å‹æ¨ç†è¿‡ç¨‹")
            with st.expander("ç‚¹å‡»å±•å¼€æŸ¥çœ‹æ¨ç†è¿‡ç¨‹", expanded=False):
                st.markdown(explanation)

if __name__ == "__main__":
    main()

# ===============================
# é¡µé¢åº•éƒ¨è¯´æ˜
# ===============================
st.markdown("---")
st.markdown(
    "<div style='text-align:center; color:#666;'>"
    "Â© 2025 æ±‰è¯­è¯ç±»éš¶å±åº¦æ£€æµ‹åˆ’ç±» "
    "</div>",
    unsafe_allow_html=True
)
